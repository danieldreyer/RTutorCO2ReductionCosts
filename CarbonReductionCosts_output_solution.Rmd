
---
title: Problem Set CarbonReductionCosts
output: 
  html_document: 
    keep_md: yes
    toc: yes
---

```{r setup, include=FALSE, echo=FALSE}
# Load libraries and source extra code
library(dplyr)
library(ggplot2)
library(gridExtra)
library(stargazer)
library(tidyverse)
library(ggalt)
library(splines)
library(kableExtra)
library(RTutor)


# Options for rendering data frames
# If you knit to a Word docx file, try
# 
# data.frame.theme="word" 
# 
# (needs RStudio > 1.2.1)
# 
# You can also set the options like
# table.max.cols as chunk options
# Makes sense if there are too many, too wide
# columns in some chunks

RTutor::set.knit.print.opts(data.frame.theme="code", table.max.rows=25, table.max.cols=NULL, round.digits=5, signif.digits=8)


# continue knitting even if there is an error
knitr::opts_chunk$set(error = TRUE) 
```

# Problem Set: Estimating CO2 Reduction Costs

Author: Daniel Dreyer


<style>
img {
    display: block;
    margin-left: auto;
    margin-right: auto;
    max-width: 100%;
}
</style>

Welcome to this interactive problem set. The awareness of climate change rose significantly over the past years. Purely questioning the moral of the population though, won't avoid its' highly uncertain effects. Therefore high efforts are made to find technical improvements as well as economical incentitives to avoid long term effects of climate change.   
In this problem set we will approach one possible countermeasure by analysing how carbon pricing would reduce emissions in the electricty sector. The analysis is based on **"Inferring Carbon Abatement Costs in Electricity Markets: A Revealed Preference Approach using the Shale Revolution"** by Joseph A. Cullen, Erin T. Mansur (2016) - further simply referred as Cullen (2016). The paper and further ressources can be downloaded from <a href="https://www.aeaweb.org/articles?id=10.1257/pol.20150388   target = "_blank"> https://www.aeaweb.org/articles?id=10.1257/pol.20150388</a>

You will use the `Statstical Programming Language R` to replicate the analysis. Basic knowledge of `R` is required, but information on important function will be provided. 
Since each new exercise inherits the results of previous exercises, it is recommendated to solve them in order. However you are free to skip to any exercise you like if you feel so.  
If you are a complete novice in `R` you should not feel left behind. Understanding the basic concepts is straight forward, you can find useful information [here](https://cran.r-project.org/manuals.html).



### Contents

$\qquad$  Overview
  
$\qquad$  1 TBA

$\qquad$  2 TBA

$\qquad$ $\qquad$ 2.1 

$\qquad$  3 TBA

$\qquad$  4 TBA

$\qquad$  5 Conclusion

$\qquad$ References


## Exercise Content

$\qquad$ *Exercise 1* - Motivation (rename later)

$\qquad$ *Exercise 2* - TBA

$\qquad$ *Exercise 3* - TBA

$\qquad$ *Exercise 4* - TBA

$\qquad$ *Exercise 5* - TBA


### ReadME


The problem set offers different ways to interact with it. Coding exercises are marked as **TASK**. Some only need to be run, for others you need to complement a small part of the code, which is noted in the task description. Below you can read about the different types of interactions with their corresponding functions:   


 - Code Chunks: Require you to complete small parts of Code. The work flow of solving code chunks is intuitive and as follows:
                
  + `edit` : Click to insert your own Code into the chunk.
  + `run chunk`: Runs the chunk and displays outputs or errors in the corresponding console.
  + `check`: Check your input for against the solution.
  + `hint` : Should you have problem to solve a task, you can request a hint.  
&nbsp;

  
  Additional functions:    
                   
  + `data`: Redirects you to the data browser - you can view the loaded data with the help of an interface.
  + `solution` : Shows the solution of the task.  
&nbsp;

  
 - Quizzes: Evaluate your knownledge of topics before we dive in our analysis.
    
 - Info Boxes: Contain additional information on technical terms or documentation of functions.
 

After you finish a chapter, click `Go to next exercise` on the bottom or navigate around with the help of the bar on top.


## Exercise 1 -- Insights into Energy Markets

The energy consumption of the world keeps rising daily. New technologies are being developed to satisfy our needs, but we are still heavily dependant on `fossil fuels`. Coal is hereby one of the biggest and most important source of energy, but at the same time the biggest cause of carbon emissions. It is easy to store, to transport, doesn't alter and can be mined in huge quantities all around the world. This makes it desirable and cheap to use as a relying energy source. Given that coal supplies will last for centuries, it is a major goal to find incentitives to reduce the use of coal and therefore emissions.
Another major energy ressource is `natural gas`. Even though still being a fossil fuel, its' emissions and heat density are way superior to coal. Nevertheless, natural gas wasn't considered to be an real alternative to coal because of more difficult extracting methods and handling.  
This changed due to the `Shale Revolution` in the early 2000s, where natural gas began to not only be a by-product of the oil industry, but could now be extracted large quantities and in a targeted manner. Lanfrancois (2012) estimates, that based on the `Clean Power Plan` introduced by the Obama Administration in 2015, carbon dioxide emissions from the electricity industry could be reduced by roughly 23 to 42 percent by replacing existing coal to gas fired generators.    
  

***

### Info: Shale-Revolution
Shale gas is a form of natural gas and is extracted from shale formation, a technology known as fracking. Since the start of this century, shale gas became a increasingly more popular source of natural gas in the United States. Whereas in the year 2000 shale gas only provided 1% of the extracted natural gas in the U.S., whereas nowadays it makes up roughly 50%. However, the long term effects of fracking on the environment are still fairly unknown and are heavily debated.

You can find further information on this topic below:  
<a href="https://en.wikipedia.org/wiki/Shale_ga   target = "_blank"> https://en.wikipedia.org/wiki/Shale_gas</a>s  
<a href="https://en.wikipedia.org/wiki/Hydraulic_fracturing   target = "_blank"> https://en.wikipedia.org/wiki/Hydraulic_fracturing</a>

***

  
Enough background for now, let's start with some interactive tasks. In `Exercise 1` we will get a feeling for the energy sector and explore time-series data of historic prices and generated power.

**Task:**
Use the `read_csv` command to *load the data set* and store it in a variable called `data`. `Read_csv` displays the parsed type of each column after you execute the command. This will come handy later on in this exercise. Since this case won't happen again in this problem set though, we will disable these messages in future exercises.


***

### Info: read.csv() and write.csv()
The command `read_csv()` reads in a **csv file** and stores it into a given name. Csv is a format for data, that uses commas as seperators and periods as decimals. Another version of are **csv2 files**, where semicolons are used for seperators and commas for decimals. We only use csv files in this problem set.

Given the file you want to read it is in the same working directory, you can use the command below:

```{r "1",eval=FALSE}
example <- read_csv("example.csv")
```

If the file is saved outside of your working directory you have to differentiate between two possibilities.  
For files that are "above" your current working directory, you have to provide the full path to the file. You can view your working directory with `getwd()`:

```{r "1__2",eval=FALSE}
example <- read_csv("C:/Data/example.csv")
```

For files that are located "below" the working directory it is sufficient to specify the file path starting with your current working directory:

```{r "1__3",eval=FALSE}
example <- read_csv("./Data/example.csv")
```

Csv files can be saved using the `write_csv` command:

```{r "1__4",eval=FALSE}
write_csv(example, file="example.csv")
```

For further information, use `help(write_csv)`.

***


```{r "1__5"}
# ... <- read_csv("./Data/exercise1.csv")
dat <- read_csv("./Data/exercise1.csv")
```

**Task:** The first thing you should do after loading a new data set is looking at the structure. Use the `head()` command to show the first **eight** rows of the data set named `dat`.  

When not given a second argument, `head()` displays the first 5 rows on default. Alternatively, the problem set provides a seperate data tab. If you want to take a closer look at the data, especially later on in the problem set, you can click `data` and get redirected to the `Data Explorer` Tab, where you can navigate along the data frame and see some basic statistics.  

```{r "1__6"}
# head(dat, ...)
head(dat, 8)
```

The data frame contains monthly numbers of generated MWh of coal and gas as well as prices of `natural gas` in Europe and the United States as well as the `natural gas index` from the year 2002 to the end of 2019. Keep in mind that different commodities are traded in different units. Coal in metric tons (`\$/mt`) and gas in British thermal units (`$/mmBTU`). The natural gas index is set to 100 in the year 2010 and changes accordingly. 
While reading in our current data set I mentioned that it would come handy to know which data types your columns inherit. `R` requires `dates` to be stored as type `Date`, otherwise we will get weird outputs when trying to plot along a time line. The date column is currently stored as type `character`. Therefore  we have to convert the date variable into a `date format` by using `as.Date()`.

**Task:**  Transform the data type with `as.Date()` and store the transformed variable to the same name.
```{r "1__7"}
# ... <- ...(dat$date, format="%m/%d/%Y")
dat$date <- as.Date(dat$date, format="%m/%d/%Y")
```

Now that we imported our data set, got a first look on its' structure and data, lets start creating our first plot. `R` provides several packages to create your own plots. Basic `R` is also capable of producing plots. This is the way to go if you want some quick visualisations. In this problem set we will, with a few exeptions, use the package `ggplot2`. It is widely considered one of the most powerful packages to create plots, but the downside is that you have to get used to the handling. In this problem set you won't need to create whole plots on your own but `fill in blanks`. This way you will learn how the logic within `ggplot2` works and at the same time won't be frustrated if the output doesn't meet the requirements.

The first plot we want to create should tell us more about the development of gas prices along the timeframe. As we have mentioned at the beginning of this exercise, the `Shale-Revolution` started in the beginning of this century. Therefore we expect falling gas prices for the U.S. market. Since commodity prices are split for regions/markets, the European Gas price should differ. Let's see if these assumptions are true.

**Task:** Use the data frame `dat` to plot historic prices of gas in Europe and the United States. For reference, just press *check*.


***

### Info: ggplot2
The package `ggplot2` is a powerful data visualization package for `R`, which is part of the `tidyverse` environment. Besides basic functions that are also provided by native `R`, it allows the user to
highly modify graphs by **altering**, **adding** or **removing** components.

The problem set doesn't require you to have deeper knowledge about function of `ggplot2`. However, you can find further documentation [here](https://ggplot2.tidyverse.org/) or type `help(ggplot2)`.

***

```{r "1__8"}
ggplot(data=dat, aes(x=date)) +
  geom_line(aes(y=dat$price_naturalgas_USA, color="Gas US"), size=1) +
  geom_line(aes(y=dat$price_naturalgas_Europe, color="Gas Europe"), size=1) +
  labs(x = "Year", y = "", title = "Natural Gas Prices", subtitle = "Y=$/mmBTU")+
  scale_color_manual(name="Region",values = c("blue","red"))
```

Looking at the plot our assumptions are confirmed. We observe a strict fall in gas prices in the U.S. from just over $12 in 2008 to under \$2 in 2016. The prices remained at roughly the same low level. Natural gas prices in Europe are considerable higher. One reason being is that fracking isn't as popular in Europe, therefore a major part of gas in Europe gets imported from Russia which drives prices. Another reason is that Europe has a different energy mix. According to the European Environment Agency (EEA) the consumption of gas decreased in average by 1.4% per year since 2005, whereas in the U.S. natural gas reached new all-time highs nearly every year.

Looking forward Because of the lack of data provided by state officials in Europe, this problem set will further on purely focus on the U.S. market. 
Onwards this problem set will focus on the U.S. market. 



To visualise the the generation of power with coal and gas, lets make another plot



Quiz: Do you think that the proportion of gas generated electicity compared to coal generated electricity has increased or decreased over time?

- increased [x]

- decreased [ ]

&nbsp;

**Task:** Create a new `ggplot2`. Plot the `date` on the x-Axis, generated electricity on the y-Axis. We want `one line` for `gas generated power` as well as `one line` for `coal generated power`. Lines are drawn with `geom_line`. For reference you can look at the code from the previous graph or conduct the help() function.

```{r "1__9"}
#ggplot(data=___, aes(x=___)) +
#  ____(aes(_=dat$generated_coal, color="Coal Generation (TWh)"), size=1, alpha=0.5) +
#  ____(aes(_=dat$generated_gas, color="Natural Gas Generation (TWh)"), size=1, alpha=0.5) +
#  labs(x = "Year", y = "", title = "Monthly Generation by Fueltype", subtitle = "Y=Monthly Electricty (TWh)")+
#  scale_color_manual(name="",values = c("black","red"))+
#  scale_y_continuous(breaks=seq(0,200,25))
ggplot(data=dat, aes(x=date)) +
  geom_line(aes(y=dat$generated_coal, color="Coal Generation (TWh)"), size=1, alpha=0.5) +
  geom_line(aes(y=dat$generated_gas, color="Natural Gas Generation (TWh)"), size=1, alpha=0.5) +
  labs(x = "Year", y = "", title = "Monthly Generation by Fueltype", subtitle = "Y=Monthly Electricty (TWh)")+
  scale_color_manual(name="",values = c("black","red"))+
  scale_y_continuous(breaks=seq(0,200,25))
```


These finding are cemented by reports from the EIA
EIA 2020/3 https://www.eia.gov/todayinenergy/detail.php?id=43035

Natural gas accounts for the largest share in electricity generation. 


Due to the lack of data provided by state officals in Europe, from here onwards we will purely focus on the U.S. market.




***

### Award: Starter Kit
Good Start by finishing the first exercise! You will earn awards at the end of every exercise. After you completed all exercises you will see how many awards you got.

***


In the next exercise we will go through the necessary theory 



## Exercise 2 -- Theory


### Relationship between Fuel and Carbon Prices


***

### Info: Variable names in this exercise
$MC$: Marginal Costs  
$HR$: Heat Rate, mmBTU/MWh  
$C_{coal}$: Cost of burning Coal  
$C_{gas}$: Cost of burning gas  
$P_{coal}$: Coal Price, $/mmBTU  
$P_{gas}$: Gas Price, $/mmBTU  
$CO_{2,coal}$: Carbon content of coal, tons/mmBTU  
$CO_{2,gas}$: Carbon content of gas, tons/mmBTU  
$P_{co2}$: Carbon Price , $/ton

***



As a prerequisite we can define the `marginal costs` of fossil-powered plants as a Equation of `heat rate` and the `costs of burning fuel`:

$$\tag{1}MC=HR\cdot(P_{fuel}+CO_{2,fuel}\cdot P_{co2})=HR\cdot C_{fuel}$$

In `Exercise 1` we already looked at fuel prices of `gas` and `coal` and their variance over time. Because of the fact that the cost efficiency of coal is generally better, we have to introduce a incentive to reduce the use of coal in relation to gas in electricity generation. One way to change the cost efficiency is to propose `carbon taxes`. This is especially viable because coal contains approximately `twice` as much $CO_2$ as natural gas and therefore lowers the cost efficiency. Another fact that drives this momentum is, that gas plants are generally more efficient than coal generators. Combining these two facts of cost and generation efficiency lead to `steeper marginal cost` for coal generators when carbon prices are introduced. Reflecting this to our upcoming analysis, we don't observe any carbon prices, but a time-series of fuel prices. To reflect the mechanism of `fuel change`, which we explained above, we introduce a`coal-gasratio`, which we define as followed:

$$\tag{2}priceratio=\frac{C_{coal}}{C_{gas}}$$

Quickly nterpreting this `Equation`, the `price ratio` will rise for higher `coal prices` or lower `gas prices`. Understanding the mechanism of changing fuel and carbon prices is essential for our main analysis.To get a clearer understanding, lets visualize the relationship with 2 graphics, which replicate Figure 4 of Cullen.

<img src="./Material/relationship.png" alt="drawing" width="600"/>
Source: Cullen (2016)  
  
Looking at the upper graph, as soon as `carbon prices` get introduced, the cost efficiency of coal generators will fall in relation to gas generators. Up until a point where gas generators will have a highercost efficiency. Transforming these prices in `price ratios` will lead to the graphic below. 


Quiz: Do you think we can create any given price ratio under the assumption that we introduce carbon prices under fixed fuel prices?

- Yes [x]

- No [ ]

&nbsp;

Combining Equation `1` and `2` we can explain price ratios as a function of `fuel prices`, `carbon content` and `carbon prices`:

$$\tag{2}priceratio=\frac{C_{coal}}{C_{gas}}=\frac{P_{coal}+CO_{2,coal}\cdot P_{co2}}{P_{gas}+CO_{2,gas}\cdot P_{co2}}$$

Rearranging for carbon prices: 

$$\tag{3}{P_{co2}}=\frac{CR\cdot{P_{gas}}-{P_{coal}}}{CO_{2,coal}-CR\cdot CO_{2,gas}}$$


***

### Award: Theorist
Gratulations! You can now map carbon prices. You are ready to start with the analysis.

***




### Interconnections

<img src="./Material/interconnections.png" alt="drawing" width="600"/>
Source: Cullen (2012)

The American Electric system is made up of three major `interconnections`, which in turn concist of different balancing authorities (responsible for maintaining the electricity balance within the region). Local electricity grids are hereby connected to form a network, which provides higher stablity and reliability. These `interconnections` operate mostly independent to each other and exchange little to no electricity, in contrast to the European electricity grid.  

In the graph below you can see the `3` interconnection we include data of in this problem set. I listed a few details for each below:
- `Eastern Interconnection`: Consists of 36 balancing authorities and extends from the East Coast to the Rocky Mountains.
- `Western Interconnection`: Involves 37 balancing authorities, which are located in the West of North America.
- Electric Reliability Council of Texas (`ERCOT`): Consists of large parts of Texas


**Task:** Just press *check*.
```{r "2__10"}
Emissions <- read.csv("./Data/Emissions_Unit_Type.csv")
```

wip

HIER HIN????????????
**Task:** Just press *check*.


***

### Info: geom_encircle
`Geom_encircle()` is part of the package `ggalt` which extends functionality of `ggplot2`. Besides standard functionality for plotting points or lines that is provided by basic `ggplot2`, it provides a advanced framework for visualising your data. `Geom_encircle()` automatically encloses points in a polygon and can be used to visualise differences in groups of data.

Call `help(geom_encircle)` to get further information.

***


```{r "2__11"}
ggplot(dat,aes(x=gasprice,y=co2mass/1000,color=intercn))+
        geom_point(alpha=0.2) +
        geom_encircle(aes(group=intercn,fill=intercn),alpha=0.3, s_shape=1) +
        theme_bw()+ 
        labs(y="", 
        x="Gas Price", 
        subtitle="y=CO2 Emissions in 1000s tons/day",
        title="CO2 Emissions vs. Gasprice")
```

TEXT




The degree to which production switches from coal to gas generation will depend on
several factors. From a static dispatch framework, fuel switching depends on the relative
fuel prices, the relative heat rates, the available capacity of gas plants, and the demand
for electricity. In addition, intra-day fluctuations in electricity demand may be important as
some generators are not well suited for starting and stopping production frequently. Start-up
costs, ramping rates, minimum down times, and other intertemporal constraints limit firms’
operation decisions (Mansur 2008, Cullen 2015). 






## Exercise 3.1 -- Emission Response Curves - A simple approach

A short recapture: Until now we got an idea how the energy market in the U.S. is build, how commodity prices changed over that and introduced the concept of `interconnections` . Additionally we
briefly went over the theory behind mapping carbon prices???. 
In `Chapter 3` we will present the needed regression theory and develop a model that will hopefully help us answer our main question on how carbon prices would effect emissions in the energy sector.
However we won't simpy propose a final model but will work our way from a simple linear regression model to more complex but also more accurate models. 



In this exercise we briefly go over the data we use for our main analysis and give an overview what we will be doing in the following exercises. The main question of this problem set is to find out
how carbon prices would effect emissions in the energy sector. To answer this we will construct a statistical model to understand the emission behaviour for changing input costs while controlling
for variables that effect the energy market. However we won't simply propose a final model but will work our way from simple linear regressions to more complex but also more accurate models.  
&nbsp;

Until now we got an idea how the energy market is 
In this and the following chapter we will take a look at regression theory and develop a model that satifies our statistical needs tor answer our initial question on how changing commodity prices will effect $CO_2$ emissions. We start with simple regressions and introduce new methods along the way to make our model more precise.

If you are purely interested in the final model and the economic impact, you can skip to `Exercise 4.1` onwards. This chapter will focus on regression theory which will allow us to construct a
fitting model and introduces some requirement to 

**Task:** To get started, load the data set `exercise3.csv`, press `edit` and `check` afterwards.

```{r "3_1__12",message=FALSE}
dat <- read_csv("Data/exercise3.csv")
head(dat,3)
```

In the last exercise we got a glimpse why it makes sense to calculate our model for each interconnection seperatly. We will get further indication on why that makes sense later on. For this purpose
we will filter our data set for interconnection `EAST` and develop the model based on these data. Once we found a fitting model we will use the model on each interconnection.    
To get started with our regression model, we will try to regress fuel prices against $CO_2$ emissions. As we have seen in the beginning of this problem set in `Exercise 1` we observe substantial
variation in coal and gas prices. While some of its' variation is regional, most of it comes from price variations over time. Because of that reason we construct a new variable called `Price Ratio`.
There are several ways to propose price ratios, we will use the ratio between the price of coal and gas and is defined as followed:  

$$\tag{2}priceratio=\frac{C_{coal}}{C_{gas}}$$

You may ask, why we won't simply use both fuel prices seperately, but construct the ratio. There are several benefits of doing so. Firstly, 



THe question here is, why use a priceratio and not just coal and gas prices seperatly.  ///////// why priceratio - paper 18 absatz 2


**Task:** The data set contains a column `intercn` with values `EAST`, `WEST` and `ERCOT`. Filter the data set for interconnection `EAST` and store the new data frame in variable `dat_east`. Additionally, calculate the cost ratio between `coalprice` and `gasprice` according to formula 2.


***

### Info: Pipe, mutate, select
The pipe operator `%>%` is a feature provided by the `dplyr` Package. Essentially it allows to exectute multiple operation on a dataframe at once.
This works the way that every pipe operator returns a dataframe and passes it to the next connected function. `Select` allows you to filter out certain columns of data, whereas `mutate` allows you to
alter data. The counterpart for selecting specific rows is `filter`. There are several more functions to alter your data, below i linked a handy cheatsheet.
  
```{r "3_1__13",eval=FALSE}
example %>% 
  select(1:5)  `select: keep certain columns, here column 1 to 5`  %>% 
  mutate(new_column = old_column+1)`mutate: create or alter columns`    

```

You can find a more detailed cheatsheet [here](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) or use the `help()` function.

***



```{r "3_1__14"}
# ... <- data %>% 
#  mutate(CR = .../...) %>% 
#  filter(intercn=="...")
dat_east <- dat %>% 
  mutate(priceratio = coalprice/gasprice) %>%
  filter(intercn=="EAST")
```


### Stage 1: Linear Regression

We start by proposing a simple linear regression model. In a mathematical way we can express the relationship as followed:

$$\tag{3}CO_{2t}=\beta_{0}+\beta_{1}\cdot priceratio_{t}$$



***

### Info: Linear Regression with lm()

`lm()` is part of the `stats` package and loaded on default. As shown in the syntax example below, it enables you to regress `y` on the indepedent variables `x1` and `x2`. The model can be `stored` in a variable or directly `used` in other functions. Another popular function to solve linear regressions in `R` is `felm()`, that provides further functionality to include `fixed effects`. In this problem set we will strictly use `lm()`.

```{r "3_1__15",eval=FALSE}
example <- lm(y~x1+x2, data=dat_east)
```

You can find more information on the `lm()` function [here](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm) or use the `help()` function.

***


**Task:** Run a regression with `co2mass` as the dependent variable and `priceratio` as independent variable. Store it in the variable `fit1`. 
```{r "3_1__16"}
# ... <- lm(...~... , data=east)
fit <- lm(co2mass ~ priceratio, data=dat_east)
```


Quiz: What impact do changing price ratios have on emissions?

- With increasing price ratios emissions will increase. [ ]

- With increasing price ratios emissions will fall. [x]



TEXT

**Task:** To
```{r "3_1__17"}
summary(fit)
```

$\beta_{1}$

The summary statistics shows as a positive value for priceratio $\beta_{1}$, which means that a increasing price ratio decreases emissions.


For upcoming regressions we will use the `stargazer()` function from the `stargazer` package to show summary statistics from our regressions. We don't need get every information the basic functions displays, therefore we define a own custom function with statistics we need. Read below to find out more about `stargazer` and `custom functions` and continue with the next `task`.


***

### Info: Stargazer
`stargazer` provides specialised `HTML` formatting for regression tables and summary statistics tables. It is easy to use, supports a large number of model types and formats data in a more pleasing way. The basic function is called by `stargazer()`, but can be customized heavily. For more information run `help(stargazer)` or read further [here](https://cran.r-project.org/web/packages/stargazer/).

***



***

### Info: Custom functions
`R` provides an easy framework to add your own functions. The syntax is quite similar to other `Programming Languages` you could be familiar with. Once you have defined a function, you can use it as long as you are in the same session. Below you can find the basic structure of a function:

```{r "3_1__18",eval=FALSE}
`myfunction <- function(arg1, arg2, ... ){`  
`statements`  
`return(object)`  
```  
Here's an simple functions that adds `5` to the input and returns it.
```{r "3_1__19",eval=FALSE}
`example <- function(x) {`  
  `x + 5`  
`}`  
`example(1)`
```  
You can find more detailed information [here](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/function).


***


**Task:** Click check to run the Code. It defines the function to show our custom regression tables.
```{r "3_1__20"}
show.regression= function(...){
  library(stargazer)
    stargazer(..., 
            type = "text", 
            style = "aer",  
            digits = 3,
            df = FALSE,
            report = "vct*",
            star.cutoffs = c(0.05, 0.01, 0.001),
            model.names = FALSE,
            object.names = TRUE,
            model.numbers = FALSE, 
            omit.stat=c("f", "ser")
    )
} 
show.regression(fit)
```

Our eventual goal is to plot the rensponse curves of changing ??AWD prices 


***

### Info: Predict
`predict()`

***


**Task:** To
```{r "3_1__21"}
p1 <- predict(fit, newdata = dat_east)
```




**Task:** To
```{r "3_1__22"}
plot(co2mass~priceratio, dat_east)
lines(dat_east$priceratio, p1, col="red")
```




**Task:** Let's see what we just defined. Run the regression table for the linear model. Insert 
```{r "3_1__23"}
# regression.result(...)
show.regression(fit)
```

TEXT

**Task:** To
```{r "3_1__24"}
plot(fit, 1)
plot(fit, 2)
```

QQ PLOT RESIDUALS?


***

### Info: R-squared
`R-Squared` is a statistical measurement that represents the correlation between `fitted values` and `observed values`. `R-squared` is always positive and ranges from 0 to 1. A value closer to 1 indicates that the suggested model explains a majority of the variance in the outcome variable.  
$R^{2}=1-\frac{Explained Variation}{Total Variation}$
A problem with the `R-squared` measurement is, that it always increases with higher numbers of variables in the model, even if these variables are only weakly responsible for the predicted values. An solution is to take the number of variables into account, this is called `Adjusted R-Squared` and also shown in the summary output.

***


RMSE?

### Stage 2: Polynomial Regression

**Task:** Just press *check*.
```{r "3_1__25"}
CR.squared <- east$CR^2
fit2 <- lm(CO2MASS ~ CR + CR.squared, east)

CR.cubed <- east$CR^3
fit3 <- lm(CO2MASS ~ CR + + CR.squared + CR.cubed, east)
```

**Task:** Just press *check*.
```{r "3_1__26"}
p2 <- predict(fit2, east)
p3 <- predict(fit3, east)
```

**Task:** Just press *check*.
```{r "3_1__27"}
plot(CO2MASS~CR, east)
lines(east$CR, p1, col="red")
lines(east$CR, p2, col="blue")
lines(east$CR, p3, col="green")
```

**Task:** Just press *check*.
```{r "3_1__28"}
regression.result(fit, fit2, fit3)
```

**Task:** Just press *check*.
```{r "3_1__29"}
anova(fit, fit2, fit3)
```



## Exercise 3.2 -- Restricted Spline Regressions

### Stage 3: Cubic Spline



Explain Cubic Splines

```{r "3_2__30",optional=TRUE}
# show that all integers between 0 and 10
1:10
```



simple cubic splines

$$\tag{4}CO_{2t}=s(CR_{t}|\beta)$$

***

### Info: ns()
`Ns()` is part of the `splines` package and allows us to perform natural splines regressions on our data. It takes several input arguments, the only one we will use is `df` which sets the degrees of freedom. 


***



First, we have to define our model 





***

### Award: Linear Regression Expert
TEXT

***













## Exercise 4 -- ???

Until now we got an idea about the energy market in the U.S. and the regression theory needed to develop a model that will answer our main question how carbon prices would reduce emissions. 

Until now we worked with data sets that only include a portion of what we will use in our final model. Therefore we will use this exercise to present the data we use for our analysis and give an overview what we will be doing in the following exercises. The main question of this problem set is to find out
how carbon prices would effect emissions in the energy sector. 



answer this we will construct a statistical model to understand the emission behaviour for changing input costs while controlling
for variables that effect the energy market. However we won't simply propose a final model but will work our way from simple linear regressions to more complex but also more accurate models.  
&nbsp;

 - You can find a rough guideline of content in each exercise below:
  + `Exercise 4.1` - Estimated CO2 Response to Fuel Prices
  + `Exercise 4.2` - Imputed CO2 Response to Carbon Prices
&nbsp;
  
Before we take a look at the data, import our dataset.

**Task:** Load the data set `main_data.csv`, press `edit` and `check` afterwards.

```{r "4__31",message=FALSE}
dat <- read_csv("Data/main_data.csv")
head(dat,3)
```
&nbsp;

The data frame is a combination of data we used previous exercises and additional factors. It consists of `daily` information for `each interconnection`. The meaning of each column is explained below:

`co2mass`: $CO_2$ emissions in tons  
`gasprice`: Capacity weighted average daily gas price per interconnetion ($ per million BTU)  
`coalprice`: Price of Coal ($ per million BTU)  
`load`: daily electricity consumption per interconnection in MWH  
`meant`: average daily temperature per interconnection  
`nonFossil`: Electricity generation with non-fossil fuel in MWH  
`so2price`: Permit prices of $SO_2$ ($/ton)  
`netNSflow`: MwH flowing from Canada to US by interconnection and month  

The data are gathered from several official U.S. agencies and aggregated to a daily level and seperated by interconnection. Because of the size of these data sets we wont do the data
preparation in this problem set but rather provide the data sources. `Emission` data are measured by the Continuous Emissions Monitoring System (CEMS) of the `Environmental Protection Agency (EPA)`.
The U.S. Energy Information Administration (EIA) collects data of `Non-fossil` energy production as well as spot prices of `coal prices` in Form 923. Spot prices of `gas` can be found in
`Intercontinental Exchange (ICE)`. Data of `electricity consumption` or `load` are provided in Form 714 of the `Federal Energy Regulatory Commission (FERC)`, permit prices of $SO_2$ from the `EPA Clean Air Markets` and finally, `net imports` of electricity from Canada are gathered from the `National Energy Board of Canada`. Links to the sources can be found in `references section`.

To give us an overview of the data, lets create a table with average values for relevant factors of each interconnection. `Dyplr` provides 


R provides several packages for that , but for now we work with packages we
introduced before and solve this with `dyplr`.  

**Task:** Use `group_by()` to group the dataset `dat` by `intercn`. Afterwards use `summarise_all()` to calculate the means of every column. You don't have to deal with the additional lines of code, which is used to create a more understandable output.


***

### Info: Group_by() and summarise()
`Group_by()` allows you to group a data frame by specific variables. Operations that are run on the grouped data frame are then performed on each group.

The function `Summarise()` is run on **grouped data** and can perform operations e.g. calculating means (`mean()`) or finding minimums (`min()`). There are several
pre-implemented version of `summarise` functions in `R`. The one we use here is `summarise_all()`, which performs these operations on all columns.

To give you an example in code form, lets pretend we have a dataframe `data` with several `car manufacturer` and their respective car models with `prices` and we want to calculate the average car price per manufacturer.

```{r "4__32",eval=FALSE}
example <- data %>% 
  group_by(manufacturer) %>%
  summarise(mean_price = mean(price))
```

Call `help(group_by)` or `help(summarize)` for further information.

***

  

***

### Info: kable()

***


///Tabelle mit einheiten

```{r "4__33"}
#... %>% 
#  select(intercn, co2mass, load, gasprice, coalprice) %>% 
#  group_by(...) %>% 
#  ...("mean") %>% 
#  mutate(co2mass = co2mass/1000, load=load/1000, "Emission Rate"=co2mass/load, "Cost Ratio"=coalprice/gasprice) %>% 
#  rename("CO2 Emissions"=co2mass, Load=load, "Gas Price"=gasprice, "Coal Price"=coalprice)
dat %>% 
  select(intercn, co2mass, load, gasprice, coalprice, nonfossil) %>% 
  group_by(intercn) %>% 
  mutate(co2mass = co2mass/1000, load=load/1000, "Price Ratio"=coalprice/gasprice, "Emission Rate"=co2mass/load, nonfossil=nonfossil/100000) %>% 
  summarise_all("mean") %>% 
  rename("Interconnection"=intercn, "CO2 Emissions"=co2mass, Load=load, "Gas Price"=gasprice, "Coal Price"=coalprice, "Non fossil"=nonfossil)
```

The table replicates `Table 1` from Cullen (2016) and reports the mean of several factors for each `interconnection`. We can clearly see that the East is by far the largest of the observed energy
markets. The emissions seem to increase proportionally to the electricity consumption if we take the electricity production from non-fossil sources in consideration. This gets clearer if the look at
the emission rates, which are defined as $ER=\frac{emissions}{load}$. Therefore the Western interconnection has by far the `cleanest` energy production, followed at some distance by Texas (`ERCOT`)
and `East`. Furthermore we observe clear variations in price ratios.  
This is in line with our assumptions from `Section 2`, where we stated that each interconnection has vastly different conditions and therefore run our analysis for each seperatly.  
In the next exercise we will use this data frame and the regression theory we presented in `Chapter 3` to trace out the emission response curves and later on tranform them into carbon prices.


## Exercise 4.1 -- Estimated CO2 Response to Fuel Prices

in this exercise we will use the findings of the previous exercises and estimate the $CO_2$ response curves to changing fuel prices. 

In this exercise we will estimate the $CO_2$ respone curve to changing fuel prices. We will construct a response for each `interconnection` seperatly

Our goal is to plot a response curve 

As a side note, the code isn't meant to be the shortest or the most efficient, but should allow you to follow the steps to get the desired result. We will split the analysis in the different interconnections we presented in a previous exercise


In this exercise we will expand our results from the previous exercise and estimate the $CO_{2}$ respone to changing fuel prices. 
To summarise the results from last exercises and to understand why we do certain methods this way, lets summarise. In exercise ?.? we showed that it makes sense to split our analysis in different connection. 

Getting the results we want isn't so easy, but we will take it step by step. First we will 


The model incorporates the findings of previous exercises. Lets look at a quick summary:

We seperate the model in each interconnection
.
.


In this and the following exercise we combine the model theory we introduced in section 3 with the background knowledge of section 2. First, we will estimate $CO_2$ response curves to changing fuel prices. 






In the following exercises, we want to derive the environmental damages caused by electric cars and analyze them. This will allow us to compare gasoline and electric vehicle damages later on. Our approach to compute electric vehicle damages involves several steps:

First, we determine how much energy an electric car uses to drive one mile. As the energy consumption of electric vehicles is dependent on the outside air temperature, we perform a temperature adjustment to get more realistic values.

Second, we estimate the emissions caused by the consumption of an additional kilowatt hour of electricity in a specific area. To do so, we perform an econometric analysis using data on the load in the different areas and emission data from U.S. power plants.

Third, I explain how these emissions can be mapped into monetary damages using an integrated assessment model called the AP2 model.

Fourth, we assume an electric vehicle charging profile and combine the results from the previous exercises.

Last, we analyze the resulting electric vehicle damage values.

Let's get started.





As a side note, the code isn't meant to be the shortest or the most efficient, but should allow you to understand every we take to get our final results. Based on the results of `exercise 4` we will split the analysis in `each` interconnection. Based on this we will explain and carry out the analysis step by step for interconnection `EAST`, afterwards apply it to `ERCOT` and `WECC` and interpret our results.




In this exercise we will estimate the $CO_2$ response curve to `changing` fuel prices. 


Building upon the model we defined in the last chapter, we will expand our regression model with several control variables as followed. The meaning and source of data to every variable is explained in the info box below:


We will perform a reduced-form regression based in the theory of mapping carbon we introduced in exercise `?????` and cubic splines from exercise `3.2`.

$$\tag{5}CO_{2t}=s(priceratio_{t}|\beta)+s(load_{t}|\theta) + s(temp_t|\omega)+X_t\psi+D_\gamma+\epsilon_t$$


***

### Info: Model variables
$CO_{2t}$: CO2 emissions in tons  
$priceratio_{t}$: Capacity weighted average daily gas price per interconnetion ($ per million BTU)  
$load_{t}$: daily electricity consumption per interconnection in MWH  
$temp_{t}$: average daily temperature per interconnection  
$X_{t}$: Factors like non-fossil electricity production (e.g. solar, hydro or wind), $SO_{2}$ price, net imports of electricity from Canada and variance in load  
$D_\gamma$: Dummy variable for seasonal variation to absorb fluctuations, e.g. by renewable energies.

***


First, as in every exercise we have to import our data set. Following we will perform a number of manipulations on the data frame to be able to run our regression model and predict the response curves.


**Task:** Load the dataframe and store it in `dat`. Create a new variable called `priceratio` and calculate the ratio $priceratio=\frac{C_{coal}}{C_{gas}}$. To save us another step, we will also create the seasonable dummy variable. 
```{r "4_1__34",message=FALSE}
dat <- read_csv("Data/main_data.csv")  %>% 
       mutate(priceratio = coalprice/gasprice,
              season=(month>3) + (month>6) + (month>9),
              yearseason=year*10+season)
basecoal=2.25
basegas=5.75

head(dat)
```

**Task:** Filter the data set for intercn `EAST`.
```{r "4_1__35"}
#east <- filter(...,...)
east <- filter(dat, intercn=="EAST")
```

**Task:** Calculate the `mean` of every variable we use in our regression. First, select the necessary columns and then use `summarise_all` to get the `mean`. Store the result in `mean_dat_east`.
```{r "4_1__36"}
# ... <- east %>% 
#  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
#  summarise_all(...)
mean_east <- east %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)
```


**Task:** To make our life a bit easier we will create a new data set with `gasprice`, `priceratio` and the results of the `last` task. Use `tibble()`, which creates a new data frame and `cbind()`, which takes a sequence of columns and combines them with another data frame.

```{r "4_1__37"}
#temp_east <- ...(gasprice = east$gasprice, priceratio = east$priceratio) %>% 
#  ...(mean_east)
predict_east <- tibble(date=east$date, intercn=east$intercn, gasprice = east$gasprice, coalprice=east$coalprice, priceratio = east$priceratio) %>% 
  cbind(mean_east)
```

Our data are now ready to be used on our model. We have the necessary data for our regression model in the data set `east` and afterwards we can predict `emissions` with the help of data in `mean_dat_east`.



**Task:** Perform the regression model we described in the beginning of this exercise for interconnection `EAST`. Use `ns()` for variables with spline regression (as explained in `3.3`). We want to use `5` degrees of freedom. Store the resulting model in `reg_east`.
```{r "4_1__38"}
#... <- lm(co2mass ~ ...(priceratio, df=...) + ...(load, df=...) + tlsd + tlmin + tlmax + ...(meant, df=...) + nonfossil + so2price + netNSflow + yearseason, data=east)
reg_east <- lm(co2mass ~ ns(priceratio, df=5) + ns(load, df=5) + tlsd + tlmin + tlmax + ns(meant, df=5) + nonfossil + so2price + netNSflow + yearseason, data=east)
```

**Task:** Predict $CO_2$ emissions based on the regression model `reg_east` and `temp_east`. We set interval to `confidence` to get the mean interval and be able to plot a confidence band later on.
Just press *check*.


***

### Info: Confidence interval
A confidence interval answers the question for which defined probability the data points lie within the interval. Mathematically, given we have observations $x_1...x_n$ and a confidence level $\gamma$, a confidence interval has a probability $\gamma$ to contain the true underlying parameter. Most commonly, and also in our case, we use
the 95% confidence interval and is defined as: 

$$\hat{y_h} ± t_{\alpha/2,n-2} \sqrt{MSE \frac{1}{n}+\frac{(x_k-\overline{x})^2}{\sum x_i-\overline{x}^2)}}$$
where $\hat{\gamma}$ is the fitted response, $t_{\alpha/2,n-2}$ the t-value with n-2 degrees of freedom and the equation inside the square root represents the standard error.

***


```{r "4_1__39"}
fit_east <- predict_east %>% 
  cbind(as.data.frame(predict(reg_east, newdata = predict_east, interval = 'confidence')))


#co2.east$fit
#temp_east = temp_east %>% cbind(as.data.frame(predict(reg_east, newdata = temp_east, interval = 'confidence')))
```

**Task:** Just press *check*.
```{r "4_1__40"}
diff_base <- abs(east$priceratio - (basecoal/basegas))
min_dif <- min(diff_base)
closest <- min_dif==diff_base
base_emit <- mean(fit_east$fit[which(closest)])

final_east <- fit_east %>% 
  mutate(fit.transformed=fit/base_emit-1,
         lwr.transformed=lwr/base_emit-1,
         upr.transformed=upr/base_emit-1)
```

**Task:** Just press *check*.
```{r "4_1__41",warning=FALSE, fig.width=7, fig.height=7}
plot_east <- ggplot(final_east, aes(x=basecoal/priceratio, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = final_east$lwr.transformed, ymax = final_east$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5,) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  labs(title="Eastern Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()

plot_east
```

TEXT////



**Task:** Run the code for the `ERCOT` interconnection. Just press *check*.
```{r "4_1__42",warning=FALSE, fig.width=7, fig.height=7}
ercot <- filter(dat, intercn=="ERCOT")

mean_ercot <- ercot %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)

predict_ercot <- tibble(date=ercot$date, intercn=ercot$intercn, gasprice = ercot$gasprice, coalprice=ercot$coalprice, priceratio = ercot$priceratio) %>% cbind(mean_ercot)

reg_ercot <- lm(co2mass ~ ns(priceratio, df=5) + ns(load, df=5) + tlsd + tlmin + tlmax + ns(meant, df=5) + nonfossil + so2price + netNSflow + yearseason, data=ercot)

#ERCOT has no net imports of electricity, predict throws warning
fit_ercot <- predict_ercot %>% 
  cbind(as.data.frame(predict(reg_ercot, newdata = predict_ercot, interval = 'confidence')))

#base_emit <- mean(fit_ercot$fit[which(min(abs(ercot$priceratio - (basecoal/basegas)))==abs(ercot$priceratio - (basecoal/basegas)))])

diff_base <- abs(ercot$priceratio - (basecoal/basegas))
min_dif <- min(diff_base)
closest <- min_dif==diff_base
base_emit <- mean(fit_ercot$fit[which(closest)])

final_ercot <- fit_ercot %>% 
  mutate(fit.transformed=fit/base_emit-1,
         lwr.transformed=lwr/base_emit-1,
         upr.transformed=upr/base_emit-1)


plot_ercot <- ggplot(final_ercot, aes(x=basecoal/priceratio, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = final_ercot$lwr.transformed, ymax = final_ercot$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  labs(title="ERCOT Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()
```

**Task:** Run the code for the `WECC` interconnection. Just press *check*.
```{r "4_1__43",warning=FALSE, fig.width=7, fig.height=7}
wecc <- filter(dat, intercn=="WECC")

mean_wecc <- wecc %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)

predict_wecc <- tibble(date=wecc$date, intercn=wecc$intercn, gasprice = wecc$gasprice, coalprice=wecc$coalprice, priceratio = wecc$priceratio) %>% cbind(mean_wecc)

reg_wecc <- lm(co2mass ~ ns(priceratio, df=5) + ns(load, df=5) + tlsd + tlmin + tlmax + ns(meant, df=5) + nonfossil + so2price + netNSflow + yearseason, data=wecc)

#ERCOT has no net imports of electricity (netNSflow=0), predict throws warning
fit_wecc <- predict_wecc %>% 
  cbind(as.data.frame(predict(reg_wecc, newdata = predict_wecc, interval = 'confidence')))

base_emit <- mean(fit_wecc$fit[which(min(abs(wecc$priceratio - (basecoal/basegas)))==abs(wecc$priceratio - (basecoal/basegas)))])

final_wecc <- fit_wecc %>% 
  mutate(fit.transformed=fit/base_emit-1,
         lwr.transformed=lwr/base_emit-1,
         upr.transformed=upr/base_emit-1)

plot_wecc <- ggplot(final_wecc, aes(x=basecoal/priceratio, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = final_wecc$lwr.transformed, ymax = final_wecc$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  labs(title="Western Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()
```

**Task:** Use grid.arrange() to display the plots next to each other. Just press *check*.

```{r "4_1__44",warning=FALSE, fig.width=14, fig.height=7}
grid.arrange(plot_east, plot_ercot, plot_wecc,  nrow=1)
```


//TEXT, east oben, hier verlgeich zu ercot, wecc






///////// test
```{r "4_1__45"}

main_data2 <- rbind(final_east, final_ercot, final_wecc)
main_data2 <- main_data2[order(as.Date(main_data2$date, format="%d/%m/%Y")),]
write.csv(main_data2, "X:\\libraries\\RTutor_BA\\main_data2.csv", row.names = FALSE)
temp <- read_csv("main_data2.csv")

```





***

### Award: Sp(l)ine Surgeon
This was a critical operation, but you mastered it! Keep going, the hardest part is over.

***



In the next exercise we will map the emission response curves from this exercise into carbon prices and estimate the effects of carbon prices on emissions.

## Exercise 4.2 --  Imputed CO2 Response to Carbon Prices

During exercise `4.1`, we have seen that $CO_2$ emissions could be greatly reduced when changing fuel prices of `gas` and `coal`. We already introduced the theory behind mapping carbon in prices in
exercise `2`. In this exercise we will follow the analysis of Cullen (2016) and transform the priceratio of the two commodities into `carbon prices`. This will allow us to estimate the approximate
costs of emission reductions. We split this exercise in two parts, first we will transform the results we gathered in exercise `4.1`

This exercise is split into 2 parts. In the first part we will transform price ratios into carbon prices and plot our result similiar to exercise `4.1`. In the second part we will adopt fixed carbon taxes, derive emission reductions based on our model and estimate the costs.

To calculate carbon prices we can rearrange equation ? from exercise ? to express them as a function of price ratios and baseline prices of gas and coal. This will lead to the following equation:


expand formula 2 into 
we introduced this in section 2, here again:

$$\tag{2}priceratio=\frac{C_{coal}}{C_{gas}}=\frac{P_{coal}+CO_{2,coal}\cdot P_{co2}}{P_{gas}+CO_{2,gas}\cdot P_{co2}}$$




$$\tag{6}{P_{co2}}=\frac{CR\cdot{P_{gas}}-{P_{coal}}}{CO_{2,coal}-CR\cdot CO_{2,gas}}$$

In a first step we have to agree on a baseline level of fuel prices as well as carbon content of each fuel type. We use the same baseline prices as in the previous exercise. The  `U.S. Energy Information Administration` (https://www.eia.gov/tools/faqs/faq.php?id=73&t=11) reports the carbon content:

- Average delivered coal price `$2.25/mmBTU` and gas prices `$5.75/mmBTU` for 2025.
- Carbon content `Natural Gas`: 117 lbs carbon/MMBTU or `0.0585 tons/MMBTU`
- Carbon content `Coal`: 210.8 lbs carbon/MMBTU or `0.1054 tons/MMBTU` (averaged on weighted fuel consumption according to EIA Form 923)


We will continue to use the results from exercise `4.1`. To avoid repeating the same steps as before, I prepared a data frame that includes the predicted `emissions` as well as the `tranformed emissions` with confidence intervals. Load the data set `main_data2.csv` and store it in `dat`. `Head()` will show you the first rows. To save us some time, we also declare the variables as described above.

**Task:** Just press *check*.
```{r "4_2__46",message=FALSE}
dat <- read_csv("Data/main_data2.csv")
head(dat,3)

basegas <- 5.75
basecoal <- 2.25
gas_cc <- 0.0585
coal_cc <- 0.1054
```

As we have all needed data now, we can calculate the carbon taxes in the next step. We will get negative tax values because of our method, therefore we will filter them out. It would't make much
sense for us here to consider negative taxes.

**Task:** Create a column `carbontax` using `Equation 6` and filter the just calculated taxes for the interval [0,80]. Save the result into data frame `tax` and display the first rows.
```{r "4_2__47",message=FALSE}
#tax <- dat %>% 
#  mutate(carbontax = (priceratio*basegas-basecoal)/(coal_cc-priceratio*gas_cc)) %>% 
#  filter(carbontax >= ... & carbontax <= ...)
#
#head(...,...)
#tax <- dat %>% 
##  mutate(carbontax = (priceratio*basegas-basecoal)/(coal_cc-priceratio*gas_cc)) %>% 
# filter(carbontax >= 0 & carbontax <= 80)


tax <- dat %>% 
  mutate(carbontax = (priceratio*basegas-basecoal)/(0.1054-priceratio*0.0585)) %>% 
  filter(carbontax >= 0 & carbontax <= 80)

head(tax,3)
```

The overall approach is similar to the one in exercise `4.1`. We will filter for each interconnection seperatly and plot our result with `ggplot2`. First we will create a plot for interconnection
`EAST` and interpret the results. Afterwards we will run the code on the other interconnections and compare them to another. In contrast to exercise `4.1` though, we won't plot the emission change,
but the abated $CO_2$ emissions.

**Task:** Filter the data frame `tax` for interconnection `EAST` and save it to `tax_east`. Since we filter for a string, don't forget to put quotes around the argument.
```{r "4_2__48"}
#
tax_east <- filter(tax, intercn=="EAST")
```

**Task:** Just press *check*.
```{r "4_2__49",fig.width=7, fig.height=7}
plot_east <- ggplot(tax_east, aes(x=carbontax, y=-fit.transformed)) +
  geom_ribbon(aes_string(ymin = -tax_east$lwr.transformed, ymax = -tax_east$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=-fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.01,0.15)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Eastern Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="y=Carbon Price $/ton")  +
  coord_flip()

plot_east
```

///////TEXT

**Task:** Run the code for the `ERCOT` interconnection. Just press *check*.
```{r "4_2__50",fig.width=7, fig.height=7}
tax_ercot <- filter(tax, intercn=="ERCOT")

plot_ercot <- ggplot(tax_ercot, aes(x=carbontax, y=-fit.transformed)) +
  geom_ribbon(aes_string(ymin = -tax_ercot$lwr.transformed, ymax = -tax_ercot$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=-fit.transformed)) +  
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.01,0.15)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Ercot Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="y=Carbon Price $/ton") + 
  coord_flip()
```

**Task:** Run the code for the `WECC` interconnection. Just press *check*.
```{r "4_2__51",fig.width=7, fig.height=7}
tax_wecc <- filter(tax, intercn=="WECC")

plot_wecc <- ggplot(tax_wecc, aes(x=carbontax, y=-fit.transformed)) +
  geom_ribbon(aes_string(ymin = -tax_wecc$lwr.transformed, ymax = -tax_wecc$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=-fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.01,0.15)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Western Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="y=Carbon Price $/ton") + 
  coord_flip()
```
&nbsp;

Quiz: As shown in an earlier exercise, interconnection `ERCOT` has higher generation of renewable energies than `EAST`. Do you expect `ERCOT` to have a higher or lower emission abatement in comparison to `EAST`?

- higher [ ]

- lower [x]


&nbsp;  
  
**Task:** Just press *check*.
```{r "4_2__52",fig.width=21, fig.height=7}
grid.arrange(plot_east, plot_ercot, plot_wecc, nrow=1)
```





***

### Award: ?
?

***






**Task:** Just press *check*.
```{r "4_2__53"}
find_closest_value <- function(a) {
  vector <- 1:9
  for(i in 0:8){
   vector[i+1] = mean(a$fit[which.min(abs(a$carbontax - i*10))])
  }
  return(vector)
}
temp1 = data.frame(tax=seq(0,80,10),east_emission=round(find_closest_value(tax_east)/100000,1), ercot_emission=round(find_closest_value(tax_ercot)/100000,1), wecc_emission=round(find_closest_value(tax_wecc)/100000,1))

temp2 <- temp1 %>% 
  mutate(perc_east=round((1-temp1$east_emission/temp1$east_emission[1])*100,1),
         perc_ercot=round((1-temp1$ercot_emission/temp1$ercot_emission[1])*100,1),
         perc_wecc=round((1-temp1$wecc_emission/temp1$wecc_emission[1])*100,1),
         emission_all=east_emission+ercot_emission+wecc_emission)

temp3 <- temp2 %>% 
  mutate(perc_all=round((1-temp2$emission_all/temp2$emission[1])*100,1))
  
table <- temp3 %>%
  select(c(1,2,5,3,6,4,7,8,9)) %>%
  kable(format="html", col.names = c("Tax","abs.","%","abs.","%","abs.","%","abs.","%"), align="c", caption = "Precited Emissions and Percentage Abatement") %>%
  add_header_above(c(" "=1, "East" = 2, "ERCOT" = 2, "West" = 2, "Total" = 2)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), position = "center", full_width = F)%>%
  #column_spec(1:9, width = "0.4") %>%
  footnote(general = "Predicted emission are in 100.000 tons/day. Change to baseline (Tax=0).")

table
```


The result corresponds to Table 2 in Cullen(2016). 




Concluding, our results seem to be robust  to parameter changes.

## Exercise 5 -- Conclusion


```{r "5__54"}
awards()
```


The methods used here can be further used to generate additoinal results. This could be a point where you can go on.




## Exercise 6 -- Bonus - Robutness Tests

//// einschub robustness test mit anderen definition von priceratios , appendix a2< number of knots NUR FUER EAST, danach kurz interpretieren


```{r "6__55",optional=TRUE}
# show that all integers between 0 and 10
1:10
```



```{r "6__56",optional=TRUE}
# show that all integers between 0 and 10
1:10
```




## Exercise References


### Bibliography

- Cullen, Joseph A., and Erin T. Mansur. 2017. "Inferring Carbon Abatement Costs in Electricity Markets: A Revealed Preference Approach Using the Shale Revolution." American Economic Journal: Economic Policy, 9 (3): 106-33.

- Lafrancois, B. A. (2012), ‘A lot left over: Reducing CO2 emissions in the United States’ electric power sector through the use of natural gas’, Energy Policy 50, 428–435.


/add literature

### R Packages

- Auguie, B. (2017): gridExtra: "Functions in Grid graphics", R package version 2.3, http://cran.r-project.org/web/packages/gridExtra/index.html

- Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables. R package version 5.2.2. https://CRAN.R-project.org/package=stargazer 

- Kranz, S. (2015): RTutor. "Creating R problem sets with automatic assessment of student's solutions", R package version 2019.10.11, https://github.com/skranz/RTutor

- Rudis, B. (2017): ggalt: "Extra Coordinate Systems, 'Geoms', Statistical Transformations, Scales and Fonts for 'ggplot2'", R package version 0.4.0, https://cran.r-project.org/web/packages/ggalt/index.html

- Wickham, H. (2016): ggplot2. "Elegant Graphics for Data Analysis", Springer-Verlag, New York, R package version 3.2.1, http://CRAN.R-project.org/package=ggplot2

- Wickham, H., Francois, R., Henry, L., Muller, K., (2018): dplyr. "A Grammar of Data Manipulation", R package version 0.8.3, http://CRAN.R-project.org/package=dplyr

- Zhu, H. (2019), kableExtra: "Construct Complex Table with 'kable' and Pipe Syntax", R package version 1.1.0, https://cran.r-project.org/web/packages/kableExtra/index.html

/// add packages, "splines", "regtools", "ggalt?" ,"kable"
 
### Data Sources

- European Environment Agency, "Primary Energy Consumption by Fuel", https://www.eea.europa.eu/data-and-maps/indicators/primary-energy-consumption-by-fuel-6/assessment-2

- Federal Energy Regulatory Comission, "Form  No. 714 Annual Electric Balancing Authority Area
and Planning Area Report", https://www.ferc.gov/docs-filing/forms/form-714/data.asp

- Government of Canada, "Canada Energy Regulator", https://www.cer-rec.gc.ca/bts/ctrg/gnnb/lctrctxprts/index-eng.html

- Intercontinental Exchange, "Commodity Prices", https://www.theice.com/marketdata/reports

- National Centers for environmental Information (NOAA), Climate data, https://www.ncdc.noaa.gov/cag/statewide/time-series

- The World Bank , "Commodity Markets Monthly Prices",  https://www.worldbank.org/en/research/commodity-markets

- United States Environmental Protection Agency, "SO2 Trading Program", https://ampd.epa.gov/ampd/

- U.S. Energy Information Administration, "Form EIA-923", https://www.eia.gov/electricity/data/eia923/

- U.S. Energy Information Administration, "Today in Energy", https://www.eia.gov/todayinenergy/detail.php?id=43035


*All of the above links were accessable as of March 31, 2020.*

