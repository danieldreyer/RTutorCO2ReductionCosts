# Problem Set: Estimating CO2 Reduction Costs

Author: Daniel Dreyer

#< ignore
```{r ""}
library(restorepoint)
# facilitates error detection
# set.restore.point.options(display.restore.point=TRUE)
library(RTutor)
library(yaml)
#library(restorepoint)
setwd("X:/libraries/RTutor_BA")
ps.name = "CarbonReductionCosts"; sol.file = paste0(ps.name,"_sol.Rmd")
libs = c("dplyr", "ggplot2", "gridExtra", "stargazer", "tidyverse", "ggalt",  "splines", "kableExtra") # character vector of all packages you load in the problem set
name.rmd.chunks(sol.file) # set auto chunk names in this file
create.ps(sol.file=sol.file, ps.name=ps.name, user.name=NULL,libs=libs, stop.when.finished=FALSE, addons="quiz") # extra.code.file="dp.R", var.txt.file ="variables.txt")
show.shiny.ps(ps.name, load.sav=FALSE,  sample.solution=TRUE, is.solved=TRUE, catch.errors=TRUE, launch.browser=TRUE)
stop.without.error()
rtutor.package.skel(sol.file=sol.file, ps.name=ps.name,libs=libs,
                    pkg.name="RTutorCarbonReductionCosts",   # Name of the problem set package
                    pkg.parent.dir = "X:/libraries/RTutor_BA", # Parent directory 
                    author="Daniel Dreyer", # Your name
                    github.user="daniel.dreyer",     # Your github user name
                    extra.code.file="dp.R", # name of extra.code.file
                    var.txt.file="variables.txt",    # name of var.txt.file
                    overwrite=FALSE  # Do you want to override if package directory exists?
)
```
#>

<style>
img {
    display: block;
    margin-left: auto;
    margin-right: auto;
    max-width: 100%;
}
</style>

Welcome to this `Interactive Problem Set`. The world's energy demand are constantly increasing and at the same time so are carbon emission. High efforts are made to find technological improvement as well as find economic incentives to avoid long term effects of climate change through high emission. During this problem set, you will examine how carbon pricing would effect emissions in the U.S. electricity sector. 
The analysis is based on **"Inferring Carbon Abatement Costs in Electricity Markets: A Revealed Preference Approach using the Shale Revolution"** by Joseph A. Cullen, Erin T. Mansur (2016) - further referred as Cullen (2016). You can find the paper and further ressources here: <a href="https://www.aeaweb.org/articles?id=10.1257/pol.20150388   target = "_blank"> https://www.aeaweb.org/articles?id=10.1257/pol.20150388</a>

____ ergebnisse ____

We replicate the analysis proposed by Cullen (2016) with the help of the `Statstical Programming Language R`. I will explain important function along the way, but you are required to have basic knowledge of `Statistics` and `R`. If you are completely new to programming in `R` you should't feel left behind though. Understanding the basic concepts are pretty straight forward, you can find useful beginners guide [here](https://cran.r-project.org/manuals.html). Below you will find an overview of content and a guideline on how to deal with our interactive problems.  


### Contents


Text

$\qquad$  Overview
  
$\qquad$  1 TBA

$\qquad$  2 TBA

$\qquad$ $\qquad$ 2.1 

$\qquad$  3 TBA

$\qquad$  4 TBA

$\qquad$  5 Conclusion

$\qquad$ References


## Exercise Content


$\qquad$ *Exercise 1* - Motivation (rename later)

$\qquad$ *Exercise 2* - TBA

$\qquad$ *Exercise 3* - TBA

$\qquad$ *Exercise 4* - TBA

$\qquad$ *Exercise 5* - TBA


### ReadME


The problem set offers different ways of interaction. Some provide you additional information or test your knowledge, others need you to fill in small gaps of code. Coding exercises are marked as **TASK**. Below you can read find the different types of interactions with their corresponding functions:   

 - *Info Boxes*: Contain additional information on technical terms or documentation of functions.
 
 - *Quizzes*: Evaluate your knownledge of topics before we dive in our analysis.
 
 - *Code Chunks*: Require you to complete small parts of Code. The work flow of solving code chunks is intuitive and as followed:
                
  + `edit` : Click to start editing the Code chunk.
  + `run chunk`: Runs the chunk and displays outputs or errors in the corresponding console.
  + `check`: Check your input against the solution.
  + `hint` : You can request a hint if you have problem solving a task.  
&nbsp;

  
  Additional functions:    
                   
  + `data`: Redirects you to the data browser - you can navigate through the data set in an interface.
  + `solution` : Shows the solution of the task.  
&nbsp;


After finishing a exercise, click `Go to next exercise` at the bottom or navigate around with the help of the bar on top.


## Exercise 1 -- Insights into Energy Markets

Energy consumption of the world keeps rising daily. New technologies are being developed to produce `green` electricity, but we are still heavily dependant on `fossil fuels`. Coal is hereby one of the biggest and most important sources of energy, but at the same time the biggest cause of carbon emissions. It is easy to store, to transport, doesn't alter and can be mined in huge quantities all around the world. This makes it desirable and cheap to use as a reliable energy source. Given that coal supplies will last for centuries, it is a major goal to find incentitives to reduce its use and therefore emissions.
Another major energy ressource is `natural gas`. Even though still being a fossil fuel, its' emissions and heat density are way superior to coal. Nevertheless, natural gas wasn't considered to be an real alternative to coal because of higher costs through difficult extracting methods and handling.  
This changed due to the `Shale Revolution`, which started in the early 2000s in the United States. Natural gas began to not only be a by-product of the oil industry, but could now be extracted in large quantities and in a targeted manner. Lanfrancois (2012) estimates, that based on the `Clean Power Plan` introduced by the Obama Administration in 2015, carbon dioxide emissions from the electricity industry could be reduced by roughly 23 to 42 percent by replacing existing coal to gas fired generators.    
  
#< info "Shale-Revolution"
Shale gas is a form of natural gas and is extracted from shale formation, a technology known as fracking. Since the start of this century, shale gas became a increasingly more popular form of natural gas in the United States. Whereas in the year 2000 shale gas only provided 1% of extracted natural gas in the U.S., nowadays it makes up roughly 50%. The long term effects on the environment however are highly unceratin and heavily debated.  

You can find further information on this topic below:  
<a href="https://en.wikipedia.org/wiki/Shale_ga   target = "_blank"> https://en.wikipedia.org/wiki/Shale_gas</a>s  
<a href="https://en.wikipedia.org/wiki/Hydraulic_fracturing   target = "_blank"> https://en.wikipedia.org/wiki/Hydraulic_fracturing</a>
#>
  
Enough background for now, let's start with some interactive tasks. In `Exercise 1` we will get a feeling for the energy sector and explore time-series data of historic prices and generated power.

**Task:**
Use the `read_csv` command to *load the data set* and store it in a variable called `dat`. `Read_csv` displays the parsed type of each column after you execute the command. This will come handy later on in this exercise. In future exercises we will diable this message.

#< info "read.csv() and write.csv()"
The command `read_csv()` reads in a **csv file** and stores it into a given name. Csv is a format for data, that uses commas as seperators and periods as decimals. Another version of are **csv2 files**, where semicolons are used for seperators and commas for decimals. We only use csv files in this problem set.

Given the file you want to read it is in the same working directory, you can use the command below:

```{r "1",eval=FALSE}
example <- read_csv("example.csv")
```

If the file is saved outside of your working directory you have to differentiate between two possibilities.  
For files that are "above" your current working directory, you have to provide the full path to the file. You can view your working directory with `getwd()`:

```{r "1__2",eval=FALSE}
example <- read_csv("C:/Data/example.csv")
```

For files that are located "below" the working directory it is sufficient to specify the file path starting with your current working directory:

```{r "1__3",eval=FALSE}
example <- read_csv("./Data/example.csv")
```

Csv files can be saved using the `write_csv` command:

```{r "1__4",eval=FALSE}
write_csv(example, file="example.csv")
```

For further information, use `help(write_csv)`.
#>

```{r "1__5"}
#< task
# ... <- read_csv("./Data/exercise1.csv")
#>
dat <- read_csv("./Data/exercise1.csv")
#< hint
display("Replace the variable name with the one given in the exercise description. No other changes are needed.")
#>
```

**Task:** The first thing you should do after loading a new data set is looking at the structure. Use the `head()` command to show the first **eight** rows of the data set named `dat`.  

When not given a second argument, `head()` displays the first 5 rows on default. Alternatively, the problem set provides a seperate data tab. If you want to take a closer look at the data, especially later on in the problem set, you can click `data` and get redirected to the `Data Explorer` Tab, where you can navigate along the data frame and see some basic statistics.  

```{r "1__6"}
#< task
# head(dat, ...)
#>
head(dat, 8)
#< hint
display("The second input parameter defines the number of row that are shown. Replace ... with the number from the task description.")
#>
```

The data frame contains monthly numbers of generated MWh of coal and gas as well as prices of `natural gas` in Europe and the United States as well as the `natural gas index` from the year 2002 to the end of 2019. Keep in mind that different commodities are traded in different units. Coal in metric tons (`\$/mt`) and gas in British thermal units (`$/mmBTU`). The natural gas index is set to 100 in the year 2010 and changes accordingly. 
While reading in our current data set I mentioned that it would come handy to know which data types your columns inherit. `R` requires `dates` to be stored as type `Date`, otherwise we will get weird outputs when trying to plot along a time line. The date column is currently stored as type `character`. Therefore  we have to convert the date variable into a `date format` by using `as.Date()`.

**Task:**  Transform the data type with `as.Date()` and store the transformed variable to the same name.
```{r "1__7"}
#< task
# ... <- ...(dat$date, format="%m/%d/%Y")
#>
dat$date <- as.Date(dat$date, format="%m/%d/%Y")
#< hint
display("Convert the column dat$date into a date format using as.Date(). Store the result in the same column.")
#>
```

Now that we imported our data set, got a first look on its structure and data, lets start creating our first plot. Basic `R` is the way to go if you want some quick visualisations. Additionally, `R` provides several packages to create highly customizable plots. In this problem set we will mostly use the package `ggplot2`. It is widely considered to be one of the most powerful packages to create plots, but having the downside that you have to get used to the handling. Because of that this proble mset doesn't require you to create whole plots on your own but requires you to fill in gaps. This way you will learn how the logic behind `ggplot2` works and at the same time won't be frustrated if the output doesn't meet the requirements.  
  
The first plot we create should tell us more about the development of gas prices along the time frame. As we have mentioned at the beginning of this exercise, the `Shale-Revolution` started in the beginning of this century. Therefore we expect falling gas prices for the U.S. market. Since commodity prices are split for regions/markets, the European Gas price should differ. Let's see if these assumptions are true.
  
**Task:** Use the data frame `dat` to plot historic prices of gas in Europe and the United States. Just press *check*.

#< info "ggplot2"
The package `ggplot2` is a powerful data visualization package for `R`, which is part of the `tidyverse` environment. Besides basic functions that are also provided by native `R`, it allows the user to
highly modify graphs by **altering**, **adding** or **removing** components.

You are not required to have deeper knowledge about the functionality of `ggplot2`. However, you can find further documentation [here](https://ggplot2.tidyverse.org/) or type `help(ggplot2)`.
#>
```{r "1__8",fig.width=9, fig.height=6, dev='svg'}
#< task_notest
ggplot(data=dat, aes(x=date)) +
  geom_line(aes(y=dat$price_naturalgas_USA, color="Gas US"), size=1) +
  geom_line(aes(y=dat$price_naturalgas_Europe, color="Gas Europe"), size=1) +
  labs(x = "Year", y = "", title = "Natural Gas Prices", subtitle = "Y=$/mmBTU")+
  scale_color_manual(name="Region",values = c("blue","red"))
#>
```

Looking at the plot our assumptions are confirmed. The spikes in 2005 and 2008 are mostly consequences of the iraq war and the financial crisis. Apart from that, we observe a strict fall of gas prices in the U.S. from just over $12 in 2008 to under \$2 in 2016. Since ten the prices remained at roughly the same level. Natural gas prices in Europe have remained at a significantly higher level. One reason being is that fracking isn't as popular in Europe, therefore a major part of gas in Europe gets imported from Russia which drives prices. On the other hand Europe has a different energy mix. According to the European Environment Agency (EEA) the consumption of gas decreased in average by 1.4% per year since 2005, whereas in the U.S. natural gas reached new all-time highs nearly every year. Because of the lack of data provided by state officials in Europe, the analysis in this problem set will further purely focus on the U.S. market.

Before getting an insight into the generated power, take your first quiz:

#< quiz "Proportion of Sectors"
question: Do you think that the proportion of gas generated electicity compared to coal generated electricity has increased or decreased over time?

sc:
    - increased*
    - decreased
success: Great, your answer is correct!
failure: Try again.
#>  
&nbsp;

**Task:** Create a new `ggplot2` for electricity generation. Plot the `date` on the x-Axisand the generated electricity on the y-Axis. We want seperate line for `gas generated power` as well as `coal generated power`. Lines are drawn with `geom_line`. For reference you can look at the code from the previous graph or conduct the `help()` function.

```{r "1__9",fig.width=9, fig.height=6, dev='svg'}
#< task
#ggplot(data=___, aes(x=___)) +
#  ____(aes(_=dat$generated_coal, color="Coal Generation (TWh)"), size=1, alpha=0.5) +
#  ____(aes(_=dat$generated_gas, color="Natural Gas Generation (TWh)"), size=1, alpha=0.5) +
#  labs(x = "Year", y = "", title = "Monthly Generation by Fueltype", subtitle = "Y=Monthly Electricty (TWh)")+
#  scale_color_manual(name="",values = c("black","red"))+
#  scale_y_continuous(breaks=seq(0,200,25))
ggplot(data=dat, aes(x=date)) +
  geom_line(aes(y=dat$generated_coal, color="Coal Generation (TWh)"), size=1, alpha=0.5) +
  geom_line(aes(y=dat$generated_gas, color="Natural Gas Generation (TWh)"), size=1, alpha=0.5) +
  labs(x = "Year", y = "", title = "Monthly Generation by Fueltype", subtitle = "Y=Monthly Electricty (TWh)")+
  scale_color_manual(name="",values = c("black","red"))+
  scale_y_continuous(breaks=seq(0,200,25))
#>
```

The results are in line with what we should expect. With gas decreasing in price, gas plants increased their share in electricity production over time. Giving you a bit more background, coal-fired plants have lower operating costs than gas-fired generators, but are slow to adjust to fluctating demands and are expensive to start. Gas generators typically fill these gaps. There are two different types of gas-generators, one being `peaker plants`, which run in high demand hours due to their fast start-up times but high marginal costs. The other type being `combined cycle gas turbines` (CCGT), having low heat rates (high efficiency of turning fuel into power) and are used to provide baseline power generation throughout the day. Because of these factors we can assume that the two types of fuel generators are "switchable".  
However, the mechanism called `fuel switching` is a lot more complex than just about changing fuel prices. Factors like capacity of plants, transmission grid limits (Mansur & White 2012, Davis & Hausman 2015) or firms market power (Bushnell, Mansur & Saravia 2008) also play a role here. We try to include some but not all of them in our analysis later on.  
To wrap this up, we observe severe fluctuations, that occur yearly with a smaller peak in summer and a bigger in the winter season. The fluctuation are largely driven by Residential using air conditioning in summer and space heating in winter (EIA, "Today in Energy", 2020/3).  
  
#< award "Artist"
You created your first plot! You will earn more awards throughout the problem set. After you completed all exercises you will see how many awards you got.
#>

In the next exercise we will go through necessary theory for our main analysis. Click `Go to next exercise` to continue.


## Exercise 2 -- Theory

### Relationship between Fuel and Carbon Prices

#< info "Variable names in this exercise"
$MC$: Marginal Costs  
$HR$: Heat Rate, mmBTU/MWh  
$C_{coal}$: Cost of burning coal  
$C_{gas}$: Cost of burning gas  
$P_{coal}$: Coal Price, $/mmBTU  
$P_{gas}$: Gas Price, $/mmBTU  
$CO_{2,coal}$: Carbon content of coal, tons/mmBTU  
$CO_{2,gas}$: Carbon content of gas, tons/mmBTU  
$P_{co2}$: Carbon Price , $/ton
#>

As seen in the last exercise there are more factors to `marginal costs` than just the commodity prices itself. With that in mind we define the `marginal costs` of fossil-powered plants as a Equation of `heat rate` and the `costs of burning fuel`. Variable names of this exercise are explained in the info-box above:

$$\tag{1}MC=HR\cdot(P_{fuel}+CO_{2,fuel}\cdot P_{co2})=HR\cdot C_{fuel}$$

In `Exercise 1` we observed generated electricity of `coal` and `gas` and their variance over time. Because of the fact that the cost efficiency of coal is generally better, we have to introduce a incentive to reduce the use of coal in relation to gas in electricity generation. One way to introdude a change in cost efficiency is to propose `carbon prices`. This is especially viable in this case because coal contains approximately `twice` as much $CO_2$ as natural gas and therefore stronger effects the cost efficiency. Another factor that drives this momentum is that gas generators generally have a more efficient heat rate than coal generators (as metioned at the end of last exercise).  
Combining these two facts of cost and generation efficiency lead to `steeper marginal cost` for coal generators when carbon prices are introduced. Reflecting this to our upcoming analysis, we don't observe any carbon prices, but a time-series of fuel prices that are transformed into burning costs with equation `(1)`. To implement the mechanism of `fuel change` we introduce a `coal-gas ratio`, which we define as followed:

$$\tag{2}costratio=\frac{C_{coal}}{C_{gas}}$$

Combining Equation `1` and `2`, we can explain `cost ratios` as a function of `fuel prices`, `carbon content` and `carbon prices`:

$$\tag{3}costratio=\frac{C_{coal}}{C_{gas}}=\frac{P_{coal}+CO_{2,coal}\cdot P_{co2}}{P_{gas}+CO_{2,gas}\cdot P_{co2}}$$

For completeness we introduce values for carbon content $CO_{2,coal}$ and  $P_{fuel}$, that will be fixed based on predictions for the year 2025. The `EIA` reports carbon content and forcasts for fuel prices. We will use these values later on in our analysis:  

- Average delivered coal price `$2.25/mmBTU` and gas prices `$5.75/mmBTU` (forcast for 2025)
- Carbon content `Natural Gas`: 117 lbs carbon/MMBTU or `0.0585 tons/MMBTU`  
- Carbon content `Coal`: 210.8 lbs carbon/MMBTU or `0.1054 tons/MMBTU`  

Lets quickly interpret `Equation 2`: The `price ratio` will rise for higher `costs of burning coal` or lower `costs of burning gas`. To make this even clearer, lets visualize the relationship, which replicates Figure 4 of Cullen.

<img src="./Material/relationship.png" alt="drawing" width="600"/>
Source: Cullen (2016)  
  
Panel `(a)` shows the relationship between fixed costs of `coal` and `gas` when `carbon prices` get introduced. As shown before we observe higher marginal costs for coal and at a certain value of carbon prices, gas becomes more cost efficient. Panel `(c)` shows the results when transforming fuel prices in price ratios as defined in `Equation 2`. We can observe the same in absence of carbon prices with fixed coal prices and variable gas prices as seen in panel `(b)` and `(d)`. 

#< quiz "carbon prices"
question: Do you think we can create any given price ratio under the assumption that we introduce carbon prices under fixed fuel prices? The answer is basically shown in the graphs above.
sc:
    - Yes*
    - No
success: Great, your answer is correct!
failure: Try again.
#>  
&nbsp;

The answer is the central idea to our analysis. We can create every variation of cost ratios, either by introducing `carbon prices` to fixed fuel prices, or without carbon prices by varying costs of `coal` and `gas`. We use this variation in the cost ratios observed in our data to understand how emissions change when gas generators become more competitive with coal plants (Cullen 2016). 

$$\tag{4}{P_{co2}}=\frac{costratio\cdot{P_{gas}}-{P_{coal}}}{CO_{2,coal}-costratio\cdot CO_{2,gas}}$$

We will use this equation in the second part of the analysis (`4.2`) to transform our fuel costs into carbon prices. Therefore we will be able to predict the impact of carbon taxes on emissions and calculate abatement costs.  
  
<br/><br/>
  
Since it is not common to have electricity grid in Europe that are formed like the ones in the United States, I will introduce the concept of interconnection in the following sub-section.

### Interconnections

<img src="./Material/interconnections.png" alt="drawing" width="600"/>
Source: Cullen (2016)

The American Electric system is made up of three major `interconnections`, which in turn concist of different balancing authorities (responsible for maintaining the electricity balance within the region). Local electricity grids are hereby connected to form a network, which provides higher stablity and reliability. These `interconnections` operate mostly independent from each other and exchange little to no electricity. This is a huge difference to the European electricity grid, where grid stability is ensured across borders.

In the graph below you can see the `3` interconnection we include data of in this problem set. I listed a few details for each below:
- `Eastern Interconnection (EAST)`: Consists of 36 balancing authorities and extends from the East Coast to the Rocky Mountains.
- `Western Interconnection (WECC)`: Involves 37 balancing authorities, which are located in the West of North America.
- `Electric Reliability Council of Texas` (ERCOT): Consists of large parts of Texas

In the first part of this exercise we already hinted that our model will we some form of regression of price ratios against emissions. Since we are essentially observing three different energy markets we should confirm the distribution of our data points. Therefore we create a graph that plots all price ratios within our data set against $CO_2$ emissions. We run the model seperately on each interconnection if find a large distribution across interconnections. We will present the data set for the analysis in detail in upcoming exercises. For not it's enough to get an impression on the distribution.

**Task:** Just press *check*.

#< info "geom_encircle"
`Geom_encircle()` is part of the package `ggalt` which extends functionality of `ggplot2`. Besides standard functionality for plotting points or lines that is provided by basic `ggplot2`, it provides a advanced framework for visualising your data. `Geom_encircle()` automatically encloses points in a polygon and can be used to visualise differences in groups of data.

Call `help(geom_encircle)` to get further information.
#>

```{r "2"}
#< task_notest
dat <- read_csv("Data/exercise3.csv")
ggplot(dat,aes(x=coalprice/gasprice,y=co2mass/1000,color=intercn))+
        geom_point(alpha=0.2) +
        geom_encircle(aes(group=intercn,fill=intercn),alpha=0.3, s_shape=1) +
        theme_bw()+ 
        labs(y="", 
        x="Price Ratio", 
        subtitle="y=CO2 Emissions in 1000 tons/day",
        title="Distribution of data")
#>
```

As you can the distribution of data point for the `Eastern` interconnection is way different than the other two interconnections. We could probably find a model that fits `ERCOT` and `WECC`, but its unlikely to fit well for `EAST`. Because of this we will perform our analysis on each `interconnection` seperately. 

#< award "Theorist"
You learned about the necessary theory. You are ready to start with the analysis!
#>

In the next chapter we will begin constructing a model that will implement the theory we introduced in this exercise. Click `Go to next exercise`.

## Exercise 3.1 -- Emission Response Curves - A simple approach

A short recapture: We got an idea about fuel shares in the U.S. energy market and introduced `interconnection`. Furthermore we introduced the concept of `fuel switching` and necessary theory behind mapping carbon pricing. In `Chapter 3` we will combine these findings and start developing a regression model. We will start by proposing a simple linear regression, analyze the statistics and work our way along to a fitting model.

If you are purely interested in the final model and the economic impact, you can skip to `Exercise 4.1`. `Chapter 3` will focus on regression theory, which will guide you to a fitting model.

**Task:** To get started, load the data set `exercise3.csv`, press `edit` and `check` afterwards.

```{r "3_1",message=FALSE}
#< task_notest
dat <- read_csv("Data/exercise3.csv")
head(dat,3)
#>
```

The data frame consists of daily data with the following columns:

`co2mass`: $CO_2$ emissions in tons  
`gasprice`: Capacity weighted average daily gas price per interconnetion ($ per million BTU)  
`coalprice`: Price of Coal ($ per million BTU)  
`load`: daily electricity consumption per interconnection in MWh  

In `Exercise 2` we saw that it makes sense for us to run our model on each `interconnection` seperatly. For this purpose we will filter our data set for interconnection `EAST` and build the model based on these data. Once we found a fitting model we will run it on each interconnection. Additionally we observed substantial variation in coal and gas prices at the beginning of this problem set and therefore defined a `cost ratio` in the previous exercise.  
Before we start with modelling we have to alter our data set with the implications from above. First we have to filter for interconnection `EAST` and then create a new column that calculates our price ratio. For reference I will include the formula once more.

**Task:** The data set contains a column `intercn` with values `EAST`, `WEST` and `ERCOT`. Filter the data set for interconnection `EAST` and store the new data frame in variable `dat_east`. Additionally, calculate the cost ratio between `coalprice` and `gasprice` according to formula 2.

#< info "Pipe, mutate, select"
The pipe operator `%>%` is a feature provided by the `dplyr` Package. Essentially it allows to exectute multiple operation on a dataframe at once.
This works the way that every pipe operator returns a dataframe and passes it to the next connected function. `Select` allows you to filter out certain columns of data, whereas `mutate` allows you to
alter data. The counterpart for selecting specific rows is `filter`. There are several more functions to alter your data, below i linked a handy cheatsheet.
  
```{r "3_1__2",eval=FALSE}
example %>% 
  select(1:5) %>%  # keep certain columns from index 1 to 5  
  mutate(new_column = old_column+1) # create or alter columns   

```

You can find a more detailed cheatsheet [here](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) or use the `help()` function.
#>

```{r "3_1__3"}
#< task
# ... <- data %>% 
#  mutate(CR = .../...) %>% 
#  filter(intercn=="...")
#>
dat_east <- dat %>% 
  mutate(priceratio = coalprice/gasprice) %>%
  filter(intercn=="EAST")
#< hint
display("Replace the variable name with the one given in the exercise description and filter for EAST.")
#>
```


### Stage 1: Linear Regression

We start by proposing a simple linear regression model. In a mathematical way we can express the relationship as followed:

$$\tag{3}CO_{2t}=\beta_{0}+\beta_{1}\cdot priceratio_{t}$$


#< info "Linear Regression with lm()"

`lm()` is part of the `stats` package and loaded on default. As shown in the syntax example below, it enables you to regress `y` on the indepedent variables `x1` and `x2`. The model can be `stored` in a variable or directly `used` in other functions. Another popular function to solve linear regressions in `R` is `felm()`, that provides further functionality to include `fixed effects`. In this problem set we will strictly use `lm()`.

```{r "3_1__4",eval=FALSE}
example <- lm(y~x1+x2, data=dat_east)
```

You can find more information on the `lm()` function [here](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm) or use the `help()` function.
#>

**Task:** Run a regression with `co2mass` as the dependent variable and `priceratio` as independent variable. Store it in the variable `fit1`. 
```{r "3_1__5"}
#< task
# ... <- lm(...~... , data=east)
#>
fit <- lm(co2mass ~ priceratio, data=dat_east)
#< hint
display("Fill in the variables given in the description. The dependent variable is the variable we want to explain.")
#>
```

#< quiz "Reg1"
question: What impact do changing price ratios have on emissions?

sc:
    - With increasing price ratios emissions will increase.
    - With increasing price ratios emissions will fall.*
success: Great, your answer is correct!
failure: Try again.
#>  


TEXT

**Task:** To
```{r "3_1__6"}
#< task_notest
summary(fit)
#>
```

$\beta_{1}$

The summary statistics shows as a positive value for priceratio $\beta_{1}$, which means that a increasing price ratio decreases emissions.


For upcoming regressions we will use the `stargazer()` function from the `stargazer` package to show summary statistics from our regressions. We don't need get every information the basic functions displays, therefore we define a own custom function with statistics we need. Read below to find out more about `stargazer` and `custom functions` and continue with the next `task`.

#< info "Stargazer"
`stargazer` provides specialised `HTML` formatting for regression tables and summary statistics tables. It is easy to use, supports a large number of model types and formats data in a more pleasing way. The basic function is called by `stargazer()`, but can be customized heavily. For more information run `help(stargazer)` or read further [here](https://cran.r-project.org/web/packages/stargazer/).
#>

#< info "Custom functions"
`R` provides an easy framework to add your own functions. The syntax is quite similar to other `Programming Languages` you could be familiar with. Once you have defined a function, you can use it as long as you are in the same session. Below you can find the basic structure of a function:

```{r "3_1__7",eval=FALSE}
`myfunction <- function(arg1, arg2, ... ){`  
`statements`  
`return(object)`  
```  
Here's an simple functions that adds `5` to the input and returns it.
```{r "3_1__8",eval=FALSE}
`example <- function(x) {`  
  `x + 5`  
`}`  
`example(1)`
```  
You can find more detailed information [here](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/function).

#>

**Task:** Click check to run the Code. It defines the function to show our custom regression tables.
```{r "3_1__9"}
#< task_notest
show.regression= function(...){
  library(stargazer)
    stargazer(..., 
            type = "text", 
            style = "aer",  
            digits = 3,
            df = FALSE,
            report = "vct*",
            star.cutoffs = c(0.05, 0.01, 0.001),
            model.names = FALSE,
            object.names = TRUE,
            model.numbers = FALSE, 
            omit.stat=c("f", "ser")
    )
} 
show.regression(fit)
#>
```

Our eventual goal is to plot the rensponse curves of changing ??AWD prices 

#< info "Predict"
`predict()`
#>

**Task:** To
```{r "3_1__10"}
p1 <- predict(fit, newdata = dat_east)
```




**Task:** To
```{r "3_1__11"}
plot(co2mass~priceratio, dat_east)
lines(dat_east$priceratio, p1, col="red")
```




**Task:** Let's see what we just defined. Run the regression table for the linear model. Insert 
```{r "3_1__12"}
#< task
# regression.result(...)
#>
show.regression(fit)
#< hint
display("Insert the name of the model you defined at the beginning of this exercise.")
#>
```

TEXT

**Task:** To
```{r "3_1__13"}
plot(fit, 1)
plot(fit, 2)
```

QQ PLOT RESIDUALS?

#< info "R-squared"
`R-Squared` is a statistical measurement that represents the correlation between `fitted values` and `observed values`. `R-squared` is always positive and ranges from 0 to 1. A value closer to 1 indicates that the suggested model explains a majority of the variance in the outcome variable.  
$R^{2}=1-\frac{Explained Variation}{Total Variation}$
A problem with the `R-squared` measurement is, that it always increases with higher numbers of variables in the model, even if these variables are only weakly responsible for the predicted values. An solution is to take the number of variables into account, this is called `Adjusted R-Squared` and also shown in the summary output.
#>

RMSE?

### Stage 2: Polynomial Regression

**Task:** Just press *check*.
```{r "3_1__14"}
CR.squared <- east$CR^2
fit2 <- lm(CO2MASS ~ CR + CR.squared, east)

CR.cubed <- east$CR^3
fit3 <- lm(CO2MASS ~ CR + + CR.squared + CR.cubed, east)
```

**Task:** Just press *check*.
```{r "3_1__15"}
p2 <- predict(fit2, east)
p3 <- predict(fit3, east)
```

**Task:** Just press *check*.
```{r "3_1__16"}
plot(CO2MASS~CR, east)
lines(east$CR, p1, col="red")
lines(east$CR, p2, col="blue")
lines(east$CR, p3, col="green")
```

**Task:** Just press *check*.
```{r "3_1__17"}
regression.result(fit, fit2, fit3)
```

**Task:** Just press *check*.
```{r "3_1__18"}
anova(fit, fit2, fit3)
```



## Exercise 3.2 -- Restricted Spline Regressions

### Stage 3: Cubic Spline





simple cubic splines

$$\tag{4}CO_{2t}=s(CR_{t}|\beta)$$

#< info "ns()" 
`Ns()` is part of the `splines` package and allows us to perform natural splines regressions on our data. It takes several input arguments, the only one we will use is `df` which sets the degrees of freedom. 
#>

WIP



#< award "Linear Regression Expert"
TEXT
#>


## Exercise 4 -- 

To this point we got an idea about the energy market in the U.S. and the theory needed to construct a model that will set carbon pricess in relation to carbon emissions. In this chapter we will 

Until now we worked with data sets that only include a portion of what we will use in our final model. Therefore we will use this exercise to present the data we use for our analysis and give an overview what we will be doing in the following exercises. 



answer this we will construct a statistical model to understand the emission behaviour for changing input costs while controlling
for variables that effect the energy market. However we won't simply propose a final model but will work our way from simple linear regressions to more complex but also more accurate models.  
&nbsp;

 - You can find a rough guideline of content in each exercise below:
  + `Exercise 4.1` - Estimated CO2 Response to Fuel Prices
  + `Exercise 4.2` - Imputed CO2 Response to Carbon Prices
&nbsp;
  
Before we head into our analysis we should make us familiar with the data we will be using. Up until now we constructed models with at most 2 dependent variables. In our final model we will add several control variables  
Before we take a look at the data, import our dataset.

**Task:** Load the data set `main_data.csv`, press `edit` and `check` afterwards.

```{r "4",message=FALSE}
#< task_notest
dat <- read_csv("Data/main_data.csv")
head(dat,3)
#>
```
&nbsp;

The data frame is a combination of data we used previous exercises and additional factors. It consists of `daily` information for `each interconnection` from 2006 to 2012. The meaning of each column is explained below:

`co2mass`: $CO_2$ emissions in tons  
`gasprice`: Capacity weighted average daily gas price per interconnetion ($ per million BTU)  
`coalprice`: Price of Coal ($ per million BTU)  
`load`: daily electricity consumption per interconnection in MWH  
`meant`: average daily temperature per interconnection  
`nonFossil`: Electricity generation with non-fossil fuel in MWH  
`so2price`: Permit prices of $SO_2$ ($/ton)  
`netNSflow`: MwH flowing from Canada to US by interconnection and month  

The data are gathered from several official U.S. agencies and aggregated to a daily level and seperated by interconnection. Because of the size of these data sets we wont do the data preparation in this problem set but rather provide the data sources. `Emission` data are measured by the Continuous Emissions Monitoring System (CEMS) of the `Environmental Protection Agency (EPA)`. The U.S. Energy Information Administration (EIA) collects data of `Non-fossil` energy production as well as spot prices of `coal prices` in Form 923. Spot prices of `gas` can be found in `Intercontinental Exchange (ICE)`. Data of `electricity consumption` or `load` are provided in Form 714 of the `Federal Energy Regulatory Commission (FERC)`, permit prices of $SO_2$ from the `EPA Clean Air Markets` and finally, `net imports` of electricity from Canada are gathered from the `National Energy Board of Canada`. Links to the sources can be found in the `References` section.

To give us an overview of the data, lets create a table with average values for relevant factors of each interconnection. `Dyplr` provides 


R provides several packages for that , but for now we work with packages we
introduced before and solve this with `dyplr`.  

**Task:** Use `group_by()` to group the dataset `dat` by `intercn`. Afterwards use `summarise_all()` to calculate the means of every column. You don't have to deal with the additional lines of code, which is used to create a more understandable output.

#< info "Group_by() and summarise()"
`Group_by()` allows you to group a data frame by specific variables. Operations that are run on the grouped data frame are then performed on each group.

The function `Summarise()` is run on **grouped data** and can perform operations e.g. calculating means (`mean()`) or finding minimums (`min()`). There are several
pre-implemented version of `summarise` functions in `R`. The one we use here is `summarise_all()`, which performs these operations on all columns.

To give you an example in code form, lets pretend we have a dataframe `data` with several `car manufacturer` and their respective car models with `prices` and we want to calculate the average car price per manufacturer.

```{r "4__2",eval=FALSE}
example <- data %>% 
  group_by(manufacturer) %>%
  summarise(mean_price = mean(price))
```

Call `help(group_by)` or `help(summarize)` for further information.
#>
  
#< info "kable()"
hallo hier entsteht eine info box
#>

///Tabelle mit einheiten

```{r "4__3"}
#< task
#... %>% 
#  select(intercn, co2mass, load, gasprice, coalprice) %>% 
#  group_by(...) %>% 
#  ...("mean") %>% 
#  mutate(co2mass = co2mass/1000, load=load/1000, "Emission Rate"=co2mass/load, "Cost Ratio"=coalprice/gasprice) %>% 
#  rename("CO2 Emissions"=co2mass, Load=load, "Gas Price"=gasprice, "Coal Price"=coalprice)
#>
dat %>% 
  select(intercn, co2mass, load, gasprice, coalprice, nonfossil) %>% 
  group_by(intercn) %>% 
  mutate(co2mass = co2mass/1000, load=load/1000, "Price Ratio"=coalprice/gasprice, "Emission Rate"=co2mass/load, nonfossil=nonfossil/100000) %>% 
  summarise_all("mean") %>% 
  rename("Interconnection"=intercn, "CO2 Emissions"=co2mass, Load=load, "Gas Price"=gasprice, "Coal Price"=coalprice, "Non fossil"=nonfossil)
```

The table replicates `Table 1` from Cullen (2016) and reports the mean of several factors for each `interconnection`. We can clearly see that the East is by far the largest of the observed energy
markets. The emissions seem to increase proportionally to the electricity consumption if we take the electricity production from non-fossil sources in consideration. This gets clearer if the look at
the emission rates, which are defined as $ER=\frac{emissions}{load}$. Therefore the `Western` interconnection has by far the `cleanest` energy production, followed with some distance by Texas (`ERCOT`)
and the `Eastern` interconnection. Furthermore we observe clear variations in price ratios.  
This is in line with our assumptions from `Section 2`, where we stated that each interconnection has vastly different conditions and therefore should conduct our regression on each seperatly. In the next exercise we will use this data set and the regression theory we presented in `Chapter 3` to trace out the emission response curves.

#< award "?"
wip
#>

Click `Go to next exercise` to continue.

## Exercise 4.1 -- Estimated CO2 Response to Fuel Prices

in this exercise we will combine the theory of `exercise 2` and regression theory of `chapter 3` to estimate the $CO_2$ response curves to changing fuel prices. To summarise what we got so far lets do a quick summary. In `exercise 2` we introduced the theory of mapping carbon prices to our cost ratios. In `exercise 3` we introduced the theory of cubic splines which we will use for our final model.
As a side note, the code isn't meant to be the shortest or the most efficient, but should allow you to follow each step we take to get our final results. Based on this we will explain and carry out the analysis step by step for interconnection `EAST`, afterwards apply it to `ERCOT` and `WECC` and interpret our results.

Building upon the model we defined in the last chapter, we will expand our regression model with several control variables as followed. The meaning and source of data to every variable is explained in the info box below:


We will perform a reduced-form regression which expands the cubic spline regression from exercise `3.2` and builds upon the theory of `exercise 2`. We define the model as followed:

$$\tag{5}CO_{2t}=s(priceratio_{t}|\beta)+s(load_{t}|\theta) + s(temp_t|\omega)+X_t\psi+D_\gamma+\epsilon_t$$

#< info "Model variables" 
$CO_{2t}$: CO2 emissions in tons  
$priceratio_{t}$: Capacity weighted average daily gas price per interconnetion ($ per million BTU)  
$load_{t}$: daily electricity consumption per interconnection in MWH  
$temp_{t}$: average daily temperature per interconnection  
$X_{t}$: Factors like non-fossil electricity production (e.g. solar, hydro or wind), $SO_{2}$ price, net imports of electricity from Canada and variance in load  
$D_\gamma$: Dummy variable for seasonal variation to absorb fluctuations, e.g. by renewable energies.
#>

The first step as in every exercise is loading our data set. 

**Task:** Load the dataframe and store it in `dat`. Create a new variable called `priceratio` and calculate the ratio $priceratio=\frac{C_{coal}}{C_{gas}}$. To save us another step, we will also create the seasonable dummy variable. 
```{r "4_1",message=FALSE}
dat <- read_csv("Data/main_data.csv")  %>% 
       mutate(priceratio = coalprice/gasprice,
              season=(month>3) + (month>6) + (month>9),
              yearseason=year*10+season)
basecoal=2.25
basegas=5.75

head(dat)
```

**Task:** Filter the data set for intercn `EAST`.
```{r "4_1__2"}
#< task
#east <- filter(...,...)
#>
east <- filter(dat, intercn=="EAST")
#< hint
display("Filter() takes a data frame as first argument and a logic as second. We want to filter for intercn EAST.")
#>
```

**Task:** Calculate the `mean` of every variable we use in our regression. First, select the necessary columns and then use `summarise_all` to get the `mean`. Store the result in `mean_dat_east`.
```{r "4_1__3"}
#< task
# ... <- east %>% 
#  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
#  summarise_all(...)
#>
mean_east <- east %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)
#< hint
display("In this case, you can insert the mathematical operation directly into summarise_all().")
#>
```


**Task:** To make our life a bit easier we will create a new data set with `gasprice`, `priceratio` and the results of the `last` task. Use `tibble()`, which creates a new data frame and `cbind()`, which takes a sequence of columns and combines them with another data frame.

```{r "4_1__4"}
#< task
#temp_east <- ...(gasprice = east$gasprice, priceratio = east$priceratio) %>% 
#  ...(mean_east)
#>
predict_east <- tibble(date=east$date, intercn=east$intercn, gasprice = east$gasprice, coalprice=east$coalprice, priceratio = east$priceratio) %>% 
  cbind(mean_east)
```

**Task:** Perform the regression model we described in the beginning of this exercise for interconnection `EAST`. Use `ns()` for variables with spline regression (as explained in `3.3`). We want to use `5` degrees of freedom. Store the resulting model in `reg_east`.
```{r "4_1__5"}
#< task
#... <- lm(co2mass ~ ...(priceratio, df=...) + ...(load, df=...) + tlsd + tlmin + tlmax + ...(meant, df=...) + nonfossil + so2price + netNSflow + yearseason, data=east)
#>
reg_east <- lm(co2mass ~ ns(priceratio, df=5) + ns(load, df=5) + tlsd + tlmin + tlmax + ns(meant, df=5) + nonfossil + so2price + netNSflow + yearseason, data=east)
```

**Task:** Predict $CO_2$ emissions based on the regression model `reg_east` and `temp_east`. We set interval to `confidence` to get the mean interval and be able to plot a confidence band later on.
Just press *check*.

#< info "Confidence interval" 
A confidence interval answers the question for which defined probability the data points lie within the interval. Mathematically, given we have observations $x_1...x_n$ and a confidence level $\gamma$, a confidence interval has a probability $\gamma$ to contain the true underlying parameter. Most commonly, and also in our case, we use
the 95% confidence interval and is defined as: 

$$\hat{y_h} Â± t_{\alpha/2,n-2} \sqrt{MSE \frac{1}{n}+\frac{(x_k-\overline{x})^2}{\sum x_i-\overline{x}^2)}}$$
where $\hat{\gamma}$ is the fitted response, $t_{\alpha/2,n-2}$ the t-value with n-2 degrees of freedom and the equation inside the square root represents the standard error.
#>

```{r "4_1__6"}
#< task_notest
fit_east <- predict_east %>% 
  cbind(as.data.frame(predict(reg_east, newdata = predict_east, interval = 'confidence')))
#>
```

**Task:** Just press *check*.
```{r "4_1__7"}
diff_base <- abs(east$priceratio - (basecoal/basegas))
min_dif <- min(diff_base)
closest <- min_dif==diff_base
base_emit <- mean(fit_east$fit[which(closest)])

final_east <- fit_east %>% 
  mutate(fit.transformed=fit/base_emit-1,
         lwr.transformed=lwr/base_emit-1,
         upr.transformed=upr/base_emit-1)
```

**Task:** Just press *check*.
```{r "4_1__8",warning=FALSE, fig.width=7, fig.height=7}
#< task_notest
plot_east <- ggplot(final_east, aes(x=basecoal/priceratio, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = final_east$lwr.transformed, ymax = final_east$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5,) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  labs(title="Eastern Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()

plot_east
#>
```

TEXT////



**Task:** Run the code for the `ERCOT` interconnection. Just press *check*.
```{r "4_1__9",warning=FALSE, fig.width=7, fig.height=7}
#< task_notest
ercot <- filter(dat, intercn=="ERCOT")

mean_ercot <- ercot %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)

predict_ercot <- tibble(date=ercot$date, intercn=ercot$intercn, gasprice = ercot$gasprice, coalprice=ercot$coalprice, priceratio = ercot$priceratio) %>% cbind(mean_ercot)

reg_ercot <- lm(co2mass ~ ns(priceratio, df=5) + ns(load, df=5) + tlsd + tlmin + tlmax + ns(meant, df=5) + nonfossil + so2price + netNSflow + yearseason, data=ercot)

#ERCOT has no net imports of electricity, predict throws warning
fit_ercot <- predict_ercot %>% 
  cbind(as.data.frame(predict(reg_ercot, newdata = predict_ercot, interval = 'confidence')))

diff_base <- abs(ercot$priceratio - (basecoal/basegas))
min_dif <- min(diff_base)
closest <- min_dif==diff_base
base_emit <- mean(fit_ercot$fit[which(closest)])

final_ercot <- fit_ercot %>% 
  mutate(fit.transformed=fit/base_emit-1,
         lwr.transformed=lwr/base_emit-1,
         upr.transformed=upr/base_emit-1)


plot_ercot <- ggplot(final_ercot, aes(x=basecoal/priceratio, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = final_ercot$lwr.transformed, ymax = final_ercot$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  labs(title="ERCOT Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()
#>
```

**Task:** Run the code for the `WECC` interconnection. Just press *check*.
```{r "4_1__10",warning=FALSE, fig.width=7, fig.height=7}
#< task_notest
wecc <- filter(dat, intercn=="WECC")

mean_wecc <- wecc %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)

predict_wecc <- tibble(date=wecc$date, intercn=wecc$intercn, gasprice = wecc$gasprice, coalprice=wecc$coalprice, priceratio = wecc$priceratio) %>% cbind(mean_wecc)

reg_wecc <- lm(co2mass ~ ns(priceratio, df=5) + ns(load, df=5) + tlsd + tlmin + tlmax + ns(meant, df=5) + nonfossil + so2price + netNSflow + yearseason, data=wecc)

fit_wecc <- predict_wecc %>% 
  cbind(as.data.frame(predict(reg_wecc, newdata = predict_wecc, interval = 'confidence')))

base_emit <- mean(fit_wecc$fit[which(min(abs(wecc$priceratio - (basecoal/basegas)))==abs(wecc$priceratio - (basecoal/basegas)))])

final_wecc <- fit_wecc %>% 
  mutate(fit.transformed=fit/base_emit-1,
         lwr.transformed=lwr/base_emit-1,
         upr.transformed=upr/base_emit-1)

plot_wecc <- ggplot(final_wecc, aes(x=basecoal/priceratio, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = final_wecc$lwr.transformed, ymax = final_wecc$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  labs(title="Western Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()
#>
```

**Task:** Use grid.arrange() to display the plots next to each other. Just press *check*.

```{r "4_1__11",warning=FALSE, fig.width=14, fig.height=7}
grid.arrange(plot_east, plot_ercot, plot_wecc,  nrow=1)
```


//TEXT, east oben, hier verlgeich zu ercot, wecc






///////// test
```{r "4_1__12"}

main_data2 <- rbind(final_east, final_ercot, final_wecc)
main_data2 <- main_data2[order(as.Date(main_data2$date, format="%d/%m/%Y")),]
write.csv(main_data2, "X:\\libraries\\RTutor_BA\\main_data2.csv", row.names = FALSE)
temp <- read_csv("main_data2.csv")

```




#< award "Sp(l)ine Surgeon"
This was a critical operation, but you mastered it! Keep going, the hardest part is over.
#>

In the next exercise we will map the emission response curves from this exercise into carbon prices and estimate the effects of carbon prices on emissions as well as the associated costs. Click `Go to next exercise` to continue.


## Exercise 4.2 --  Imputed CO2 Response to Carbon Prices

During exercise `4.1`, we have seen that $CO_2$ emissions could be greatly reduced when changing fuel prices of `coal` and `gas`. We already introduced the theory behind mapping carbon in prices in exercise `2`. In this exercise we will follow the analysis of Cullen (2016) and transform the priceratio of the two commodities into `carbon prices`. This will allow us to estimate the change in emission with certain carbon taxes and approximate costs of these emission reductions. We split this exercise in two logical parts, first we will transform the results we gathered in exercise `4.1` with the help of `Equation 3`. Afterwards we will plot the emission response curves on carbon taxes.

For reference or when you decided to skip to this exercise I once again include the equation. Additionally we will use the same values for baseline fuel prices and carbon content as introduced in `exercise 2` and used in `exercise 4.1`.

$$\tag{3}{P_{co2}}=\frac{CR\cdot{P_{gas}}-{P_{coal}}}{CO_{2,coal}-CR\cdot CO_{2,gas}}$$

- Average delivered coal price `$2.25/mmBTU` and gas prices `$5.75/mmBTU` for 2025. 
- Carbon content `Natural Gas`: 117 lbs carbon/MMBTU or `0.0585 tons/MMBTU`
- Carbon content `Coal`: 210.8 lbs carbon/MMBTU or `0.1054 tons/MMBTU` (averaged on weighted fuel consumption according to EIA Form 923)


As mentioned the goal of this exercise is to transform the response curves of exercise `4.1` into emission abatement curves. To avoid repeating the same steps as before, I prepared a data frame that includes the predicted `emissions` as well as the `tranformed emissions` with confidence intervals. Load the data set `main_data2.csv` and store it in `dat`. `Head()` will show you the first rows. To save us some time, we also declare the fixed values as described above.

**Task:** Just press *check*.
```{r "4_2",message=FALSE}
#< task_notest
dat <- read_csv("Data/main_data2.csv")
head(dat,3)

basegas <- 5.75
basecoal <- 2.25
gas_cc <- 0.0585
coal_cc <- 0.1054
#>
```

As we have all needed data now, we can calculate the carbon taxes in the next step. We will get negative tax values because of our method, therefore we will filter them out. It would't make much
sense for us here to consider negative taxes.

**Task:** Create a column `carbontax` using `Equation 3` and filter the just calculated taxes for the interval [0,80]. Save the result into data frame `tax` and display the first rows.
```{r "4_2__2",message=FALSE}
#< task
#... <- dat %>% 
#  mutate(carbontax = (priceratio*...-...)/(coal_cc-priceratio*gas_cc)) %>% 
#  filter(carbontax >= ... & carbontax <= ...)
#
#head(...,...)
#>
tax <- dat %>% 
  mutate(carbontax = (priceratio*basegas-basecoal)/(0.1054-priceratio*0.0585)) %>% 
  filter(carbontax >= 0 & carbontax <= 80)

head(tax,3)
#< hint
display("Following the equation given above to calculate cabon taxes. We want to keep carbon tax rates between 0 and 80, simply insert the numbers. Display the first three rows with head(dataframe, 3).")
#>
```

The overall approach is similar to the one in exercise `4.1`. We will filter for each interconnection seperatly and plot our result with `ggplot2`. First we will create a plot for interconnection
`EAST` and interpret the results. Afterwards we will run the code on the other interconnections and compare them to another. In contrast to exercise `4.1` though, we won't plot the emission change,
but the abated $CO_2$ emissions.

**Task:** Filter the data frame `tax` for interconnection `EAST` and save it to `tax_east`. Since we filter for a string, don't forget to put quotes around the argument.
```{r "4_2__3"}
#< task
#
#>
tax_east <- filter(tax, intercn=="EAST")
#< hint
display("Use filter(dataset,filter). We want to filter for interconnection EAST.")
#>
```

**Task:** Just press *check*.
```{r "4_2__4",fig.width=7, fig.height=7}
#< task_notest
plot_east <- ggplot(tax_east, aes(x=carbontax, y=-fit.transformed)) +
  geom_ribbon(aes_string(ymin = -tax_east$lwr.transformed, ymax = -tax_east$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=-fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.01,0.15)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Eastern Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="y=Carbon Price $/ton")  +
  coord_flip()

plot_east
#>
```

///////TEXT

**Task:** Run the code for the `ERCOT` interconnection. Just press *check*.
```{r "4_2__5",fig.width=7, fig.height=7}
#< task_notest
tax_ercot <- filter(tax, intercn=="ERCOT")

plot_ercot <- ggplot(tax_ercot, aes(x=carbontax, y=-fit.transformed)) +
  geom_ribbon(aes_string(ymin = -tax_ercot$lwr.transformed, ymax = -tax_ercot$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=-fit.transformed)) +  
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.01,0.15)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Ercot Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="y=Carbon Price $/ton") + 
  coord_flip()
#>
```

**Task:** Run the code for the `WECC` interconnection. Just press *check*.
```{r "4_2__6",fig.width=7, fig.height=7}
#< task_notest
tax_wecc <- filter(tax, intercn=="WECC")

plot_wecc <- ggplot(tax_wecc, aes(x=carbontax, y=-fit.transformed)) +
  geom_ribbon(aes_string(ymin = -tax_wecc$lwr.transformed, ymax = -tax_wecc$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=-fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.01,0.15)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Western Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="y=Carbon Price $/ton") + 
  coord_flip()
#>
```
&nbsp;
#< quiz "Compare emission abatement"
question: We have seen in an earlier exercise, that interconnection `ERCOT` has higher generation of renewable energies than `EAST`. Do you expect `ERCOT` to have a higher or lower emission abatement in comparison to `EAST`?

sc:
    - higher
    - lower*
success: Great, your answer is correct!
failure: Try again.
#>  

&nbsp;  
  
**Task:** Just press *check*.
```{r "4_2__7",fig.width=21, fig.height=7}
grid.arrange(plot_east, plot_ercot, plot_wecc, nrow=1)
```

TEXT

#< award "2?"
?
#>


**Task:** Just press *check*.
```{r "4_2__8"}
#< task_notest
find_closest_value <- function(a) {
  vector <- 1:9
  for(i in 0:8){
   vector[i+1] = mean(a$fit[which.min(abs(a$carbontax - i*10))])
  }
  return(vector)
}
temp1 = data.frame(tax=seq(0,80,10),east_emission=round(find_closest_value(tax_east)/100000,1), ercot_emission=round(find_closest_value(tax_ercot)/100000,1), wecc_emission=round(find_closest_value(tax_wecc)/100000,1))

temp2 <- temp1 %>% 
  mutate(perc_east=round((1-temp1$east_emission/temp1$east_emission[1])*100,1),
         perc_ercot=round((1-temp1$ercot_emission/temp1$ercot_emission[1])*100,1),
         perc_wecc=round((1-temp1$wecc_emission/temp1$wecc_emission[1])*100,1),
         emission_all=east_emission+ercot_emission+wecc_emission)

temp3 <- temp2 %>% 
  mutate(perc_all=round((1-temp2$emission_all/temp2$emission[1])*100,1))
  
table <- temp3 %>%
  select(c(1,2,5,3,6,4,7,8,9)) %>%
  kable(format="html", col.names = c("Tax","abs.","%","abs.","%","abs.","%","abs.","%"), align="c", caption = "Precited Emissions and Percentage Abatement") %>%
  add_header_above(c(" "=1, "East" = 2, "ERCOT" = 2, "West" = 2, "Total" = 2)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), position = "center", full_width = F)%>%
  #column_spec(1:9, width = "0.4") %>%
  footnote(general = "Predicted emission are in 100.000 tons/day. Change to baseline (Tax=0).")

table
#>
```


The result corresponds to Table 2 in Cullen(2016). 

TEXT





```{r "4_2__9"}
testvector <- tax_east$carbontax

test <- tax_east %>% 
  mutate(fx1=carbontax,
         fx2=carbontax[+1])



#gen fx1=carbontax
#					gen fx2 = carbontax[_n+1]
#					gen x1 =  base_emit - emithat //the height of the curve when the base emission are the zero line
#					gen x2 =  base_emit -emithat[_n+1] 
#gen area = 0.5*(x2-x1)*(fx2+fx1)
```
















To conclude our analysis we can calculate the abatement costs for certain carbon taxes. Lets say we introduce a carbon tax of `40$/ton`

```{r "4_2__10"}

```

Calculating costs






Concluding, our results seem to be robust  to parameter changes.

## Exercise 5 -- Conclusion


```{r "5"}
#< task
awards()
#>
```


The methods used here can be further used to generate additoinal results. This could be a point where you can go on.




## Exercise 6 -- Bonus - Robutness Tests

//// einschub robustness test mit anderen definition von priceratios , appendix a2< number of knots NUR FUER EAST, danach kurz interpretieren

#! start_note "Robustness Test - andere priceratio"

```{r "6",optional=TRUE}
#< task
# show that all integers between 0 and 10
#>
1:10
```

#! end_note 

#! start_note "Robustness Test - weniger knots"

```{r "6__2",optional=TRUE}
#< task
# show that all integers between 0 and 10
#>
1:10
```

#! end_note 



## Exercise References


### Bibliography

- Cullen, Joseph A., and Erin T. Mansur. 2017. "Inferring Carbon Abatement Costs in Electricity Markets: A Revealed Preference Approach Using the Shale Revolution." American Economic Journal: Economic Policy, 9 (3): 106-33.

- Lafrancois, B. A. (2012), âA lot left over: Reducing CO2 emissions in the United Statesâ electric power sector through the use of natural gasâ, Energy Policy 50, 428â435.


/add literature, exercise 2

### R Packages

- Auguie, B. (2017): gridExtra: "Functions in Grid graphics", R package version 2.3, http://cran.r-project.org/web/packages/gridExtra/index.html

- Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables. R package version 5.2.2. https://CRAN.R-project.org/package=stargazer 

- Kranz, S. (2015): RTutor. "Creating R problem sets with automatic assessment of student's solutions", R package version 2019.10.11, https://github.com/skranz/RTutor

- Rudis, B. (2017): ggalt: "Extra Coordinate Systems, 'Geoms', Statistical Transformations, Scales and Fonts for 'ggplot2'", R package version 0.4.0, https://cran.r-project.org/web/packages/ggalt/index.html

- Wickham, H. (2016): ggplot2. "Elegant Graphics for Data Analysis", Springer-Verlag, New York, R package version 3.2.1, http://CRAN.R-project.org/package=ggplot2

- Wickham, H., Francois, R., Henry, L., Muller, K., (2018): dplyr. "A Grammar of Data Manipulation", R package version 0.8.3, http://CRAN.R-project.org/package=dplyr

- Zhu, H. (2019), kableExtra: "Construct Complex Table with 'kable' and Pipe Syntax", R package version 1.1.0, https://cran.r-project.org/web/packages/kableExtra/index.html

/// add packages, "splines", "regtools", "ggalt?" ,"kable"
 
### Data Sources

- European Environment Agency, "Primary Energy Consumption by Fuel", https://www.eea.europa.eu/data-and-maps/indicators/primary-energy-consumption-by-fuel-6/assessment-2

- Federal Energy Regulatory Comission, "Form  No. 714 Annual Electric Balancing Authority Area
and Planning Area Report", https://www.ferc.gov/docs-filing/forms/form-714/data.asp

- Government of Canada, "Canada Energy Regulator", https://www.cer-rec.gc.ca/bts/ctrg/gnnb/lctrctxprts/index-eng.html

- Intercontinental Exchange, "Commodity Prices", https://www.theice.com/marketdata/reports

- National Centers for environmental Information (NOAA), Climate data, https://www.ncdc.noaa.gov/cag/statewide/time-series

- The World Bank , "Commodity Markets Monthly Prices",  https://www.worldbank.org/en/research/commodity-markets

- United States Environmental Protection Agency, "SO2 Trading Program", https://ampd.epa.gov/ampd/

- U.S. Energy Information Administration, "FAQ", (https://www.eia.gov/tools/faqs/faq.php?id=73&t=11)

- U.S. Energy Information Administration, "Form EIA-923", https://www.eia.gov/electricity/data/eia923/

- U.S. Energy Information Administration, "Today in Energy", https://www.eia.gov/todayinenergy/detail.php?id=43035

*All of the above links were accessable as of March 31, 2020.*

