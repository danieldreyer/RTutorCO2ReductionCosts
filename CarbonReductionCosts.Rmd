
```{r 'check_ps', include=FALSE}

user.name = '' # set to your user name

# To check your problem set, run the 
# RStudio Addin 'Check Problemset'

# Alternatively run the following lines
library(RTutor)
ps.dir = getwd() # directory of this file
ps.file = 'CarbonReductionCosts.Rmd' # name of this file
check.problem.set('CarbonReductionCosts', ps.dir, ps.file, user.name=user.name, reset=FALSE)
```

# Problem Set: Estimating CO2 Reduction Costs

Author: Daniel Dreyer


<style>
img {
    display: block;
    margin-left: auto;
    margin-right: auto;
    max-width: 100%;
}
</style>

Welcome to this `Interactive Problem Set`. During this problem set we will examine the effect of carbon taxes on emissions in the electricity sector. The analysis is based on **"Inferring Carbon Abatement Costs in Electricity Markets: A Revealed Preference Approach using the Shale Revolution"** by Joseph A. Cullen, Erin T. Mansur (2016) - further referred as Cullen. You can downlaod the paper including the author's STATA code from: <a href="https://www.aeaweb.org/articles?id=10.1257/pol.20150388   target = "_blank"> https://www.aeaweb.org/articles?id=10.1257/pol.20150388</a>

____ ergebnisse ____

We will use the statistical programming language `R` to replicate the analyisis proposed by Cullen. I will provide information about concepts and functions along the way, but you are required to have basic knowledge of `Statistics` and `R`. If you are completely new to programming in `R` you should't feel left behind though. Understanding the basic concepts is pretty straight forward, you can find a useful beginners guide [here](https://cran.r-project.org/manuals.html). Below you will find an overview of content and a guideline on how to solve upcoming interactive problems.  

## Exercise Content


$\qquad$ *Exercise 1* - Motivation (rename later)

$\qquad$ *Exercise 2* - TBA

$\qquad$ *Exercise 3* - TBA

$\qquad$ *Exercise 4* - TBA

$\qquad$ *Exercise 5* - TBA


### Instructions


The problem set offers different ways of interaction. Some provide you additional information or test your knowledge, others require you to write your own code snippets. Coding exercises are marked as **TASK**. You are not required to solve exercises in the given order but its recommended. Below you can read find the different types of interactions with their corresponding functions:   

 - *Info Boxes*: Contain additional information on technical terms or documentation of functions.
 
 - *Quizzes*: Evaluate your knownledge of topics before we dive in our analysis.
 
 - *Code Chunks*: Require you to complete small parts of Code. The work flow of solving code chunks is intuitive and as followed:
                
  + `edit` : At the start of each exercise click check to start editing the Code chunk.
  + `run chunk`: Runs the chunk and displays outputs in the corresponding console.
  + `check`: Check your input against the solution.
  + `hint` : You can request a hint if you have problem solving a task.  
&nbsp;

  
  Additional functions:    
                   
  + `data`: Redirects you to the data browser - you can navigate through the data set.
  + `solution` : Displays the solution of the task.  
&nbsp;


After finishing a exercise, click `Go to next exercise` at the bottom or navigate around with the help of the bar on top.


## Exercise 1 -- Insights into Energy Markets

The world has to further reduce it's $CO_2$ emissions in order to meet the requirements of the Paris Convention on Climate Neutrality by 2050. Right now the energy consumption keeps rising daily and even though new technologies are being developed to increase the percentage of `green` electricity, we are still heavily dependant on `fossil fuels`. `Coal` is hereby one of the most important sources of energy, but at the same time the biggest cause of carbon emissions. Reasons being, that it is easy to store, transport, doesn't alter and is mined in large quantities around the world. Given that coal supplies will last for centuries, it is a major goal to find incentitives to reduce it's use and therefore emissions. One solution would be to improve the efficiency of coal-generators, another one to replace it with another fuel type.  
One alternative energy source is `natural gas`, which is obviously also a type of fossil fuel, but it's $CO_2$ emissions and heat density are far more efficient. Nevertheless, natural gas wasn't considered to be an real alternative to coal because of higher costs through more difficult extracting methods and handling.  
This changed with the `Shale Revolution`, which started in the early 2000s in the United States. Natural gas began to not only be a by-product of the oil industry, but could now be extracted in large quantities and in a targeted manner. Lanfrancois (2012) estimates, that based on the `Clean Power Plan` introduced by the Obama Administration in 2015, $CO_2$ emissions from the electricity sector could be reduced by roughly 23 to 42 percent by replacing existing coal to gas fired generators.    
  
info("Shale-Revolution") # Run this line (Strg-Enter) to show info
  
Let's start with some interactive tasks. In `Exercise 1` we will get insights into global energy markets and explore time-series data of historic prices and generated electricity.

**Task:**
Use the `read_csv` function to load the data set `exercise1.csv` and store it in a variable called `dat`. `Read_csv` reports the variable type of each column after execution. This will come handy later on in this exercise. In future exercises we will disable this message.  

info("read.csv() and write.csv()") # Run this line (Strg-Enter) to show info

```{r "1__5"}
# ___ <- read_csv("./Data/exercise1.csv")
```

**Task:** The first thing we should do after loading a new data set is to look at it's structure. Use the `head()` command to display the first **eight** rows of the data set `dat`. When not given a second argument, `head()` displays the first 5 rows on default. Alternatively, you can click on `data` and get redirected to the `Data Explorer` tab, where you can navigate around the data frame and see some basic statistics.

```{r "1__6"}
# head(dat,___)
```

The data frame includes 214 observations of **monthly** data from year 2002 to 2019. It contains generated power in MWh of the U.S. as well as prices for `natural gas` in Europe and the United States. Keep in mind that different commodities are traded in different units, coal in metric tons (`\$/mt`) and gas in million British thermal units (`\$/mmBTU`). 
I mentioned that it would come handy to know which data types our columns inherit (hovering over the column names in the output above will give you the same information). `R` requires `dates` to be stored as type `Date` to be able to create plots along a time line. Since the date column is currently stored as type `character` we have to convert the variable into a `date format` by using `as.Date()`.

**Task:**  Transform the data type with `as.Date()` and save it to the same column.
```{r "1__7"}
# ___ <- ___(___, format="%m/%d/%Y")

```

Now that we imported our data set and processed it for analysis, let's start exploring. First, we create a plot that tells us more about the price development of gas in both regions. Because of the fact that the `Shale-Revolution` started in the beginning of this century, we expect a increasing supply and therefore falling prices for gas in the United States. Since commodity markets are split into regions, the European Prices should somehow differ.  
Besides funtionality that `R` provides on default, there are several packages that let us create highly customizable plots. We will mostly use the package `ggplot2`, which is widely considered to be one of the most powerful packages to create plots, having the downside that the handling can be a bit tricky. Therefore, you aren't required to create entire plots on your own but but to fill in gaps. This way you get used to the logic behind `ggplot2` and at the same time won't get frustrated if your output didn't meet the exact requirements.  
  
**Task:** Use the data frame `dat` to plot `historic prices` of natural gas in `Europe` and the `United States` along `date` on the x-Axis.

info("ggplot2") # Run this line (Strg-Enter) to show info
```{r "1__8",fig.width=9, fig.height=6, dev='svg'}
#ggplot(data=___, aes(x=___)) +
#  geom_line(aes(y=dat$price_naturalgas_USA, color="United States"), size=1) +
#  geom_line(aes(y=dat$price_naturalgas_Europe, color="Europe"), size=1) +
#  labs(x = "Year", y = "", title = "Natural Gas Prices", subtitle = "Y=$/mmBTU")+
#  scale_color_manual(name="Region",values = c("blue","red"))

```

Looking at the plot, our assumptions are confirmed. The spikes in 2005 and 2008 are mostly consequences of the Iraq War and the Financial Crisis. Apart from that, we observe decreasing gas prices in the U.S. from just over \$12 in 2008 to under \$2 in 2016. Since then the prices remained at roughly the same level.  
Natural gas prices in Europe remained at a significantly higher level. One reason being, that fracking isn't as popular in Europe, therefore a major part of gas gets imported from Russia which drives prices. Additionally, Europe has a widely different energy mix in comparison to the United States. According to the European Environment Agency (EEA), the consumption of gas decreased in average by 1.4% per year since 2005, whereas in the U.S. natural gas reached new all-time highs almost every year. 

Besides information of fuel prices, our data frame also provides data for generated power. Before we take a look at the time-series for his, take your first quiz:  

#! addon__quiz__Proportion of Sectors
&nbsp;

**Task:** Create a new `ggplot2` for generated power. Plot the `date` on the x-Axis and the generated electricity on the y-Axis. We want seperate line for `gas generated power` as well as `coal generated power`, which can be added with `geom_line`. For reference you can look at the code from the previous graph or conduct the `help()` function.

```{r "1__9",fig.width=9, fig.height=6, dev='svg'}
#ggplot(data=___, aes(x=___)) +
#  ____(aes(_=dat$generated_coal, color="Coal Generation (TWh)"), size=1, alpha=0.5) +
#  ____(aes(_=dat$generated_gas, color="Natural Gas Generation (TWh)"), size=1, alpha=0.5) +
#  labs(x = "Year", y = "", title = "Monthly Generation by Fueltype", subtitle = "Y=Monthly Electricty (TWh)")+
#  scale_color_manual(name="",values = c("black","red"))+
#  scale_y_continuous(breaks=seq(0,200,25))
ggplot(data=dat, aes(x=date)) +
  geom_line(aes(y=dat$generated_coal, color="Coal Generation (TWh)"), size=1, alpha=0.5) +
  geom_line(aes(y=dat$generated_gas, color="Natural Gas Generation (TWh)"), size=1, alpha=0.5) +
  labs(x = "Year", y = "", title = "Monthly Generation by Fueltype", subtitle = "Y=Monthly Electricty (TWh)")+
  scale_color_manual(name="",values = c("black","red"))+
  scale_y_continuous(breaks=seq(0,200,25))
```

The results are in line with what we should expect. With a higher supply of gas and decreasing prices, gas plants increased their share in power generation over time. Giving you a bit more background information: Coal-fired generators tend to have lower operating costs than gas-fired ones, but are expensive to start and adjust slowly to fluctuating demands. Gas-generators can fill these gaps. There are two different types of gas-generators, The first type are `peaker plants`. They run in high demand hours due to their fast start-up times, but on the downside suffer from high marginal costs. The second type are `combined cycle gas turbines` (CCGT). They have low heat rates (high efficiency of turning fuel into power) and are used to provide baseline power generation throughout the day.  
Combining the factors above, we can say that both fuel-generators have the possiblity to generate power in all situation and meet our needs, meaning that the fuels are `switchable`. However, the mechanism of `fuel switching` is a lot more complex than just about the cost efficiency. We already mentioned some factors above, but capacity of plants, transmission grid limits (Mansur & White 2012, Davis & Hausman 2015) or market power of firms (Bushnell, Mansur & Saravia 2008) also play a big role.    
To wrap this up, we observe severe fluctuations of generated power along the year, that occur with smaller peaks in summer and a bigger ones in winter season. These fluctuation are largely driven by using air conditioning in summer and space heating in winter (EIA, "Today in Energy", 2020/3).  
  

Click `Go to next exercise` to continue.



## Exercise 2 -- Theory

### Relationship between Fuel and Carbon Prices

///// ?
In this exercise we work towards a method that connects the mechanism of `fuel switching` to our analysis. We already mentioned, that there are several factors that influence the usage of certain fuel types. We will include some of them later on, but for now we keep it simple and only consider prices.  
In case we would decide which fuel to use for power generation in terms of costs, `Marginal Costs` (MC) would play a central role. Per defintion, Marginal Costs not only include the price to buy the fuel, but include all costs that are incurred in producing additional electricty.  
Cullen hereby defined a formula which defines `Marginal Costs` as a Equation of `heat rate` and the `costs of burning fuel`. Variable names of this exercise are explained in the info-box below:

$$\tag{1}MC=HR\cdot(P_{fuel}+CO_{2,fuel}\cdot P_{co2})=HR\cdot C_{fuel}$$

info("Variable names") # Run this line (Strg-Enter) to show info

At the beginning of this problem set we mentioned, that it has to be a central goal for us to reduce emissions. We also observed, that the proportion of gas and coal have converged considerably over time. Apart from relying on the effects of the normal economy, where demand meets supply, we need to find further incentives to increase the share of gas. To reinforce this we can use the property, that coal contains approximately twice as much $CO_2$ as natural gas. Therefore, we can introduce **carbon prices**.  
Because of the difference in `carbon content` per fuel type, the cost efficiency of coal is far mroe effected. The momentum is additionally driven by the fact that the heat rate of gas generators is generally more efficient than the one of coal generators.
Combining these two facts lead to `steeper marginal costs` for coal generators when carbon prices are introduced. Reflecting this to our upcoming analysis, we won't observe carbon prices in available data sets, but a variation in fuel prices that are transformed by `Equation 1` into `costs of burning fuel`.  We can combine the variation of both fuel costs by creating a `cost ratio`:

$$\tag{2}costratio=\frac{C_{coal}}{C_{gas}}$$

This will help us explain the relation of both fuel costs in a single variable and therefore simplifies our model and interpretation. By combining Equation `1` with Equation `2`, we can explain `cost ratios` as a function of `fuel prices`, `carbon content` and `carbon prices`:

$$\tag{3}costratio=\frac{C_{coal}}{C_{gas}}=\frac{P_{coal}+CO_{2,coal}\cdot P_{co2}}{P_{gas}+CO_{2,gas}\cdot P_{co2}}$$

Our eventual goal is to find the response curves of `emissions` to changing `fuel costs`. As mentioned above we observe a variance in fuel prices. To be able to clearly interpret our results we have to agree on a base-level of prices for both types of fuel. Ideally we want to set a base level that is based on future price predictions, meaning that in the end we want to achieve a result which shows us the changes in emissions in relation to these base prices. Luckily the `EIA` provides predictions for the year 2025. For completeness I include the values of carbon content $CO_{2,coal}$, which are also provided by the `EIA`:

- Average delivered coal price `$2.25/mmBTU` and gas prices `$5.75/mmBTU` (forcast for 2025)
- Carbon content `Natural Gas`: 117 lbs carbon/MMBTU or `0.0585 tons/MMBTU`  
- Carbon content `Coal`: 210.8 lbs carbon/MMBTU or `0.1054 tons/MMBTU`  

You might have noticed by now that `cost ratios` play a central role in our analysis. To make this even clearer let's study the behaviour of our equations a bit more closely.

#! addon__quiz__Cost Ratios
&nbsp;

This relation is obviously quite intuitive. By adding carbon prices as in `Equation 3` it gets a bit more complex. The new relation is visualized in the graph below. The values in the graphs correspond to the values of base prices from above.  

<img src="./Material/relationship.png" alt="drawing" width="600"/>
Source: Cullen 
  
Panel `(a)` shows the relationship between fixed costs of `coal` and `gas` when `carbon prices` get introduced. As we explained above, we observe steeper marginal costs for coal and at a certain level, natural gas becomes more cost efficient. Panel `(c)` displays the results when transforming fuel prices in cost ratios as defined in `Equation 2`. With the transformation to cost ratios we can plot one line for both fuels and interpret how they react to carbon prices.  
Panel `(b)` and `(d)` plot the same method, but this time in absence of carbon prices and with fixed coal prices. The message you should get here is, that we can find the same cost ratios (`red lines`) with both approaches.

#! addon__quiz__carbon Prices
&nbsp;

In summary, the answer is the central idea to our analysis. We observe variations of cost ratios in our data and can build a model that predicts the effect on $CO_2$ emissions when a certain generator becomes more cost-efficient.  
Up until now we are be able to analyse the effects of changing cost ratios on emissions. With the introduction of carbon prices it would be interesting to directly know the effects of certain levels of carbon prices on emissions. Therefore, we can rearrange `Equation 3` to carbon prices, which will find its use at the end of our analysis:

$$\tag{4}{P_{co2}}=\frac{costratio\cdot{P_{gas}}-{P_{coal}}}{CO_{2,coal}-costratio\cdot CO_{2,gas}}$$

<br/><br/>
  
Since it's not common in Europe to have the kind of electricity grids as in the United States, we will introduce the concept of `Interconnections` in the following sub-section.

### Interconnections

The American Electric system is made up of three major `Interconnections`, that in turn consist of different balancing authorities (responsible for maintaining the electricity balance within the region). Local electricity grids are hereby connected to form a network, which provides higher stablity and reliability.  
`Interconnections` operate mostly independent from each other and exchange little to no electricity, which is a huge difference in comparison to the European electricity grid, where grid stability is ensured across borders.

In the graph below you can see the `3` interconnection we include data of in this problem set. I listed a few details for each below:
- `Eastern Interconnection (EAST)`: Consists of 36 balancing authorities and extends from the East Coast to the Rocky Mountains.
- `Western Interconnection (WECC)`: Involves 37 balancing authorities, which are located in the West of North America.
- `Electric Reliability Council of Texas (ERCOT)`: Consists of large parts of Texas

<img src="./Material/interconnections.png" alt="drawing" width="600"/>
Source: Cullen

In the first part of this exercise we already hinted that our model will we some form of regression of price ratios against emissions. Since we are essentially observing three different energy markets we should confirm the distribution of our data points. Therefore we create a graph that plots all price ratios within our data set against $CO_2$ emissions. We run the model seperately on each interconnection if find a large distribution across interconnections. We will present the data set for the analysis in detail in upcoming exercises. For not it's enough to get an impression on the distribution.

In the section above we already stated that in a first step we want to find a model that explains the relation between cost ratios and emission. Since we are essentially observing three different energy markets, we should check the distribution of data and determine whether we can create one model for the entire market or seperate it by interconnection.  
We will present the data in detail in the upcoming chapters, for now we create a graph that plots the cost ratio against $CO_2$ emissions and additionally encricles the data to its corresponding interconnction.

**Task:** Just press *check*.

info("geom_encircle()") # Run this line (Strg-Enter) to show info

 //////////// rename data set

```{r "2",message=FALSE}
dat <- read_csv("Data/exercise3.csv")
ggplot(dat,aes(x=coalprice/gasprice,y=co2mass/1000,color=intercn))+
        geom_point(alpha=0.2) +
        geom_encircle(aes(group=intercn,fill=intercn),alpha=0.3, s_shape=1) +
        theme_bw()+ 
        labs(y="", 
        x="Cost Ratio", 
        subtitle="y=CO2 Emissions in 1000 tons/day",
        title="Distribution of data")
```

////// ?

At this point we will just analyse the distribution of the data. We see that the data point of the `Eastern` Interconnection is way different than the other two interconnections. We could probably find a model that fits for `ERCOT` and `WECC`, but its unlikely to fit `EAST` as well. Because of this we will perform our analysis on each `interconnection` seperately. 


In the next chapter we will build a mathematical model that will implement the theory we introduced in this exercise. Click `Go to next exercise`.


## Exercise 3.1 -- Emission Response Curves - A simple Approach

A short recapture: Up to this point we got some insights into the U.S. energy market and introduced the concept of mapping cost ratios and carbon prices to emissions. In this exercise we will combine these findings and develop a model which will allow us to predict the impact of changing fuel costs on emissions. We start by proposing a simple linear model and work our way towards more complex but also more precise ones.  
If you are purely interested in the final model and the economic impact, you can skip to `Exercise 4.1`. The next two exercises will focus on regression theory, which build a basis to understand the methods we use for our main analysis.

**Task:** To get started, load the data set `exercise3.csv`, press `edit` and `check` afterwards.

```{r "3_1",message=FALSE}
dat <- read_csv("Data/exercise3.csv")
head(dat,3)
```

Due to the size of the original data sets we skip the data preparation in this problem set but rather provide the data sources and work with the final data set. It consists of 7671 observations from 2006 onwards and is aggregated daily and seperated by interconnection. Along the way we will extend the data set with additional variables. You can find the meaning of the variables and it's associated units below:  

`co2mass`: $CO_2$ Emissions in tons  
`gasprice`: Capacity weighted average daily gas price ($ per million BTU)  
`coalprice`: Price of Coal ($ per million BTU)  
`load`: Daily electricity consumption in MWh  

The data are gathered from several official U.S. agencies, `Emission` data are measured by the Continuous Emissions Monitoring System (CEMS) of the `Environmental Protection Agency (EPA)`. The U.S. Energy Information Administration (EIA) collects data of `coal prices` in Form 923. Spot prices for `gas` can be found at the `Intercontinental Exchange (ICE)` and data for `electricity consumption` or `load` are provided by the `Federal Energy Regulatory Commission (FERC)` in Form 714.  
As mentioned in `Exercise 2` it makes sense for us to run our model on each `interconnection` seperatly. For this purpose we will filter our data set for interconnection `EAST` and develop the model based on these data. Once we find a fitting model we will run it on each interconnection and merge our results. For this chapter and for ease of interpretation we convert emissions and load from tons to million tons.  

**Task:** Use the pipe operator `%>%` to combine following tasks: Filter the data set `dat` for interconnection `EAST` and store it in `dat_east`. Additionally, calculate the cost ratio between `coalprice` and `gasprice` according to `Equation 2`.

info("Pipe(), Select(), Filter(), Mutate()") # Run this line (Strg-Enter) to show info

```{r "3_1__3"}
# ___ <- data ___ 
#  mutate(costratio = ___/___,
#         co2mass = co2mass/1000000),
#         load = load/1000000) ___
#  filter(intercn=="___")
```



### Linear Regression

The easiest way to start is to propose a simple linear regression model that predicts emissions purely on the basis of a linear relationship to cost ratios. In mathematical terms we can express the relationship as followed, with $CO_{2t}$ for mass of $CO_2$ emissions, $\beta_t$ for our coeffcients and $\epsilon_t$  for the Error-Term:

$$co2mass_{2t}=\beta_{0}+\beta_{1}\cdot costratio_{t}+\epsilon_t$$

info("Linear Regression with lm()") # Run this line (Strg-Enter) to show info

**Task:** Run a regression with `co2mass` as the dependent variable and `costratio` as independent variable. Store it in the variable `fit.linear`. 
```{r "3_1__5"}
# ___ <- lm(___~___ , data=dat_east)

```

R provides a function that provides the summary statistics of our model on default with `summary()`. Since it's output is pretty static, we will use `stargazer()`. The function allows us to custimize the output to our needs and it supports the `html` format. Therefore, we define our own version of stargazer() and at the same time introduce custom functions which will be useful later on. Read the `Info Boxes` below to find out more about `stargazer()` and `custom functions`.  

**Task:** Just press **check** to define the function.

info("Stargazer") # Run this line (Strg-Enter) to show info

info("Custom functions") # Run this line (Strg-Enter) to show info

```{r "3_1__8"}
show.regression= function(...){
  library(stargazer)
    stargazer(..., 
            type = "text", 
            style = "aer",  
            digits = 3,
            df = FALSE,
            report = "vct*",
            star.cutoffs = c(0.05, 0.01, 0.001),
            model.names = FALSE,
            object.names = TRUE,
            model.numbers = FALSE, 
            omit.stat=c("f", "ser")
    )
}
```

#! addon__quiz__Reg1
  
**Task:** Use the function we defined above to display the summary statistics of `fit.linear`.
```{r "3_1__9"}
# Enter your code here.
```


We observe a positive intercept term $\beta_0$ with 5.87704 and a negative coefficient for $\beta_1$ of -1.30554, meaning that emissions fall with an increasing cost ratio. The three stars next to our coefficents imply, that the p-value is smaller than 0.1. Therefore, the coefficients are inconsistent with the null hypothesis and it may be rejected. In other words the probabiliy of finding an estimator that is at least as high as the one we predicted is smaller than one percent.  

info("R-squared") # Run this line (Strg-Enter) to show info

Next, we determine if the model fits the data. One possibiliy is to use the $R^2$ indicator, which measures quite low at $19.7%$. However, we should take this measurement with a grain of salt. As mentioned before, our coefficients are statistically significance, therefore we are still able to draw conclusions from our results as shown above. 


### Multivariate Regression Models

If we look back at the implications of the energy market from `Exercise 1`, we know that there are several other factors that should influence $CO_2$ emissions of energy generation. To include additional effects in our model we can use `Multivariate Regression Models`. For now, we add the effect of `electricity consumption` or `load`. Our regression formula changes to:   
$$co2mass_{2t}=\beta_0+\beta_1\cdot costratio_t+\beta_2\cdot load_t+\epsilon_t$$

**Task:** Run a regression based on the multivariate model. Use the same data frame `dat_east` and store it as `fit.multi`. Additionally, use `show.regression()` to output the summary statistics of both fits together.
```{r "3_1__10"}
#fit1 = lm(co2mass ~ costratio + load, data=dat_east)

```

The influence of `costratio` is around half as big as before. `Load` has a positive coefficient $\beta_2$ of 0.774, which is also quite logical since emissions should increase with more generated electricity. We conclude that the fuel costs and the generated electricity both have a nearly equal influence on $CO_2$ emissions. According to the p-values, all coefficients are  siginificant, but we observe a big difference in the `R-squared` measurement. In contast to our first model, the second model explains a vast majority of the obvserved values With $92.5\%$.  
Concluding this we see some improvement in our statistics when introducing a second coefficient to our model. Let's pretend we are satisfied with our results from `fit1` and we follow along our analysis. As long as we keep our models that simple, we can directly draw conclusion from the summary statistics. However, if we continue to add more variables to our model and introduce additional statistical methods this won't be that easy. Therefore, having a well fitted model is just the first step for us. In the end we want to create a graph that plots the response curves of emissions against changing costs of fuel. To do this for any model, we first have to calculate the fitted values based of our model. Luckily, R provides a function exactly for this case, named `predict()`.  

**Task:** Predict the fitted values of `fit1` on `dat_east` and store it in `co2.hat1`.

info("Predict") # Run this line (Strg-Enter) to show info

```{r "3_1__12"}
# Enter your code here.
```

Now, that we calculated the fitted values we can proceed and plot cost ratios against the fitted values of emissions. However due to the fact that we added load to our model, we have a multivariate regression model with two independent variables, which graphically spans over three dimensions. To illustrate this problem let's create a plot for `fit1`.

**Task:** Just press **check**
```{r "3_1__13",fig.width=9, fig.height=6, dev='svg'}
#take sample from data to limit points shown in plot
temp<- dat_east %>% cbind(co2.hat1)
temp1<- temp[sample(nrow(temp), 150), ]
#assign vairables to axises
x <- temp1$costratio
y <- temp1$load
z <- temp1$co2.hat1
#set a nice color scheme
numbercol <- 8 # number of colors
plotcolor <- brewer.pal(numbercol,"Reds") # use Brewer to get color scheme 
colornum <- cut(rank(z), numbercol, labels=FALSE)
colorcode <- plotcolor[colornum] # assign color
#plot
s3d <- scatterplot3d(x,y,z, col.axis="gray", col.grid="gray", type="h",color=colorcode, 
angle = 35, scale.y = 1, pch = 19, xlab="Cost Ratio", ylab = "Load", zlab = "Emissions")
s3d$plane3d(fit1, lty = "dotted")
```

//////////////////////


Because of the vast amount of observation I limited the data points in our plot to a sample size. The predicted emissions are plotted as dots and the corresponding regression plane (dotted line) alongside. 


Of course it would be a valid solution to visualize our results that way. 



Considering we add further variables later on and that we want to easily be able to interpret our plots, we want to visualye these in a two-dimensional 


If we wanted to visualize this in a two-dimensional graph, as it is needed to produce robust scientific results


Because of that there's no exact "line" to be drawn here if we wanted to . Since it is not that common to plot regressions, let's see what would happen if we continue and simply plot these predicted values. For purpose of illustration, run the code below.

It would be a valid solution to continue with a three-dimensional graph, but since we will add further variables, it isn't sufficient for us in term of robust scientific results. 

**Task:** Just press **check**
```{r "3_1__14"}
ggplot(dat_east,aes(x=costratio,y=co2.hat1))+
        geom_line(aes(x=dat_east$costratio, y=co2.hat1))+
        labs(y="Emissions", x="Cost Ratio")
```

`R` hereby follows it's intential purpose and connects all fitted values along the range of cost ratios. Since we don't consider the `load` variable in the two-dimensional plane, we get a output that is not at all what we want. To solve this issue we will use a work around in the way that we won't predict our fitted values on the original data frame we build our model on. Instead we evaluate all independent variables with exception of cost ratios at their respective means. We plot emissions against cost ratios, therefore we evaluate ratios at their true values. 
This is possible, because the average of the fitted values $\hat{y_i}$ are equal to the average of the actual values $y_i$: 

$$\frac{1}{n}\sum_{i=1}^n \hat{y_i}=\frac{1}{n}\sum_{i=1}^n y_i$$

This is true for regressions with an intercept term (Sarndal, Swensson and Wretman, 1992). The sum of the residuals of the variables equal to zero in this case.  
To implement this method into our analysis we create a new data frame with the means of our independent variables. At this point we only added `load` to our model, therefore we include `costratio` and the mean value of `load`. Afterwards we can use these data to run `predict()` on. At the end of this exercise we will once more plot our reponse curves and see the effects of this approach on our plots.

**Task:** Just press *check*.
```{r "3_1__15"}
pred_dat = tibble(co2mass = dat_east$co2mass, costratio = dat_east$costratio) %>%
  cbind(load=mean(dat_east$load))
```

### Non-linear models

Now, that we are able to plot multivariate regressions into a two-dimensional grid, we continue to further develop our model. Our previous models assumed a linear relationship between emissions, fuel prices and load. Given the complexity of electricity markets and the statistics we gathered up to this point, we should assume a more complex relationship in form of a highly non-linear response of emissions. The type of regression that fits a non-linear relationship between dependent and independent variables is called `Polynomial Regression`. The easiest way to transform our previous model is to replace the linear variable with a cubic function:

$$co2mass_{2t}=\beta_0+\beta_1\cdot costratio_t+\beta_2\cdot costratio_t^2+\beta_3\cdot costratio_t^3+\beta_4\cdot load_t+\epsilon_t$$

**Task:** The syntax in R to create a cubic function is `poly()`. We can include all grades of the polynomical function but since `R` does this on it's own, it is enough to define it as followed. Just press *check*.
```{r "3_1__16"}
fit2 = lm(co2mass ~ poly(costratio,3, raw = TRUE) + load, data=dat_east)
show.regression(fit1, fit2)
```

The summary shows the statistics for the  linear (`fit1`) and polynomial model (`fit2`). The first thing we can observe is, that R provides a coefficient for every grade of the cubic function. Mathematically the cubic function is noted as $-10.059x-0.287x^2+1.444x^3$ and we can calculate the positive turning point with: $\frac{∂(-10.059x-0.287x^2+1.444x^3)}{∂x} = 0 => 2.74058$. This means, that `costratio` has no futher positive effect on emissions when its' value is greater than 2.74. The value of $R^2$ is comparable between both models, but as mentioned before we shouldn't purely rely on this measurement. Since we stated that emissions should follow a highly non-linear reponse, we can assume that the non-linear model is a far better fit, even though the statistics are comparable.  
We finish this exercise by plotting the reponse curves once again with the method we introduced before. First, we predict the fitted values on the new data frame, afterwards we can create our plot as usual.

**Task:** Run `predict()` on `fit1` and `fit2`. We already predicted values for `fit1`, but this time we use the data frame `pred_dat`.
```{r "3_1__17"}
#co2.hat1 = ___
#co2.hat2 = ___

```

**Task:** Create a new ggplot. Use `geom_line()` to plot one line each for `co2.hat1` and `co2.hat2`. Assign `costratio` to the x-axis and the fitted emission values to the y-axis.
```{r "3_1__18"}
#ggplot(pred_dat,aes(x=costratio,y=dat_east$co2mass))+
#   geom_line(aes(___), color="red") +
#   geom_line(aes(___), color="green") +

```

The plot shows us the two regression lines for the linear and non-linear regression approach. By including the mean-values of `load` in the data frame that we use to calculate the fitted values we get a line to interpret. Furthermore, the non-linear model seems to reflect the real-world a lot better. Because of technological and capacity restriction it is unlikely that emissions can increase in a linear fashion without restrictions. That effect should also apply for higher cost ratios.  
Looking closely though, we still see some flaws that don't seem to be accurate. For example it is unlikely that we observe increasing emissions with higher cost ratios. Obviously this is caused by the type of cubic functions we use and their mathematical behaviour, so going forward we improve the method of using polynomial function for our model. Click `Go to next exercise` to continue.



## Exercise 3.2 -- Restricted Cubic Spline Regressions

In this exercise we will introduce the conecpt of `restricted spline regressions`, which are basically a special form of polynomial regressions. In the world of craftman's the term splines would refer to a strip of wood that is being shaped into a smoothed curve. The strip is hereby forced around fixed points to form a natural spline. In the world of mathematics these splines are defined as a form of piece-wise polynomial functions, which usually consist of cubic polynomials. `Knots` refer to the fixed points in mathematical splines and are placed along the range of data. As we ajust the number of knots the spline becomes more or less flexible.  

<img src="./Material/splines.png" alt="drawing" width="400"/>
Source: Author  

We can roughly visualize this method with the graph above. Given a range of data, we set a certain amount of `Knots` and in between those ("Segments"), we fit several cubic functions. Combining the cubic function will give us our regression line for the spline regression. Mind here that the amount of Knots has to be chosen with caution, cause a wrong amount of knots can lead to over- or underfitting. A way to confirm the correctness of the fit is to conduct robustness tests where we adjust the number of knots. We will do this briefly at the end of this problem set. At last, our model will be `restricted` , meaning that the spline is constrained to be linear in front of the first knot and after the last one. This solves the problem we observed with the polynomial model at the end of last exercise.

**Task:** To start, load the required data. We use the same data and limit them to interconnection `EAST` as before. The data frame already takes the changes into account. Just press *check*.
```{r "3_2",message=FALSE}
# Enter your code here.
```

**Task:** Fit a regression model, which includes `costratio` and `load` as natural splines with `5` degrees of freedom. Use the data frame `dat_east`.  

$$\tag{5}co2mass_{2t}=s(priceratio_{t}|\beta)+s(load_{t}|\theta)+\epsilon_t$$

info("ns()") # Run this line (Strg-Enter) to show info

```{r "3_2__3",message=FALSE}
#fit3 = lm(co2mass ~ ns(___)+ns(___), data=dat_east)
```

**Task:** Use `show.regression()` to get the summary statistics of `fit3`.
```{r "3_2__4"}
# Enter your code here.
```

The summary statistics of our spline model is comparable to the simple polynomial regressions from last exercise, where we got a coefficient for every grade of the cubic function. In this case we get a coefficient for every degree of freedom. Since splines are transformations of explanatory variables it isn't really possible to interpret these coefficients straightforward. Nevertheless we want to get clear and  interpretable results and that's the reason why we went through the trouble and introduced the methods to create plots from our models.

**Task:** Just press *check*.
```{r "3_2__5",warning=FALSE}
pred_dat = tibble(costratio = dat_east$costratio) %>%
  cbind(load=mean(dat_east$load))
co2.hat3 = predict(fit3, pred_dat)
ggplot(pred_dat,aes(x=costratio,y=dat_east$co2mass))+
    geom_point(alpha=0.3) + 
    geom_line(aes(x=costratio, y=co2.hat3), color="red") + 
    scale_y_continuous(limits=c(4,6))
```

We continue to see a negative relationship between cost ratios and $CO_2$ emissions. Additionally I added the data points of $CO_2$ emissions. As cost ratios increase, the variance between our regression line and the observations tends to increase. This is a strong indicator that our model suffers from heteroskedasticity. Since standard error methods rely on the assumption that there's no correlation between the independent variables and the variance of the dependent variables, we shouldn't use them but instead calculate `heteroskedasticity robust standard errors`.  
R packages normally provide a lot of handy functions to predict fitted values and calculate robust standard errors at the same time. However, we don't predict our fitted values on the same data frame we build our model on. Therefore, I wrote a custom function that allows us to predict our fitted values and at the same time provides the Newey-West estimators, which is already implemented in the `sandwich` package. The function will calculate the errors based on our requirement and we are later able to include the confidence intervals in our plot. For reference I included the function below, however we won't go through the theory Newey-West estimators or explain the function.  

info("Custom Function") # Run this line (Strg-Enter) to show info




## Exercise 4 -- Examining Carbon Abatement


In the following chapter we shift our focus away from theory and work our way towards our final results. To approach our main analysis we split it into two parts:

- First, we determine the $CO_2$ emission response curves to changing fuel costs. To reflect the behaviour of the energy market as closely as possible we will add additional factors to the model we introduced in the previous exericise. (`Exercise 4.1`)

- Afterwards, based on the theory of `Exercise 2`, we transform our fuel costs into carbon prices and discuss the final results. (`Exercise 4.2`)

In Chapter 3 we worked our way towards a fitting model and ended up with spline regressions. To keep it simple we limited our data to fuel costs and generated electricity (`load`). The goal of this exercise is, to introduce the additional factors we want to include in our model and get a final impression of the data. 

**Task:** Load the data set `main_data.csv` with `read_csv` and store it into a variable called `dat`.

```{r "4",message=FALSE}
#___ <- ___("./Data/___")
```
&nbsp;
The data frame is a combination of data we used before and adds several factors that have influences on emissions. The data continue to be aggregated to a daily level and seperated by interconnections. New variables are explained below:

`tlsd`, `tlmin`, `tlmax`: Standard deviation, minimum and maximum of `load`  
`meant`: Average daily temperature  
`nonFossil`: Electricity generated with non-fossil fuel in MWh  
`so2price`: Permit prices of $SO_2$ ($/ton)  
`netNSflow`: Electricity flowing from Canada to the U.S. in MWh  

The U.S. Energy Information Administration (EIA) provides data for `non-fossil` energy production, permit prices for $SO_2$ are collected from the `EPA Clean Air Markets` and `net imports` of electricity from Canada are gathered from the `National Energy Board of Canada`. You can find links to the links to the data in the `References` section.  
Another factor we haven't considered yet is the seasonal component in energy consumption. We already mentioned in `Exercise 1`, that load heavily varies during the year with a smaller peak in summer and a bigger one in winter. To adjust for this effect we create a dummy variable that controls for years and seasons (off-season/summer/winter). 

**Task:** Calculate the seasonal dummy variable and show the first few rows. Just press *check*.
```{r "4__2"}
# Enter your code here.
```

The data frame includes all variables we want and will be used for our main analysis. We already got a glimpse on some variables earlier. Now that we have our complete data we will create a summary table, which will show us the means of important variables, seperated by interconnections. That way we can draw some conclusions for further interpretations.  

**Task:** We use `group_by()` to group the dataset `dat` by `intercn`. Afterwards, run `summarise_all()` to calculate the means of every column. For formatting we use the `kable`. Just press *check*.

info("Group_by() and summarise()") # Run this line (Strg-Enter) to show info
  
info("kable()") # Run this line (Strg-Enter) to show info

**Task:** Just press **check**.
```{r "4__4"}
dat_final %>% 
  select(intercn, co2mass, load, coalprice, gasprice, costratio, nonfossil) %>% 
  group_by(intercn) %>% 
  mutate(co2mass = co2mass/1000, load=load/1000, "Emission Rate"=co2mass/load, nonfossil=nonfossil/100000) %>% 
  summarise_all("mean") %>% 
  kable(format="html", align="c", col.names = c("intercn","Emissions","Load","Gas Price","Coal Price","Price Ratio","Non Fossil","Emission Rate")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), position = "center", full_width = F)
```

The table reports the means of important variables for each interconnection. We can clearly see that `EAST` is by far the largest of the observed energy markets in terms of emissions, load and non-fossil power generation. The emissions seem to increase proportionally to the electricity consumption for all interconnections if we take the electricity production from non-fossil sources in consideration. This gets clearer if the look at the emission rates, which is defined as $ER=\frac{emissions}{load}$. The `Western` interconnection hereby has by far the `greenest` energy production, followed with some distance by Texas (`ERCOT`) and the `Eastern` interconnection. Furthermore we observe clear variations in price ratios. These observations are in line with our assumptions from `Exercise 2`, where we stated that each interconnection has vastly different market conditions.

In the next exercise will will use this data frame and in combination with the theory of `Chapter 3` to trace out the emission response curves. Click `Go to next exercise` to continue.



## Exercise 4.1 -- Estimated CO2 Response to Fuel Prices

In this exercise we will finally bring together all the findings so far and dedicate ourselves to our main results. In the first step we will perform the regression model based on the implications we made in `Exercise 3.2`. Afterwards we will use this model to predict emissions and trace our the emission response curves to changing fuel prices. Based on this we will explain and carry out the analysis step by step for interconnection `EAST`, afterwards apply it to `ERCOT` and `WECC` and interpret our results.  
As a side note, we will dive through a bunch of code. It isn't meant to be the shortest or the most efficient, but should allow you to follow each step closely. 

First, as always, we import our data frame from the previous exercise. The first steps are pretty straight forwards. First, we filter for interconnection `EAST`. Secondly, we create a new data frame with the mean values of the independent variables as shown in `Exercise 3.1`. Since these steps are pretty straight forward and you have seen the methods before, go ahead and prepare our data.

**Task:** Load the dataframe and store it in `dat`.
```{r "4_1",message=FALSE}
dat <- read_csv("Data/exercise4_1.csv")
head(dat,3)
```

**Task:** Filter the data set `dat` for intercn `EAST` and store it in `east`.
```{r "4_1__2"}
# Enter your code here.
```

**Task:** Calculate the `mean` of every variable we use in our regression. First, `select()` the necessary columns and then use `summarise_all()` to calculate the means. Store the result in `mean_east`.
```{r "4_1__3"}
# ___ <- east %>% 
#  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
#  summarise_all(___)

```

**Task:** To make our life a bit easier we merge the data frame with the mean values with important variables that will help us later. If we would skip that step we would have to work with two data frames. Just press *check*.
```{r "4_1__4"}
predict_east <- tibble(date=east$date, intercn=east$intercn, co2mass=east$co2mass, gasprice = east$gasprice, coalprice=east$coalprice, costratio = east$costratio) %>% 
  cbind(mean_east)
```


The data preparation is done, now we can define our model. We will perform a restricted spline regression as introduced in `Exercise 3.2`. The complete model is proposed by Cullen and is defined as below. We construct splines for `costratio`, `load`  and `meant` and include the remaining control variables as well as the seasonal dummy variable in a linear form.

$$\tag{5}co2mass_{2t}=s(costratio_{t}|\beta)+s(load_{t}|\theta) + s(meant_t|\omega)+X_t\psi+D_\gamma+\epsilon_t$$

info("Model variables") # Run this line (Strg-Enter) to show info

**Task:** Since we will run this regression model one times each for every interconnection, we can save some work and pre-define our model. Define the model according to `Equation 5` and store it into the variable `model`.
```{r "4_1__5"}
#___ co2mass ~ ___(priceratio, df=...) + ___(load, df=...) + tlsd + tlmin + tlmax + ___(meant, df=___) + nonfossil + so2price + netNSflow + yearseason

```

**Task:** Perform the regression of `model`. Use `lm()` and the data frame `east`.
```{r "4_1__6"}
# Enter your code here.
```

We mentioned this before, but because of the fact that the spline coefficients are transformations of explanatory variables, we forego looking at the summary statistics. Instead we continue with our workflow. In the next step we predict the fitted values 



**Task:** Predict $CO_2$ emissions based on the regression model `reg_east` and `temp_east`. We set interval to `confidence` to get the mean interval and be able to plot a confidence band later on.
Just press *check*.

wie ist custom function defined - arguments

info("Confidence interval") # Run this line (Strg-Enter) to show info

```{r "4_1__7"}
# Enter your code here.
```



/// reg_robust <- lm_robust(y1 ~ x, mydat, se_type = 'stata')
/// https://ditraglia.com/econ224/lab07.pdf


Now we are at the point were we could plot our results. By doing so we would plot the absolute values of the fitted $CO_2$ emissions against cost ratios. In `Exercise 2` we showed that we can construct cost ratios with a variety of different fuel costs. This was an elegant method for us to use for modelling, but our final results should really give us an clear impression on the indications. Therefore, we will simply transform cost ratios backwards and just show gas prices. Additionally we mentioned in `Exercise 2` that it would be to get the change in emissions in relation to base line prices instead of absolute values. We use predictions of fuel costs 



In the end it would be nice to get an output that gives as an percentage change of emissions to changing costs. Therefore we can take our fitted values and transform them base 

Additionally, as we saw in `Exercise 2` we can pretty much construct cost ratios with various `gas` and `coal` costs. Let's say we have 


**Task:** Just press *check*.
```{r "4_1__8"}
# Enter your code here.
```



**Task:** The only task left is to create our plot. Just press *check*.
```{r "4_1__9",warning=FALSE, fig.width=7, fig.height=7}
# transform costratio backwards to plot gas costs, save plot to variable for later use
plot_east <- ggplot(final_east, aes(x=basecoal/east$costratio, y=fit.transformed)) +
  #use geom_ribbon() to add a confidence interval
  geom_ribbon(aes_string(ymin = final_east$lwr.transformed, ymax = final_east$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5,) +
  # add line for fitted emission values
  geom_line(aes(y=fit.transformed)) +
  # transform y-Axis to a percentage scale and set range
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  # add indication line for baseline gas price
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  # set scale and range of x-Axis
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  # add labels 
  labs(title="Eastern Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  # set theme (optional)
  theme_minimal()

plot_east
```

TEXT////

If you feel confident you can write the code for the other two interconnection by your own. Otherweise just run the two code chunks below.

**Task:** Run the code for the `ERCOT` interconnection. Just press *check*.
```{r "4_1__10",warning=FALSE, fig.width=7, fig.height=7}

#filter for interconnection ERCOT
ercot <- filter(dat, intercn=="ERCOT")

#calculate the mean for regression coefficients
mean_ercot <- ercot %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)

#join data
predict_ercot <- tibble(date=ercot$date, intercn=ercot$intercn, gasprice = ercot$gasprice, coalprice=ercot$coalprice, costratio = ercot$costratio) %>% cbind(mean_ercot)

#run model 
reg_ercot <- lm(model, data=ercot)

#predict new co2 emission and join with predict_ercot, ERCOT has no net imports of electricity, predict throws warning
fit_ercot <- predict_ercot %>% 
  cbind(as.data.frame(predict(reg_ercot, newdata = predict_ercot, interval = 'confidence')))

#find baselevel of emission in relation to baseline price of coal and gas
diff_base <- abs(ercot$costratio - (basecoal/basegas))
min_dif <- min(diff_base)
closest <- min_dif==diff_base
base_emit <- mean(fit_ercot$fit[which(closest)])

#transform predicted emission into percentage change to baseline emissions
final_ercot <- fit_ercot %>% 
  mutate(fit.transformed=fit/base_emit-1,
         lwr.transformed=lwr/base_emit-1,
         upr.transformed=upr/base_emit-1)

#plot result
plot_ercot <- ggplot(final_ercot, aes(x=basecoal/costratio, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = final_ercot$lwr.transformed, ymax = final_ercot$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  labs(title="ERCOT Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()
```

**Task:** Run the code for the `WECC` interconnection. Just press *check*.
```{r "4_1__11",warning=FALSE, fig.width=7, fig.height=7}
wecc <- filter(dat, intercn=="WECC")

mean_wecc <- wecc %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)

predict_wecc <- tibble(date=wecc$date, intercn=wecc$intercn, gasprice = wecc$gasprice, coalprice=wecc$coalprice, costratio = wecc$costratio) %>% cbind(mean_wecc)

reg_wecc <- lm(model, data=wecc)

fit_wecc <- predict_wecc %>% 
  cbind(as.data.frame(predict(reg_wecc, newdata = predict_wecc, interval = 'confidence')))

base_emit <- mean(fit_wecc$fit[which(min(abs(wecc$costratio - (basecoal/basegas)))==abs(wecc$costratio - (basecoal/basegas)))])

final_wecc <- fit_wecc %>% 
  mutate(fit.transformed=fit/base_emit-1,
         lwr.transformed=lwr/base_emit-1,
         upr.transformed=upr/base_emit-1)

plot_wecc <- ggplot(final_wecc, aes(x=basecoal/costratio, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = final_wecc$lwr.transformed, ymax = final_wecc$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  labs(title="Western Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()
```

**Task:** Use grid.arrange() to display the plots next to each other. Just press *check*.

```{r "4_1__12",warning=FALSE, fig.width=14, fig.height=7}
# Enter your code here.
```


//TEXT, east oben, hier verlgeich zu ercot, wecc






///////// test
```{r "4_1__13"}
# Enter your code here.
```





In the next exercise we will map the emission response curves from this exercise into carbon prices and estimate the effects of carbon prices on emissions as well as the associated costs. Click `Go to next exercise` to continue.


## Exercise 4.2 --  Imputed CO2 Response to Carbon Prices

In the last exercise we plotted the effect of changing cost ratios of `coal` and `gas` against the fitted values of $CO_2$ emissions. What we are really interested though, is the effect of carbon prices on emissions. Therefore we introduced a way to transform our cost ratios in carbon taxes in `Exercise 2`. This will allow us to determine the effects as well as the costs. The plan of this is exercise is to first transform our cost ratios according to `Equation 3` and afterwards plot our results similiar to `Exercise 4.1`. 

We continue to use the same fixed and predicted fuel prices for 2025 to determine the base line level of our emissions. Additionally we need the carbon contents of both fuel types. We introduced the values of carbon content in `Exercise 2`, for reference I include them once more:  

- Carbon content `Natural Gas`: 117 lbs carbon/MMBTU or `0.0585 tons/MMBTU`
- Carbon content `Coal`: 210.8 lbs carbon/MMBTU or `0.1054 tons/MMBTU` (averaged on weighted fuel consumption according to EIA Form 923)  

To avoid repeating the same steps as in the last exercise, I prepared a data frame that includes the data of all interconnections with `predicted emissions`, `tranformed emissions` and confidence intervals from the previous exercise. We load the data set and store it as `dat`. We also declare the variables for `base prices` and `carbon content`.

**Task:** Just press *check*.
```{r "4_2",message=FALSE}
dat <- read_csv("Data/exercise4_2.csv")
head(dat,3)

basegas <- 5.75
basecoal <- 2.25
co2_coal <- 0.0585
co2_gas <- 0.1054
```

In the next step we want to transform our cost ratios using `Equation 3` (see below). Since we have all data available for the equation we can just go ahead and perform the calculation.  

$$\tag{3}{P_{co2}}=\frac{CR\cdot{base_{gas}}-{base_{coal}}}{CO_{2,coal}-CR\cdot CO_{2,gas}}$$

**Task:** Create a new column `carbontax` using `Equation 3`. Store the resulting data frame as `dat_tax`.
```{r "4_2__2",message=FALSE}
#___ <- dat %>% 
#  mutate(carbontax = (costratio*___-___)/(___-costratio*___)) %>% 
#
#head(___,___)

```

**Task:** Use `range()` to get the minimum and maximum of `carbontax`.
```{r "4_2__3"}
# Enter your code here.
```

As you can see we calculated negative as well as very high values of carbon taxes. Negative values wouldn't make much sense to consider for a tax in our case. The same is true for values that are extremely high. Because of that we will limit our taxes to a range of $[0,80]$.  

**Task:** Filter `carbon taxes` according to the data range above and store the data frame into `tax`.
```{r "4_2__4"}
#___ <- dat_tax %>% 
#  filter(carbontax >= ___ & carbontax <= ___)
#head(tax,3)

```

The overall approach to visualize our results is similiar to the on in Exercise `4.1`. We will filter our data frame for each interconnection and create a plot. In difference to the last exercise we will plot the response curves of emissions to changing carbon prices. Also we will interpret the output of all regions at once.

**Task:** Filter the data frame `tax` for interconnection `EAST` and save it to `tax_east`. Since we filter for a string, don't forget to put quotes around the argument.
```{r "4_2__5"}
# Enter your code here.
```

**Task:** Just press *check*.
```{r "4_2__6",fig.width=7, fig.height=7}
#run for Interconnection EAST
plot_east <- ggplot(tax_east, aes(x=carbontax, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = tax_east$lwr.transformed, ymax = tax_east$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-0.15,.01)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Eastern Interconnection",
       y="", x="Carbon Price $/ton", subtitle="y=CO2 emissions in Percentage") +
  coord_flip()

#run for Interconnection ERCOT
tax_ercot <- filter(tax, intercn=="ERCOT")

plot_ercot <- ggplot(tax_ercot, aes(x=carbontax, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = tax_ercot$lwr.transformed, ymax = tax_ercot$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +  
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-0.15,.01)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Ercot Interconnection",
       y="", x="Carbon Price $/ton", subtitle="y=CO2 emissions in Percentage") +
  coord_flip()

# run for Interconnection WECC
tax_wecc <- filter(tax, intercn=="WECC")

plot_wecc <- ggplot(tax_wecc, aes(x=carbontax, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = tax_wecc$lwr.transformed, ymax = tax_wecc$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-0.15,.01)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Western Interconnection",
       y="", x="Carbon Price $/ton", subtitle="y=CO2 emissions in Percentage") +
  coord_flip()
```

**Task:** Just press *check*.
```{r "4_2__7",fig.width=21, fig.height=7, warning=FALSE}
# Enter your code here.
```

The first plot shows the emission response curve of the Eastern Interconnection. This plot has the advantage, in comparison to the plots we made in the previous exercise, that we directly interpret the effect of certain levels of carbon prices on emissions. We see, that $CO_2$ emissions fall steeper for lower carbon prices. Purely interepreting the graph we could suggest that carbon prices between \$10 and \$40 have the most effect per dollar value. We will later on extract discrete values from our data set and calculate absolute costs of carbon taxes.  
Following this, we can plot the results for the remaining two interconnections. Run the two code chunks below and afterwards answer the quiz before we look at the results. 

wv energie verbrauch

The first thing we observe, 

Because of the fact that ercot is already more reliant on renewable energies we can argue that the emission reduction from switching between gas and coal- 
is steepest with a introduction of carbon prices and slows afterwards.


Based on our method we dont get carbon prices higher than 72 for West because of the price structure.
In the end all interconnection end up at around a reduction of 12% 

We can argue that additional carbon reduction will result from other factors if 


If we look at the ERCOT region (Texas), the first difference that ...

&nbsp;
#! addon__quiz__Costs of carbon taxes

&nbsp;  

**Task:** Just press *check*.
```{r "4_2__8"}
#define a function to find the value of emissions that is closest to the level of carbon taxes 
find_closest_value <- function(a) {
  vector <- 1:9
  for(i in 0:8){
   vector[i+1] = mean(a$fit[which.min(abs(a$carbontax - i*10))])
  }
  return(vector)
}
#create a new data frame with tax levels from 0 to 80 in steps of 10 and emissions of each interconnection
temp1 = data.frame(tax=seq(0,80,10),east_emission=round(find_closest_value(tax_east)/100000,1), ercot_emission=round(find_closest_value(tax_ercot)/100000,1), wecc_emission=round(find_closest_value(tax_wecc)/100000,1))

#caluclate the percentage change to our baseline level of emissions, additionally sum emissions to get total value of emissions
temp2 <- temp1 %>% 
  mutate(perc_east=round((1-temp1$east_emission/temp1$east_emission[1])*100,1),
         perc_ercot=round((1-temp1$ercot_emission/temp1$ercot_emission[1])*100,1),
         perc_wecc=round((1-temp1$wecc_emission/temp1$wecc_emission[1])*100,1),
         emission_all=east_emission+ercot_emission+wecc_emission)

#calculate the percentage change of total emissions and add total costs of emissions in bn$/year
temp3 <- temp2 %>% 
  mutate(perc_all=round((1-temp2$emission_all/temp2$emission[1])*100,1),
         total_costs=round(temp2$tax*temp2$emission_all/10000*365,1))

#use kable to create a table and change styling accordingly
table <- temp3 %>%
  select(c(1,2,5,3,6,4,7,8,9,10)) %>%
  kable(format="html", col.names = c("Tax","abs.","%","abs.","%","abs.","%","abs.","%", "bn$/year"), align="c", caption = "Precited Emissions and Percentage Abatement") %>%
  add_header_above(c(" "=1, "East" = 2, "ERCOT" = 2, "West" = 2, "Total" = 3)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), position = "center", full_width = F)%>%
  #column_spec(1:9, width = "0.4") %>%
  footnote(general = "Predicted emission are in 100.000 tons/day. Change to baseline (Tax=0).")

table
```


The result corresponds to Table 2 in Cullen's paper and show us the absolute values of emission reduction in comparison to the graphical view of above. The values at `tax = 0` mark the baseline emission at our predicted prices for gas and coal. When considering the combined emissions of all three interconnections, we clearly see that the majority results from the Eastern Interconnection. Following this we can suggest a tax rate which has the best dollar to emission reduction rate, which is roughly at a level of $20/ton. We can then directly derive the costs for such a measure. These taxes would then cost approx. \$45.6 billion per year, which are significant. The effects on a economy are hereby very uncertain, and there's much controversy over the eventual costs, also referred with "dead-weight-loss" (Mankiw-David Hakes, 2012). In economic terms, a tax increases the prices of a certain good and therefore widens the range between the prices at which buyers are willing to buy and seller willing to sell. This normally leads to reduced quantities purchased. Since we are introducing taxes on a essential good like energy, determining if the tax is worth the econimic costs is a topic worth on its own.  
  
These were our main findings in this problem set. In the next chapter we will conclude our results during this problem set. Click `Go to next exercise` to continue.

## Exercise 5 -- Conclusion and Discussion

Along this interactive R problem set, we answered the question whether carbon prices would effect emissions in the electritcity sector. We started by giving a overview of the electricity market and showed how the share of fuel-types and their prices changed over time. Afterwards we introduced the theory in `Exercise 2`, which enabled us to mapping carbon prices by using the variance in cost ratios. With these findings we started to build a mathematical model that made predictions based of externals factors to answer our main question. We found that the emissions of electricity markets respond highly non-linear and introduced advanced methods to meet these requirements. In `Exercise 4` we finally were able to trace out the emission respond curves to changing carbon prices. Since we implicated, that the U.S. energy market reacts differently for each interconnection, we gathered statistically robust results for each region (see `Info Box` below). Nevertheless, the grids are comparable with small differences mostly due to varying uses of regenerative energies or foreign electricity imports.  
Especially for relatively low carbon prices of about \$20, we can achieve signifact reductions in $CO_2$ emissions and at the same time limits the burden of the tax. A tax as high as \$70/ton seems unreasonable at this point, because the economic impact of the total costs would be highly uncertain. Since newly build coal generators are already quite efficient, a low tax would furthermore be better to drive carbon heavy plants out of the markets (Cullen & Renolds, 2016).  
Nevertheless, we have to be cautious with the assumptions we made in our methods. We predicted the relative change of emissions in relation to future coal and gas prices. With recent events around COVID-19, these predictions could be highly unlikely. As we have mentioned in `Exercise 1`, the steep fall in gas prices is mostly driven by the boom of the fracking sector. Because of the fact, that gas and oil prices plummeted further lately and a wide range of fracking companies operate at low bounds of profitability, we can assume that many of them could go bankrupt. This could likely reverse the price fall long term.    
We also included $SO_2$ permits in our model. Per construction of these allowances, their prices increase over time, which makes the long-term reduction of $CO_2$ plannable and at the same time a good long-term investment for institutional traders (there's no option to trade them as retail traders at this moment). With the introducting of carbon prices we would lower the demand of these permits, which would negate the effects of carbon prices and also question the purpose of $SO_2$ allowances.  
Additionally, we just assumed that carbon prices would be a good instrument to quickly and efficiently lower emissions. On one side, it sets pressure on the profit margin of energy companies, which would indirectly enhance the development of greener technologies. On the other side, it leads to higher consumer prices. Furthermore we can't ignore the fact, that generators in plants are normally planned to operate for a set amount of time, which would lead to slower responses.  
Concluding, carbon prices can be a strong factor to decide in which direction the energy sector will be headed in the forseeable future. Cullen goes even further in his analysis than we were able to here. If you are interested you can read further in his paper.  
I hope you enjoyed working through this problem set. Run the chunk below to see how many awards you earned throughout the exercises.

```{r "5"}
awards()
```


#! start_note "Robustness Checks"

We can conduct two easy robustness tests for our model. First, we could change the way we define our cost ratio. For our analysis we defined coal over gas, but instead we could define the inverse and simply take the price difference of gas and coal. The results hereby are very similiar if we adjust the mapping accordingly, therefore we won't provide a plot.  
We can also vary the `Knots` we use in our spline regression. We already mentioned in `Exercise 3.2` why we should test this. The process of achieving the result is equal to our previous method, below you see the output of a model with 4 degrees of freedomin comparison to our main results. As mentioned we get a less flexible curve, but the result are statistically insensitive to changes of the number of knots. Run the chunk above to get the graph (optional).

```{r "5__2",optional=TRUE, message=FALSE}
# Enter your code here.
```



#! end_note


## Exercise References


### Bibliography

- Bushnell, J. B., Mansur, E. T. & Saravia, C. (2008), ‘Vertical arrangements, market structure, and competition: An analysis of restructured US electricity markets’, American Economic Review 98(1), 237–66.

- Cullen, Joseph A., and Erin T. Mansur. 2017. "Inferring Carbon Abatement Costs in Electricity Markets: A Revealed Preference Approach Using the Shale Revolution." American Economic Journal: Economic Policy, 9 (3): 106-33.

- Cullen, J. & Renolds, S. (2016), ‘The long run impact of environmental policies on wholesale electricity markets: A dynamic competitive analysis’, Working Paper.

- Davis, L. & Hausman, C. (2015), Market impacts of a nuclear power plant closure, Ei @ haas working paper wp-248.

- Harrell, F. (2012), ‘Regression Model Strategies‘, Springer-verlag.

- Hakes, M. (2012), ‘Principles of microeconomics‘, South-Western Cengage Learning.

- Lafrancois, B. A. (2012), ‘A lot left over: Reducing CO2 emissions in the United States’ electric power sector through the use of natural gas’, Energy Policy 50, 428–435.

- Mansur, E. T. & White, M. (2012), ‘Market organization and efficiency in electricity markets’, (Working Paper).

- Swensson, Wretman (1992), ‘Model Assisted Survey Sampling‘, Springer-Verlag.

### R Packages

- Auguie, B. (2017): gridExtra: "Functions in Grid graphics", R package version 2.3, http://cran.r-project.org/web/packages/gridExtra/index.html

- Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables. R package version 5.2.2. https://CRAN.R-project.org/package=stargazer 

- Kranz, S. (2020): RTutor. "Creating R problem sets with automatic assessment of student's solutions", R package version 2020.03.13, https://github.com/skranz/RTutor

- Ligges, U., Maechler, M., Schnackenberg, S. (2018), scatterplot3d: "Plots a three dimensional (3D) point cloud.", R package version 0.3-41, https://cran.r-project.org/web/packages/scatterplot3d/index.html

- Neuwirth, E. (2014), RColorBrewer: "Provides color schemes for maps (and other graphics)". R package version 1.1-2, https://cran.r-project.org/web/packages/RColorBrewer/index.html

- Rudis, B. (2017): ggalt: "Extra Coordinate Systems, 'Geoms', Statistical Transformations, Scales and Fonts for 'ggplot2'", R package version 0.4.0, https://cran.r-project.org/web/packages/ggalt/index.html

- Venables ,W., Bates, D. (2019), splines: "Regression spline functions and classes.", R package version 3.6.2, Part of R.3.6.2

- Wickham, H. (2016): ggplot2. "Elegant Graphics for Data Analysis", Springer-Verlag, New York, R package version 3.2.1, http://CRAN.R-project.org/package=ggplot2

- Wickham, H., Francois, R., Henry, L., Muller, K., (2018): dplyr. "A Grammar of Data Manipulation", R package version 0.8.3, http://CRAN.R-project.org/package=dplyr

- Zhu, H. (2019), kableExtra: "Construct Complex Table with 'kable' and Pipe Syntax", R package version 1.1.0, https://cran.r-project.org/web/packages/kableExtra/index.html

### Data Sources

- European Environment Agency, "Primary Energy Consumption by Fuel", https://www.eea.europa.eu/data-and-maps/indicators/primary-energy-consumption-by-fuel-6/assessment-2

- Federal Energy Regulatory Comission, "Form  No. 714 Annual Electric Balancing Authority Area
and Planning Area Report", https://www.ferc.gov/docs-filing/forms/form-714/data.asp

- Government of Canada, "Canada Energy Regulator", https://www.cer-rec.gc.ca/bts/ctrg/gnnb/lctrctxprts/index-eng.html

- Intercontinental Exchange, "Commodity Prices", https://www.theice.com/marketdata/reports

- National Centers for environmental Information (NOAA), Climate data, https://www.ncdc.noaa.gov/cag/statewide/time-series

- The World Bank , "Commodity Markets Monthly Prices",  https://www.worldbank.org/en/research/commodity-markets

- United States Environmental Protection Agency, "SO2 Trading Program", https://ampd.epa.gov/ampd/

- U.S. Energy Information Administration, "FAQ", (https://www.eia.gov/tools/faqs/faq.php?id=73&t=11)

- U.S. Energy Information Administration, "Form EIA-923", https://www.eia.gov/electricity/data/eia923/

- U.S. Energy Information Administration, "Today in Energy", https://www.eia.gov/todayinenergy/detail.php?id=43035

*All of the above links were accessable as of March 31, 2020.*

