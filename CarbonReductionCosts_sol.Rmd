# Problem Set: Estimating CO2 Reduction Costs

Author: Daniel Dreyer

#< ignore
```{r ""}
library(restorepoint)
# facilitates error detection
# set.restore.point.options(display.restore.point=TRUE)
library(RTutor)
library(yaml)
#library(restorepoint)
setwd("X:/libraries/RTutor_BA")
ps.name = "CarbonReductionCosts"; sol.file = paste0(ps.name,"_sol.Rmd")
libs = c("dplyr", "ggplot2", "gridExtra", "stargazer", "tidyverse", "ggalt",  "splines", "kableExtra") # character vector of all packages you load in the problem set
name.rmd.chunks(sol.file) # set auto chunk names in this file
create.ps(sol.file=sol.file, ps.name=ps.name, user.name=NULL,libs=libs, stop.when.finished=FALSE, addons="quiz") # extra.code.file="dp.R", var.txt.file ="variables.txt")
show.shiny.ps(ps.name, load.sav=FALSE,  sample.solution=TRUE, is.solved=TRUE, catch.errors=TRUE, launch.browser=TRUE)
stop.without.error()
rtutor.package.skel(sol.file=sol.file, ps.name=ps.name,libs=libs,
                    pkg.name="RTutorCarbonReductionCosts",   # Name of the problem set package
                    pkg.parent.dir = "X:/libraries/RTutor_BA", # Parent directory 
                    author="Daniel Dreyer", # Your name
                    github.user="daniel.dreyer",     # Your github user name
                    extra.code.file="dp.R", # name of extra.code.file
                    var.txt.file="variables.txt",    # name of var.txt.file
                    overwrite=FALSE  # Do you want to override if package directory exists?
)
```
#>

<style>
img {
    display: block;
    margin-left: auto;
    margin-right: auto;
    max-width: 100%;
}
</style>

Welcome to this interactive problem set. The awareness of climate change rose significantly over the past years. Purely questioning the moral of the population though, won't avoid its' highly uncertain effects. Therefore high efforts are made to find technical improvements as well as economical incentitives to avoid long term effects of climate change.   
In this problem set we will approach one possible countermeasure by analysing how carbon pricing would reduce emissions in the electricty sector. The analysis is based on **"Inferring Carbon Abatement Costs in Electricity Markets: A Revealed Preference Approach using the Shale Revolution"** by Joseph A. Cullen, Erin T. Mansur (2016) - further simply referred as Cullen (2016). The paper and further ressources can be downloaded from <a href="https://www.aeaweb.org/articles?id=10.1257/pol.20150388   target = "_blank"> https://www.aeaweb.org/articles?id=10.1257/pol.20150388</a>

You will use the `Statstical Programming Language R` to replicate the analysis. Basic knowledge of `R` is required, but information on important function will be provided. 
Since each new exercise inherits the results of previous exercises, it is recommendated to solve them in order. However you are free to skip to any exercise you like if you feel so.  
If you are a complete novice in `R` you should not feel left behind. Understanding the basic concepts is straight forward, you can find useful information [here](https://cran.r-project.org/manuals.html).



### Contents

$\qquad$  Overview
  
$\qquad$  1 TBA

$\qquad$  2 TBA

$\qquad$ $\qquad$ 2.1 

$\qquad$  3 TBA

$\qquad$  4 TBA

$\qquad$  5 Conclusion

$\qquad$ References


## Exercise Content

$\qquad$ *Exercise 1* - Motivation (rename later)

$\qquad$ *Exercise 2* - TBA

$\qquad$ *Exercise 3* - TBA

$\qquad$ *Exercise 4* - TBA

$\qquad$ *Exercise 5* - TBA


### ReadME


The problem set offers different ways to interact with it. Coding exercises are marked as **TASK**. Some only need to be run, for others you need to complement a small part of the code, which is noted in the task description. Below you can read about the different types of interactions with their corresponding functions:   


 - Code Chunks: Require you to complete small parts of Code. The work flow of solving code chunks is intuitive and as follows:
                
  + `edit` : Click to insert your own Code into the chunk.
  + `run chunk`: Runs the chunk and displays outputs or errors in the corresponding console.
  + `check`: Check your input for against the solution.
  + `hint` : Should you have problem to solve a task, you can request a hint.  
&nbsp;

  
  Additional functions:    
                   
  + `data`: Redirects you to the data browser - you can view the loaded data with the help of an interface.
  + `solution` : Shows the solution of the task.  
&nbsp;

  
 - Quizzes: Evaluate your knownledge of topics before we dive in our analysis.
    
 - Info Boxes: Contain additional information on technical terms or documentation of functions.
 

After you finish a chapter, click `Go to next exercise` on the bottom or navigate around with the help of the bar on top.


## Exercise 1 -- Motivation

`Coal` is the **world's biggest source of energy and carbon emissions**, mostly because it is easy to store, transport, doesn't alter and can be mined in huge quantities around the world. This makes it desirable and cheap to use as a energy source. Given that the coal supply will last for decades, it is a major goal to find incentitives to reduce emissions from coal consumption.  
One alternative to coal is `natural gas`. Even though still being a fossil fuel, its' emissions and heat density are way superior to coal. Nevertheless, natural gas wasn't considered to be an real alternative to coal because to its higher prices more difficult handling up until the early 2000s.  
This changed due to the `Shale Revolution`, whereby natural gas was not only a by-product of the oil industry, but could now be extracted in a targeted manner and in large quantities. Lanfrancois (2012) estimates, that based on the Clean Power Plan introduced by the Obama administration in 2015, carbon dioxide emissions from the electricity industry could be reduced by 23 to 42 percent by switching existing coal powered generators to gas powered ones.  
  
#< info "Shale-Revolution"
Shale gas is a form of natural gas and is extracted from shale formation, known as fracking. Since the start of the century, shale gas became a increasingly more important source of natural gas in the United States. Whereas in 2000 shale gas only provided 1% of the natural gas, nowadays in 2020 it makes up roughly 50%.
However at the same time, the environmental concerns of fracking are heavily debated.  

You can find further information on the topic here:  
<a href="https://en.wikipedia.org/wiki/Shale_ga   target = "_blank"> https://en.wikipedia.org/wiki/Shale_gas</a>s  
<a href="https://en.wikipedia.org/wiki/Hydraulic_fracturing   target = "_blank"> https://en.wikipedia.org/wiki/Hydraulic_fracturing</a>
#>
  
With this in mind, in `Exercise 1` you will explore data to get insights in the current situation of the U.S. energy sector. You will look at the distribution of energy sources in the American market, its prices and the generated load over time.  

**Task:**
Use the `read_csv` command to *load the data set* and store it in a variable called `PaGP`.
The basic structure of the command is already given in the code chunk as a comment.

#< info "read.csv() and write.csv()"
The command `read_csv()` reads in a **csv file** and stores it into a given name. Csv is a format for data, that uses commas as seperators and periods as decimals. Another version of are **csv2 files**, where semicolons are used for seperators and commas for decimals. We only use csv files here.

Given the file you want to read it is in the same working directory, you can use the command below:

```{r "1",eval=FALSE}
example <- read_csv("example.csv")
```

If the file is saved outside of your working directory there are two possibilities. For one you can insert the whole file path, if the file is you can navigate through the whole file path if your file is above 

If the file is saved in an structure above your working directory you have to additionally insert the full file path:

```{r "1__2",eval=FALSE}
example <- read_csv("C:/Data/example.csv")
```

For files that are located below the working directory it is sufficient to specify the following file path:

```{r "1__3",eval=FALSE}
example <- read_csv("./Data/example.csv")
```


Csv files can be saved using the `write.csv` command.

```{r "1__4",eval=FALSE}
write_csv(example, file="example.csv")
```

For further information, use `help(write.csv)`.
#>

```{r "1__5"}
#< task
# ... <- read_csv("./Data/PaGP.csv")
#>
PaGP <- read_csv("./Data/PaGP.csv")
#< hint
display("Replace the variable name with the one given in the exercise description. No other changes are needed.")
#>
```


**Task:** Lets take a look at the data we just imported. Use the `head()` command to show the first **eight** rows of the data set. 


```{r "1__6"}
#< task
# head(PaGP, ...)
#>
head(PaGP, 5)
#< hint
display("The second input parameter defines the number of row that are shown. Replace ... with the number from the task description.")
#>

```


Alternatively you can press the `data` button to get redirected to the `Data Explorer` Tab. 

The date column is currently stored as a character. To be able visualize the date variable as a continuous variable, we have to convert is. Therefore, R has a build in date class.  
**Task:** Just press *check*.

```{r "1__7"}
#< task_notest
PaGP <- as.data.frame(PaGP)
PaGP$date <- as.Date(PaGP$date)
#>
```

  
The data frame contains monthly numbers of generated MwH with coal and gas as well as prices of Energy commodities. 
Keep in mind that different commodities are traded in different units. Oil is traded in barrels (\$/bbl), coal in metric tons (\$/mt) and gas in British thermal units($/mmbtu). The natural gas index is
set to 100 in the year 2010 and changes accordingly.
Prior to visualizing the data and to get clearer results, lets modifiy the data set. As mentioned before, commodities are traded in different units. Therefore we will add new entries for normalized
prices, which gives us a good cost basis to produce the same amount of energy with each commodity.  On this account, we assume that `1 MwH = 0.454 mT Coal = 3.412 mmBtu Natural Gas`.

**Task:** Perform the above calculations. Just press *check*.
  
#< info "Pipe, mutate, select"
The pipe operator `%>%` is a feature provided by the `dplyr` Package. Essentially it allows to exectute multiple operation on a dataframe at once.
This works the way that every pipe operator returns a dataframe and passes it to the next connected function. `Select` allows you to filter out certain columns of data, whereas `mutate` allows you to
alter data. The counterpart for selecting specific rows is `filter`. There are several more functions to alter your data, below i linked a handy cheatsheet.
  
```{r "1__8",eval=FALSE}
example %>% 
  select(1:5)  `select: keep certain columns, here column 1 to 5`  %>% 
  mutate(new_column = old_column+1)`mutate: create or alter columns`    

```

You can find a more detailed cheatsheet [here](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) or use the `help()` function.
#>

#< info "ggplot2"
The package `ggplot2` is a powerful data visualization package for `R`, which is part of the `tidyverse` environment. Besides basic functions that are also provided by native `R`, it allows the user to
highly modify graphs by **altering**, **adding** or **removing** components.

The problem set doesn't require you to have deeper knowledge about function of `ggplot2`. However, you can find further documentation [here](https://ggplot2.tidyverse.org/) or type `help(ggplot2)`.
#>


```{r "1__9"}
PaGP <- PaGP %>% 
  mutate(price_naturalgas_USA_normalized = price_naturalgas_USA * 3.412,
         price_naturalgas_Europe_normalized = price_naturalgas_Europe * 3.412,
         price_coal_australia_normalized = price_coal_australia * 0.453, 
         price_coal_africa_normalized = price_coal_africa * 0.453)
```

**Task:** Output a graphic. Just press *check*.
```{r "1__10"}
#< task_notest
ggplot(data=PaGP, aes(x=date)) +
  geom_line(aes(y=PaGP$price_coal_australia_normalized, color="Coal Autralia"), size=1) +
  geom_line(aes(y=PaGP$price_coal_africa_normalized, color="Coal Africa"), size=1) +
  geom_line(aes(y=PaGP$price_naturalgas_USA_normalized, color="Gas US"), size=1) +
  geom_line(aes(y=PaGP$price_naturalgas_Europe_normalized, color="Gas Europe"), size=1) +
  labs(x = "Year", y = "", title = "Normalized Ressource Prices", subtitle = "Y=$/MwH")+
  scale_color_manual(name="Region",values = c("green", "yellow", "blue","red"))
#>
```

TEXT


In the next Step we will look at the generated Power for Coal / Gas in the U.S. 



#< quiz "Proportion of Sectors"
question: Do you think that the proportion of gas generated electicity compared to coal generated electricity has increased or decreased over time?

sc:
    - increased*
    - decreased
success: Great, your answer is correct!
failure: Try again.
#>  
&nbsp;




**Task:** Just press *check*.

```{r "1__11"}
#< task_notest
ggplot(data=PaGP, aes(x=date)) +
  geom_line(aes(y=PaGP$generated_coal, color="Coal Generation (TWh)"), size=1, alpha=0.5) +
  geom_line(aes(y=PaGP$generated_gas, color="Natural Gas Generation (TWh)"), size=1, alpha=0.5) +
  labs(x = "Year", y = "", title = "Monthly Generation by Fueltype", subtitle = "Y=Monthly Electricty (TWh)")+
  scale_color_manual(name="",values = c("black","red"))+
  scale_y_continuous(breaks=seq(0,200,25))
#>
```

TEXT

#< award "Starter Kit"
Good Start! You will earn awards at the end of every chapter. At the end you will see how many you have earned.
#>


## Exercise 2 -- Interconnections // mapping carbon prices???

![Interconnections](./Material/interconnections.png) (SOURCE)

#< info "Interconnections"
The American Electric system is made up of three major `Interconnections`, which in turn concist of different balancing authorities (responsible for maintaining the electricity balance within the region).
Local electricity grids are hereby connected to form a network, which provides higher stablity and reliability of electricity. These `Interconnections` are operated independently of each other and, in contrast to the European electricity grid, there is little transfer of power.  
The 3 regions, as seen in the graph above, are as followed:
- Easter Interconnection: Consists of 36 balancing authorities and extends from the East Coast to the Rocky Mountains.
- Western Interconnection: Involves 37 balancing authorities, which are located in the West of North America.
- Electric Reliability Council of Texas (ERCOT): Consists of large parts of Texas
#>

**Task:** Just press *check*.
```{r "2"}
#< task_notest
Emissions <- read.csv("./Data/Emissions_Unit_Type.csv")
#>
```

wip

HIER HIN????????????
**Task:** Just press *check*.

#< info "geom_encircle"
`Geom_encircle()` is part of the package `ggalt` which extends functionality of `ggplot2`. Besides standard functionality for plotting points or lines that is provided by basic `ggplot2`, it provides a advanced framework for visualising your data. `Geom_encircle()` automatically encloses points in a polygon and can be used to visualise differences in groups of data.

Call `help(geom_encircle)` to get further information.
#>

```{r "2__2"}
#< task_notest
ggplot(dat,aes(x=gasprice,y=co2mass/1000,color=intercn))+
        geom_point(alpha=0.2) +
        geom_encircle(aes(group=intercn,fill=intercn),alpha=0.3, s_shape=1) +
        theme_bw()+ 
        labs(y="", 
        x="Gas Price", 
        subtitle="y=CO2 Emissions in 1000s tons/day",
        title="CO2 Emissions vs. Gasprice")
#>
```

TEXT



### theory behind mapping carbon prices


$$\tag{1}MC=HR\cdot(P_{fuel}+CO_{2,fuel}\cdot P_{co2})=HR\cdot C_{fuel}$$

einfuehren priceratio auf basis von tabelle oben - hohe varianz

theory hier,

warum carbon prices steht da!





## Exercise 3.1 -- Priceratio Regressions

In this exercise we briefly go over the data we use for our main analysis and give an overview what we will be doing in the following exercises. The main question of this problem set is to find out
how carbon prices would effect emissions in the energy sector. To answer this we will construct a statistical model to understand the emission behaviour for changing input costs while controlling
for variables that effect the energy market. However we won't simply propose a final model but will work our way from simple linear regressions to more complex but also more accurate models.  
&nbsp;

Until now we got an idea how the energy market is 
In this and the following chapter we will take a look at regression theory and develop a model that satifies our statistical needs tor answer our initial question on how changing commodity prices will effect $CO_2$ emissions. We start with simple regressions and introduce new methods along the way to make our model more precise.


If you want to go faster through the problem set without the theoretical background, you can skip to exercise `4.1` onwards, where we present the final model and visualize our results.

//////////// neu data frame nur mit co2mass gas coalprice

**Task:** To get started, load the data set `exercise3.csv`, press `edit` and `check` afterwards.

```{r "3_1",message=FALSE}
#< task_notest
dat <- read_csv("Data/exercise3.csv")
head(dat,3)
#>
```

We have seen in the previous exercise that it makes sense to calculate our model for each intersection separately. For this purpose we filter our data for intersection `EAST` and develop the model based on that `intersection`. Afterwards we will use the model on each intersection. Since we observe substantial variation in coal and gas prices, we construct a new variable for relative costs `priceratio`. There are several ways to propose price ratios, we use the ratio between the price of coal and gas, which is defined as followed:  

As we have seen in the last chapter it makes sense to apply our analysis for each intersection `separately`. For this reason the data are divided into interconnections. We `develop` our model based on the `EAST` interconnection and map the model to all at a later point in time.  







$$\tag{2}CR=\frac{C_{coal}}{C_{gas}}=\frac{P_{coal}+CO_{2,coal}\cdot P_{co2}}{P_{gas}+CO_{2,gas}\cdot P_{co2}}$$

THe question here is, why use a priceratio and not just coal and gas prices seperatly.  ///////// why priceratio - paper 18 absatz 2


**Task:** The data set contains a column `intercn` with values `EAST`, `WEST` and `ERCOT`. Filter only for data with interconnection `EAST` and store the new data frame in variable `dat_east`. Additionally, calculate the cost ratio between `coalprice` and `gasprice` according to formula 2.
```{r "3_1__2"}
#< task
# ... <- data %>% 
#  mutate(CR = .../...) %>% 
#  filter(intercn=="...")
#>
dat_east <- dat %>% 
  mutate(priceratio = coalprice/gasprice) %>%
  filter(intercn=="EAST")
#< hint
display("Replace the variable name with the one given in the exercise description and filter for EAST.")
#>
```


### Stage 1: Linear Regression

We start by proposing a simple linear regression model. In a mathematical way we can express the relationship as followed:

$$\tag{3}CO_{2t}=\beta_{0}+\beta_{1}\cdot priceratio_{t}$$


#< info "Linear Regression with lm()"

`lm()` is part of the `stats` package and loaded on default. As shown in the syntax example below, it enables you to regress `y` on the indepedent variables `x1` and `x2`. The model can be `stored` in a variable or directly `used` in other functions. Another popular function to solve linear regressions in `R` is `felm()`, that provides further functionality to include `fixed effects`. In this problem set we will strictly use `lm()`.

```{r "3_1__3",eval=FALSE}
example <- lm(y~x1+x2, data=dat_east)
```

You can find more information on the `lm()` function [here](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm) or use the `help()` function.
#>

**Task:** Run a regression with `co2mass` as the dependent variable and `priceratio` as independent variable. Store it in the variable `fit1`. 
```{r "3_1__4"}
#< task
# ... <- lm(...~... , data=east)
#>
fit <- lm(co2mass ~ priceratio, data=dat_east)
#< hint
display("Fill in the variables given in the description. The dependent variable is the variable we want to explain.")
#>
```

#< quiz "Reg1"
question: What impact do changing price ratios have on emissions?

sc:
    - With increasing price ratios emissions will increase.
    - With increasing price ratios emissions will fall.*
success: Great, your answer is correct!
failure: Try again.
#>  


TEXT

**Task:** To
```{r "3_1__5"}
#< task_notest
summary(fit)
#>
```

$\beta_{1}$

The summary statistics shows as a positive value for priceratio $\beta_{1}$, which means that a increasing price ratio decreases emissions.


For upcoming regressions we will use the `stargazer()` function from the `stargazer` package to show summary statistics from our regressions. We don't need get every information the basic functions displays, therefore we define a own custom function with statistics we need. Read below to find out more about `stargazer` and `custom functions` and continue with the next `task`.

#< info "Stargazer"
`stargazer` provides specialised `HTML` formatting for regression tables and summary statistics tables. It is easy to use, supports a large number of model types and formats data in a more pleasing way. The basic function is called by `stargazer()`, but can be customized heavily. For more information run `help(stargazer)` or read further [here](https://cran.r-project.org/web/packages/stargazer/).
#>

#< info "Custom functions"
`R` provides an easy framework to add your own functions. The syntax is quite similar to other `Programming Languages` you could be familiar with. Once you have defined a function, you can use it as long as you are in the same session. Below you can find the basic structure of a function:

```{r "3_1__6",eval=FALSE}
`myfunction <- function(arg1, arg2, ... ){`  
`statements`  
`return(object)`  
```  
Here's an simple functions that adds `5` to the input and returns it.
```{r "3_1__7",eval=FALSE}
`example <- function(x) {`  
  `x + 5`  
`}`  
`example(1)`
```  
You can find more detailed information [here](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/function).

#>

**Task:** Click check to run the Code. It defines the function to show our custom regression tables.
```{r "3_1__8"}
#< task_notest
show.regression= function(...){
  library(stargazer)
    stargazer(..., 
            type = "text", 
            style = "aer",  
            digits = 3,
            df = FALSE,
            report = "vct*",
            star.cutoffs = c(0.05, 0.01, 0.001),
            model.names = FALSE,
            object.names = TRUE,
            model.numbers = FALSE, 
            omit.stat=c("f", "ser")
    )
} 
show.regression(fit)
#>
```

Our eventual goal is to plot the rensponse curves of changing ??AWD prices 



**Task:** To
```{r "3_1__9"}
p1 <- predict(fit, newdata = dat_east)
```


#< info "Predict"
`predict()`
#>

**Task:** To
```{r "3_1__10"}
plot(co2mass~priceratio, dat_east)
lines(dat_east$priceratio, p1, col="red")
```




**Task:** Let's see what we just defined. Run the regression table for the linear model. Insert 
```{r "3_1__11"}
#< task
# regression.result(...)
#>
show.regression(fit)
#< hint
display("Insert the name of the model you defined at the beginning of this exercise.")
#>
```

TEXT

**Task:** To
```{r "3_1__12"}
plot(fit, 1)
plot(fit, 2)
```

QQ PLOT RESIDUALS?

#< info "R-squared"
`R-Squared` is a statistical measurement that represents the correlation between `fitted values` and `observed values`. `R-squared` is always positive and ranges from 0 to 1. A value closer to 1 indicates that the suggested model explains a majority of the variance in the outcome variable.  
$R^{2}=1-\frac{Explained Variation}{Total Variation}$
A problem with the `R-squared` measurement is, that it always increases with higher numbers of variables in the model, even if these variables are only weakly responsible for the predicted values. An solution is to take the number of variables into account, this is called `Adjusted R-Squared` and also shown in the summary output.
#>

### Stage 2: Polynomial Regression

**Task:** Just press *check*.
```{r "3_1__13"}
CR.squared <- east$CR^2
fit2 <- lm(CO2MASS ~ CR + CR.squared, east)

CR.cubed <- east$CR^3
fit3 <- lm(CO2MASS ~ CR + + CR.squared + CR.cubed, east)
```

**Task:** Just press *check*.
```{r "3_1__14"}
p2 <- predict(fit2, east)
p3 <- predict(fit3, east)
```

**Task:** Just press *check*.
```{r "3_1__15"}
plot(CO2MASS~CR, east)
lines(east$CR, p1, col="red")
lines(east$CR, p2, col="blue")
lines(east$CR, p3, col="green")
```

**Task:** Just press *check*.
```{r "3_1__16"}
regression.result(fit, fit2, fit3)
```

**Task:** Just press *check*.
```{r "3_1__17"}
anova(fit, fit2, fit3)
```



## Exercise 3.2 -- Restricted Spline Regressions

### Stage 3: Cubic Spline



#! start_note "Cubic Splines?"
Explain Cubic Splines

```{r "3_2",optional=TRUE}
#< task
# show that all integers between 0 and 10
#>
1:10
```

#! end_note 


simple cubic splines

$$\tag{4}CO_{2t}=s(CR_{t}|\beta)$$
#< info "ns()" 
`Ns()` is part of the `splines` package and allows us to perform natural splines regressions on our data. It takes several input arguments, the only one we will use is `df` which sets the degrees of freedom. 

#>


First, we have to define our model 




#< award "Linear Regression Expert"
TEXT
#>












## Exercise 4 -- ???

In this chapter we will carry out our main analysis. Before 


In this exercise we present the data we use for our analysis and give an overview what we will be doing in the following exercises. The main question of this problem set is to find out
how carbon prices would effect emissions in the energy sector. 



answer this we will construct a statistical model to understand the emission behaviour for changing input costs while controlling
for variables that effect the energy market. However we won't simply propose a final model but will work our way from simple linear regressions to more complex but also more accurate models.  
&nbsp;

 - You can find a rough guideline of content in each exercise below:
  + `Exercise 4.1` - Estimated CO2 Response to Fuel Prices
  + `Exercise 4.2` - Imputed CO2 Response to Carbon Prices
&nbsp;
  
Before we take a look at the data, import our dataset.

**Task:** Load the data set `main_data.csv`, press `edit` and `check` afterwards.

```{r "4",message=FALSE}
#< task_notest
dat <- read_csv("Data/main_data.csv")
head(dat,3)
#>
```
&nbsp;

The data frame is a combination of data we used previous exercises and additional factors. It consists of `daily` information for `each interconnection`. The meaning of each column is explained below:

`co2mass`: $CO_2$ emissions in tons  
`gasprice`: Capacity weighted average daily gas price per interconnetion ($ per million BTU)  
`coalprice`: Price of Coal ($ per million BTU)  
`load`: daily electricity consumption per interconnection in MWH  
`meant`: average daily temperature per interconnection  
`nonFossil`: Electricity generation with non-fossil fuel in MWH  
`so2price`: Permit prices of $SO_2$ ($/ton)  
`netNSflow`: MwH flowing from Canada to US by interconnection and month  

The data are gathered from several official U.S. agencies and aggregated to a daily level and seperated by interconnection. Because of the size of these data sets we wont do the data
preparation in this problem set but rather provide the data sources. `Emission` data are measured by the Continuous Emissions Monitoring System (CEMS) of the `Environmental Protection Agency (EPA)`.
The U.S. Energy Information Administration (EIA) collects data of `Non-fossil` energy production as well as spot prices of `coal prices` in Form 923. Spot prices of `gas` can be found in
`Intercontinental Exchange (ICE)`. Data of `electricity consumption` or `load` are provided in Form 714 of the `Federal Energy Regulatory Commission (FERC)`, permit prices of $SO_2$ from the `EPA Clean Air Markets` and finally, `net imports` of electricity from Canada are gathered from the `National Energy Board of Canada`. Links to the sources can be found in `references section`.


When choosing control variables we have to be sure that they directly effect the emissions 

To give us an overview of the data, lets create a table with average values for relevant factors for each interconnection. R provides several packages that , but for now we work with packages we
introduced before and solve this with `dyplr`.  

**Task:** Use `group_by()` to group the dataset `dat` by `intercn`. Afterwards use `summarise_all()` to calculate the means of every variable. You don't have to deal with the additional lines of code, which is used to create a more understandable output.

#< info "Group_by() and summarise()"
`Group_by()` allows you to group a data frame by specific variables. Operations that are run on the grouped data frame are then performed on each group.

The function `Summarise()` is run on **grouped data** and can perform operations e.g. calculating means (`mean()`) or finding minimums (`min()`). There are several
pre-implemented version of `summarise` function in `R`. The one we use here is `summarise_all()`, which performs these operations on all columns.

To give you an example in code form, lets pretend we have a dataframe `data` with several `car manufacturer` and their respective car models with `prices` and we want to calculate the average car price per manufacturer.

```{r "4__2",eval=FALSE}
example <- data %>% 
  group_by(manufacturer) %>%
  summarise(mean_price = mean(price))
```

Call `help(group_by)` or `help(summarize)` for further information.
#>

```{r "4__3"}
#< task
#... %>% 
#  select(intercn, co2mass, load, gasprice, coalprice) %>% 
#  group_by(...) %>% 
#  ...("mean") %>% 
#  mutate(co2mass = co2mass/1000, load=load/1000, "Emission Rate"=co2mass/load, "Cost Ratio"=coalprice/gasprice) %>% 
#  rename("CO2 Emissions"=co2mass, Load=load, "Gas Price"=gasprice, "Coal Price"=coalprice)
#>
dat %>% 
  select(intercn, co2mass, load, gasprice, coalprice, nonfossil) %>% 
  group_by(intercn) %>% 
  mutate(co2mass = co2mass/1000, load=load/1000, "Cost Ratio"=coalprice/gasprice, "Emission Rate"=co2mass/load, "Non fossil"=nonfossil) %>% 
  summarise_all("mean") %>% 
  rename("Interconnection"=intercn, "CO2 Emissions"=co2mass, Load=load, "Gas Price"=gasprice, "Coal Price"=coalprice)
```

The table replicates table 1 from Cullen (2016). As we easily observe the interconnections are vastly different energy markets. While the EAST interconnection is a lot bigger than the other, it also 


/// graph einheiten y achse
































## Exercise 4.1 -- Estimated CO2 Response to Fuel Prices

in this exercise we will use the findings of the previous exercises and estimate the $CO_2$ response curves to changing fuel prices. 

In this exercise we will estimate the $CO_2$ respone curve to changing fuel prices. We will construct a response for each `interconnection` seperatly

Our goal is to plot a response curve 

As a side note, the code isn't meant to be the shortest or the most efficient, but should allow you to follow the steps to get the desired result. We will split the analysis in the different interconnections we presented in a previous exercise


In this exercise we will expand our results from the previous exercise and estimate the $CO_{2}$ respone to changing fuel prices. 
To summarise the results from last exercises and to understand why we do certain methods this way, lets summarise. In exercise ?.? we showed that it makes sense to split our analysis in different connection. 

Getting the results we want isn't so easy, but we will take it step by step. First we will 


The model incorporates the findings of previous exercises. Lets look at a quick summary:

We seperate the model in each interconnection
.
.


In this and the following exercise we combine the model theory we introduced in section 3 with the background knowledge of section 2. First, we will estimate $CO_2$ response curves to changing fuel prices. 






In the following exercises, we want to derive the environmental damages caused by electric cars and analyze them. This will allow us to compare gasoline and electric vehicle damages later on. Our approach to compute electric vehicle damages involves several steps:

First, we determine how much energy an electric car uses to drive one mile. As the energy consumption of electric vehicles is dependent on the outside air temperature, we perform a temperature adjustment to get more realistic values.

Second, we estimate the emissions caused by the consumption of an additional kilowatt hour of electricity in a specific area. To do so, we perform an econometric analysis using data on the load in the different areas and emission data from U.S. power plants.

Third, I explain how these emissions can be mapped into monetary damages using an integrated assessment model called the AP2 model.

Fourth, we assume an electric vehicle charging profile and combine the results from the previous exercises.

Last, we analyze the resulting electric vehicle damage values.

Let's get started.





As a side note, the code isn't meant to be the shortest or the most efficient, but should allow you to understand every we take to get our final results. Based on the results of `exercise 4` we will split the analysis in `each` interconnection. Based on this we will explain and carry out the analysis step by step for interconnection `EAST`, afterwards apply it to `ERCOT` and `WECC` and interpret our results.




In this exercise we will estimate the $CO_2$ response curve to `changing` fuel prices. 


Building upon the model we defined in the last chapter, we will expand our regression model with several control variables as followed. The meaning and source of data to every variable is explained in the info box below:


We will perform a reduced-form regression based in the theory of mapping carbon we introduced in exercise `?????` and cubic splines from exercise `3.2`.

$$\tag{5}CO_{2t}=s(priceratio_{t}|\beta)+s(load_{t}|\theta) + s(temp_t|\omega)+X_t\psi+D_\gamma+\epsilon_t$$

#< info "Model variables" 
$CO_{2t}$: CO2 emissions in tons  
$priceratio_{t}$: Capacity weighted average daily gas price per interconnetion ($ per million BTU)  
$load_{t}$: daily electricity consumption per interconnection in MWH  
$temp_{t}$: average daily temperature per interconnection  
$X_{t}$: Factors like non-fossil electricity production (e.g. solar, hydro or wind), $SO_{2}$ price, net imports of electricity from Canada and variance in load  
$D_\gamma$: Dummy variable for seasonal variation to absorb fluctuations, e.g. by renewable energies.
#>

First, as in every exercise we have to import our data set. Following we will perform a number of manipulations on the data frame to be able to run our regression model and predict the response curves.


**Task:** Load the dataframe and store it in `dat`. Create a new variable called `priceratio` and calculate the ratio $priceratio=\frac{C_{coal}}{C_{gas}}$. To save us another step, we will also create the seasonable dummy variable. 
```{r "4_1",message=FALSE}
dat <- read_csv("Data/main_data.csv")  %>% 
       mutate(priceratio = coalprice/gasprice,
              season=(month>3) + (month>6) + (month>9),
              yearseason=year*10+season)
basecoal=2.25
basegas=5.75

head(dat)
```

**Task:** Filter the data set for intercn `EAST`.
```{r "4_1__2"}
#< task
#east <- filter(...,...)
#>
east <- filter(dat, intercn=="EAST")
#< hint
display("Filter() takes a data frame as first argument and a logic as second. We want to filter for intercn EAST.")
#>
```

**Task:** Calculate the `mean` of every variable we use in our regression. First, select the necessary columns and then use `summarise_all` to get the `mean`. Store the result in `mean_dat_east`.
```{r "4_1__3"}
#< task
# ... <- east %>% 
#  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
#  summarise_all(...)
#>
mean_east <- east %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)
#< hint
display("In this case, you can insert the mathematical operation directly into summarise_all().")
#>
```


**Task:** To make our life a bit easier we will create a new data set with `gasprice`, `priceratio` and the results of the `last` task. Use `tibble()`, which creates a new data frame and `cbind()`, which takes a sequence of columns and combines them with another data frame.

```{r "4_1__4"}
#< task
#temp_east <- ...(gasprice = east$gasprice, priceratio = east$priceratio) %>% 
#  ...(mean_east)
#>
predict_east <- tibble(date=east$date, intercn=east$intercn, gasprice = east$gasprice, coalprice=east$coalprice, priceratio = east$priceratio) %>% 
  cbind(mean_east)
```

Our data are now ready to be used on our model. We have the necessary data for our regression model in the data set `east` and afterwards we can predict `emissions` with the help of data in `mean_dat_east`.



**Task:** Perform the regression model we described in the beginning of this exercise for interconnection `EAST`. Use `ns()` for variables with spline regression (as explained in `3.3`). We want to use `5` degrees of freedom. Store the resulting model in `reg_east`.
```{r "4_1__5"}
#< task
#... <- lm(co2mass ~ ...(priceratio, df=...) + ...(load, df=...) + tlsd + tlmin + tlmax + ...(meant, df=...) + nonfossil + so2price + netNSflow + yearseason, data=east)
#>
reg_east <- lm(co2mass ~ ns(priceratio, df=5) + ns(load, df=5) + tlsd + tlmin + tlmax + ns(meant, df=5) + nonfossil + so2price + netNSflow + yearseason, data=east)
```

**Task:** Predict $CO_2$ emissions based on the regression model `reg_east` and `temp_east`. We set interval to `confidence` to get the mean interval and be able to plot a confidence band later on.
Just press *check*.

#< info "Confidence interval" 
A confidence interval answers the question for which defined probability the data points lie within the interval. Mathematically, given we have observations $x_1...x_n$ and a confidence level $\gamma$, a confidence interval has a probability $\gamma$ to contain the true underlying parameter. Most commonly, and also in our case, we use
the 95% confidence interval and is defined as: 

$$\hat{y_h} Â± t_{\alpha/2,n-2} \sqrt{MSE \frac{1}{n}+\frac{(x_k-\overline{x})^2}{\sum x_i-\overline{x}^2)}}$$
where $\hat{\gamma}$ is the fitted response, $t_{\alpha/2,n-2}$ the t-value with n-2 degrees of freedom and the equation inside the square root represents the standard error.
#>

```{r "4_1__6"}
#< task_notest
fit_east <- predict_east %>% 
  cbind(as.data.frame(predict(reg_east, newdata = predict_east, interval = 'confidence')))


#co2.east$fit
#temp_east = temp_east %>% cbind(as.data.frame(predict(reg_east, newdata = temp_east, interval = 'confidence')))
#>
```

**Task:** Just press *check*.
```{r "4_1__7"}
diff_base <- abs(east$priceratio - (basecoal/basegas))
min_dif <- min(diff_base)
closest <- min_dif==diff_base
base_emit <- mean(fit_east$fit[which(closest)])

final_east <- fit_east %>% 
  mutate(fit.transformed=fit/base_emit-1,
         lwr.transformed=lwr/base_emit-1,
         upr.transformed=upr/base_emit-1)
```

**Task:** Just press *check*.
```{r "4_1__8",warning=FALSE, fig.width=7, fig.height=7}
#< task_notest
plot_east <- ggplot(final_east, aes(x=basecoal/priceratio, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = final_east$lwr.transformed, ymax = final_east$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  labs(title="Eastern Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()

plot_east
#>
```

TEXT////



**Task:** Run the code for the `ERCOT` interconnection. Just press *check*.
```{r "4_1__9",warning=FALSE, fig.width=7, fig.height=7}
#< task_notest
ercot <- filter(dat, intercn=="ERCOT")

mean_ercot <- ercot %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)

predict_ercot <- tibble(date=ercot$date, intercn=ercot$intercn, gasprice = ercot$gasprice, coalprice=ercot$coalprice, priceratio = ercot$priceratio) %>% cbind(mean_ercot)

reg_ercot <- lm(co2mass ~ ns(priceratio, df=5) + ns(load, df=5) + tlsd + tlmin + tlmax + ns(meant, df=5) + nonfossil + so2price + netNSflow + yearseason, data=ercot)

#ERCOT has no net imports of electricity, predict throws warning
fit_ercot <- predict_ercot %>% 
  cbind(as.data.frame(predict(reg_ercot, newdata = predict_ercot, interval = 'confidence')))

#base_emit <- mean(fit_ercot$fit[which(min(abs(ercot$priceratio - (basecoal/basegas)))==abs(ercot$priceratio - (basecoal/basegas)))])

diff_base <- abs(ercot$priceratio - (basecoal/basegas))
min_dif <- min(diff_base)
closest <- min_dif==diff_base
base_emit <- mean(fit_ercot$fit[which(closest)])

final_ercot <- fit_ercot %>% 
  mutate(fit.transformed=fit/base_emit-1,
         lwr.transformed=lwr/base_emit-1,
         upr.transformed=upr/base_emit-1)


plot_ercot <- ggplot(final_ercot, aes(x=basecoal/priceratio, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = final_ercot$lwr.transformed, ymax = final_ercot$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  labs(title="ERCOT Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()
#>
```

**Task:** Run the code for the `WECC` interconnection. Just press *check*.
```{r "4_1__10",warning=FALSE, fig.width=7, fig.height=7}
#< task_notest
wecc <- filter(dat, intercn=="WECC")

mean_wecc <- wecc %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)

predict_wecc <- tibble(date=wecc$date, intercn=wecc$intercn, gasprice = wecc$gasprice, coalprice=wecc$coalprice, priceratio = wecc$priceratio) %>% cbind(mean_wecc)

reg_wecc <- lm(co2mass ~ ns(priceratio, df=5) + ns(load, df=5) + tlsd + tlmin + tlmax + ns(meant, df=5) + nonfossil + so2price + netNSflow + yearseason, data=wecc)

#ERCOT has no net imports of electricity, predict throws warning
fit_wecc <- predict_wecc %>% 
  cbind(as.data.frame(predict(reg_wecc, newdata = predict_wecc, interval = 'confidence')))

base_emit <- mean(fit_wecc$fit[which(min(abs(wecc$priceratio - (basecoal/basegas)))==abs(wecc$priceratio - (basecoal/basegas)))])

final_wecc <- fit_wecc %>% 
  mutate(fit.transformed=fit/base_emit-1,
         lwr.transformed=lwr/base_emit-1,
         upr.transformed=upr/base_emit-1)

plot_wecc <- ggplot(final_wecc, aes(x=basecoal/priceratio, y=fit.transformed)) +
  geom_ribbon(aes_string(ymin = final_wecc$lwr.transformed, ymax = final_wecc$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2.2, 12)) +
  labs(title="Western Interconnection", subtitle = "y=Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()
#>
```

**Task:** Use grid.arrange() to display the plots next to each other. Just press *check*.

```{r "4_1__11",warning=FALSE, fig.width=14, fig.height=7}
grid.arrange(plot_east, plot_ercot, plot_wecc,  nrow=1)
```


//TEXT, east oben, hier verlgeich zu ercot, wecc






///////// test
```{r "4_1__12"}

main_data2 <- rbind(final_east, final_ercot, final_wecc)
main_data2 <- main_data2[order(as.Date(main_data2$date, format="%d/%m/%Y")),]
write.csv(main_data2, "X:\\libraries\\RTutor_BA\\main_data2.csv", row.names = FALSE)
temp <- read_csv("main_data2.csv")

```




#< award "Sp(l)ine Surgeon"
This was a critical operation, but you mastered it! Keep going, the hardest part is over.
#>


In the next exercise we will map the emission response curves from this exercise into carbon prices and estimate the effects of carbon prices on emissions.

## Exercise 4.2 --  Imputed CO2 Response to Carbon Prices

During exercise `4.1`, we have seen that $CO_2$ emissions could be greatly reduced when changing fuel prices of `gas` and `coal`. We already introduced the theory behind mapping carbon in prices in
exercise `2`. In this exercise we will follow the analysis of Cullen (2016) and transform the priceratio of the two commodities into `carbon prices`. This will allow us to estimate the approximate
costs of emission reductions. We split this exercise in two parts, first we will transform the results we gathered in exercise `4.1`

This exercise is split into 2 parts. In the first part we will transform price ratios into carbon prices and plot our result similiar to exercise `4.1`. In the second part we will adopt fixed carbon taxes, derive emission reductions based on our model and estimate the costs.

To calculate carbon prices we can rearrange equation ? from exercise ? to express them as a function of price ratios and baseline prices of gas and coal. This will lead to the following equation:

$$\tag{6}{P_{co2}}=\frac{CR\cdot{P_{gas}}-{P_{coal}}}{CO_{2,coal}-CR\cdot CO_{2,gas}}$$

In a first step we have to agree on a baseline level of fuel prices as well as carbon content of each fuel type. We use the same baseline prices as in the previous exercise. The  `U.S. Energy Information Administration` (https://www.eia.gov/tools/faqs/faq.php?id=73&t=11) reports the carbon content:

- Average delivered coal price `$2.25/mmBTU` and gas prices `$5.75/mmBTU` for 2025.
- Carbon content `Natural Gas`: 117 lbs carbon/MMBTU or `0.0585 tons/MMBTU`
- Carbon content `Coal`: 210.8 lbs carbon/MMBTU or `0.1054 tons/MMBTU` (averaged on weighted fuel consumption according to EIA Form 923)


We will continue to use the results from exercise `4.1`. To avoid repeating the same steps as before, I prepared a data frame that includes the predicted `emissions` as well as the `tranformed emissions` with confidence intervals. Load the data set `main_data2.csv` and store it in `dat`. `Head()` will show you the first rows. To save us some time, we also declare the variables as described above.

**Task:** Just press *check*.
```{r "4_2",message=FALSE}
#< task_notest
dat <- read_csv("Data/main_data2.csv")
head(dat,3)

basegas <- 5.75
basecoal <- 2.25
gas_cc <- 0.0585
coal_cc <- 0.1054
#>
```

As we have all needed data now, we can calculate the carbon taxes in the next step. We will get negative tax values because of our method, therefore we will filter them out. It would't make much
sense for us here to consider negative taxes.

**Task:** Create a column `carbontax` using `Equation 6` and filter the just calculated taxes for the interval [0,80]. Save the result into data frame `tax` and display the first rows.
```{r "4_2__2",message=FALSE}
#< task
#tax <- dat %>% 
#  mutate(carbontax = (priceratio*basegas-basecoal)/(coal_cc-priceratio*gas_cc)) %>% 
#  filter(carbontax >= ... & carbontax <= ...)
#
#head(...,...)
#>
#tax <- dat %>% 
##  mutate(carbontax = (priceratio*basegas-basecoal)/(coal_cc-priceratio*gas_cc)) %>% 
# filter(carbontax >= 0 & carbontax <= 80)


tax <- dat %>% 
  mutate(carbontax = (priceratio*basegas-basecoal)/(0.1054-priceratio*0.0585)) %>% 
  filter(carbontax >= 0 & carbontax <= 80)

head(tax,3)
#< hint
display("We want to keep carbon tax rates between 0 and 80. Display the first three rows with head(dataframe, 3).")
#>
```

The overall approach is similar to the one in exercise `4.1`. We will filter for each interconnection seperatly and plot our result with `ggplot2`. First we will create a plot for interconnection
`EAST` and interpret the results. Afterwards we will run the code on the other interconnections and compare them to another. In contrast to exercise `4.1` though, we won't plot the emission change,
but the abated $CO_2$ emissions.

**Task:** Filter the data frame `tax` for interconnection `EAST` and save it to `tax_east`. Since we filter for a string, don't forget to put quotes around the argument.
```{r "4_2__3"}
#< task
#
#>
tax_east <- filter(tax, intercn=="EAST")
#< hint
display("Use filter(dataset,filter). We want to filter for interconnection EAST.")
#>
```

**Task:** Just press *check*.
```{r "4_2__4",fig.width=7, fig.height=7}
#< task_notest
plot_east <- ggplot(tax_east, aes(x=carbontax, y=-fit.transformed)) +
  geom_ribbon(aes_string(ymin = -tax_east$lwr.transformed, ymax = -tax_east$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=-fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.01,0.15)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Eastern Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="y=Carbon Price $/ton")  +
  coord_flip()

plot_east
#>
```

///////TEXT

**Task:** Run the code for the `ERCOT` interconnection. Just press *check*.
```{r "4_2__5",fig.width=7, fig.height=7}
#< task_notest
tax_ercot <- filter(tax, intercn=="ERCOT")

plot_ercot <- ggplot(tax_ercot, aes(x=carbontax, y=-fit.transformed)) +
  geom_ribbon(aes_string(ymin = -tax_ercot$lwr.transformed, ymax = -tax_ercot$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=-fit.transformed)) +  
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.01,0.15)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Ercot Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="y=Carbon Price $/ton") + 
  coord_flip()
#>
```

**Task:** Run the code for the `WECC` interconnection. Just press *check*.
```{r "4_2__6",fig.width=7, fig.height=7}
#< task_notest
tax_wecc <- filter(tax, intercn=="WECC")

plot_wecc <- ggplot(tax_wecc, aes(x=carbontax, y=-fit.transformed)) +
  geom_ribbon(aes_string(ymin = -tax_wecc$lwr.transformed, ymax = -tax_wecc$upr.transformed),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=-fit.transformed)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.01,0.15)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Western Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="y=Carbon Price $/ton") + 
  coord_flip()
#>
```
&nbsp;
#< quiz "Compare emission abatement"
question: As shown in an earlier exercise, interconnection `ERCOT` has higher generation of renewable energies than `EAST`. Do you expect `ERCOT` to have a higher or lower emission abatement in comparison to `EAST`?

sc:
    - higher
    - lower*
success: Great, your answer is correct!
failure: Try again.
#>  

&nbsp;  
  
**Task:** Just press *check*.
```{r "4_2__7",fig.width=21, fig.height=7}
grid.arrange(plot_east, plot_ercot, plot_wecc, nrow=1)
```




#< award "?"
?
#>





**Task:** Just press *check*.
```{r "4_2__8"}
#< task_notest
find_closest_value <- function(a) {
  vector <- 1:9
  for(i in 0:8){
   vector[i+1] = mean(a$fit[which.min(abs(a$carbontax - i*10))])
  }
  return(vector)
}
temp1 = data.frame(tax=seq(0,80,10),east_emission=round(find_closest_value(tax_east)/100000,1), ercot_emission=round(find_closest_value(tax_ercot)/100000,1), wecc_emission=round(find_closest_value(tax_wecc)/100000,1))

temp2 <- temp1 %>% 
  mutate(perc_east=round((1-temp1$east_emission/temp1$east_emission[1])*100,1),
         perc_ercot=round((1-temp1$ercot_emission/temp1$ercot_emission[1])*100,1),
         perc_wecc=round((1-temp1$wecc_emission/temp1$wecc_emission[1])*100,1),
         emission_all=east_emission+ercot_emission+wecc_emission)

temp3 <- temp2 %>% 
  mutate(perc_all=round((1-temp2$emission_all/temp2$emission[1])*100,1))
  
table <- temp3 %>%
  select(c(1,2,5,3,6,4,7,8,9)) %>%
  kable(col.names = c("Tax","abs.","%","abs.","%","abs.","%","abs.","%"), align="c", caption = "Precited Emissions and Percentage Abatement") %>%
  add_header_above(c(" "=1, "East" = 2, "ERCOT" = 2, "West" = 2, "Total" = 2)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), position = "center", full_width = F)%>%
  #column_spec(1:9, width = "0.4") %>%
  footnote(general = "Predicted emission are in 100.000 tons/day. Change to baseline (Tax=0).")

table
#>
```


The result corresponds to Table 2 in Cullen(2016). 




Concluding, our results seem to be robust  to parameter changes.

## Exercise 5 -- Conclusion


```{r "5"}
#< task
awards()
#>
```


The methods used here can be further used to generate additoinal results. This could be a point where you can go on.




## Exercise 6 -- Bonus - Robutness Tests

//// einschub robustness test mit anderen definition von priceratios , appendix a2< number of knots NUR FUER EAST, danach kurz interpretieren

#! start_note "Robustness Test - andere priceratio"

```{r "6",optional=TRUE}
#< task
# show that all integers between 0 and 10
#>
1:10
```

#! end_note 

#! start_note "Robustness Test - weniger knots"

```{r "6__2",optional=TRUE}
#< task
# show that all integers between 0 and 10
#>
1:10
```

#! end_note 



## Exercise References


### Bibliography

- Cullen, Joseph A., and Erin T. Mansur. 2017. "Inferring Carbon Abatement Costs in Electricity Markets: A Revealed Preference Approach Using the Shale Revolution." American Economic Journal: Economic Policy, 9 (3): 106-33.

- Lafrancois, B. A. (2012), âA lot left over: Reducing CO2 emissions in the United Statesâ electric power sector through the use of natural gasâ, Energy Policy 50, 428â435.


/add literature

### R Packages

- Auguie, B. (2017): gridExtra: "Functions in Grid graphics", R package version 2.3, http://cran.r-project.org/web/packages/gridExtra/index.html

- Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables. R package version 5.2.2. https://CRAN.R-project.org/package=stargazer 

- Kranz, S. (2015): RTutor. "Creating R problem sets with automatic assessment of student's solutions", R package version 2019.10.11, https://github.com/skranz/RTutor

- Rudis, B. (2017): ggalt: "Extra Coordinate Systems, 'Geoms', Statistical Transformations, Scales and Fonts for 'ggplot2'", R package version 0.4.0, https://cran.r-project.org/web/packages/ggalt/index.html

- Wickham, H. (2016): ggplot2. "Elegant Graphics for Data Analysis", Springer-Verlag, New York, R package version 3.2.1, http://CRAN.R-project.org/package=ggplot2

- Wickham, H., Francois, R., Henry, L., Muller, K., (2018): dplyr. "A Grammar of Data Manipulation", R package version 0.8.3, http://CRAN.R-project.org/package=dplyr

- Zhu, H. (2019), kableExtra: "Construct Complex Table with 'kable' and Pipe Syntax", R package version 1.1.0, https://cran.r-project.org/web/packages/kableExtra/index.html

/// add packages, "splines", "regtools", "ggalt?" ,"kable"
 
### Data Sources

- Federal Energy Regulatory Comission, "Form  No. 714 Annual Electric Balancing Authority Area
and Planning Area Report", https://www.ferc.gov/docs-filing/forms/form-714/data.asp

- Government of Canada, "Canada Energy Regulator", https://www.cer-rec.gc.ca/bts/ctrg/gnnb/lctrctxprts/index-eng.html

- Intercontinental Exchange, "Commodity Prices", https://www.theice.com/marketdata/reports

- National Centers for environmental Information (NOAA), Climate data, https://www.ncdc.noaa.gov/cag/statewide/time-series

- The World Bank , "Commodity Markets Monthly Prices",  https://www.worldbank.org/en/research/commodity-markets

- United States Environmental Protection Agency, "SO2 Trading Program", https://ampd.epa.gov/ampd/

- U.S. Energy Information Administration, "Form EIA-923", https://www.eia.gov/electricity/data/eia923/


*All of the above links were accessable as of March 31, 2020.*

