
---
title: Problem Set CarbonReductionCosts
output: 
  html_document: 
    keep_md: yes
    toc: yes
---

```{r setup, include=FALSE, echo=FALSE}
# Load libraries and source extra code
library(dplyr)
library(ggplot2)
library(gridExtra)
library(htmlTable)
library(stargazer)
library(pracma)
library(haven)
library(tidyverse)
library(ggalt)
library(regtools)
library(splines)
library(RTutor)


# Options for rendering data frames
# If you knit to a Word docx file, try
# 
# data.frame.theme="word" 
# 
# (needs RStudio > 1.2.1)
# 
# You can also set the options like
# table.max.cols as chunk options
# Makes sense if there are too many, too wide
# columns in some chunks

RTutor::set.knit.print.opts(data.frame.theme="code", table.max.rows=25, table.max.cols=NULL, round.digits=5, signif.digits=8)


# continue knitting even if there is an error
knitr::opts_chunk$set(error = TRUE) 
```

# Problem Set: Estimating CO2 Reduction Costs

Author: Daniel Dreyer



Welcome to this interactive problem set. The awareness of climate change rose significantly over the past years. Purely questioning the moral of the population though, won't avoid its' highly uncertain effects. Therefore high efforts are made to find technical improvements as well as economical incentitives to avoid long term effects of climate change.   
In this problem set we will approach one possible countermeasure by analysing how carbon pricing would reduce emissions in the electricty sector. The analysis is based on **"Inferring Carbon Abatement Costs in Electricity Markets: A Revealed Preference Approach using the Shale Revolution"** by Joseph A. Cullen, Erin T. Mansur (2016) - further simply referred as Cullen. The paper and further ressources can be downloaded from <a href="https://www.aeaweb.org/articles?id=10.1257/pol.20150388   target = "_blank"> https://www.aeaweb.org/articles?id=10.1257/pol.20150388</a>

You will use the `Statstical Programming Language R` to replicate the analysis. Basic knowledge of `R` is required, but information on important function will be provided. 
Since each new exercise inherits the results of previous exercises, it is recommendated to solve them in order. However you are free to skip to any exercise you like if you feel so.  
If you are a complete novice in `R` you should not feel left behind. Understanding the basic concepts is straight forward, you can find useful information [here](https://cran.r-project.org/manuals.html).



### Contents

$\qquad$  Overview
  
$\qquad$  1 TBA

$\qquad$  2 TBA

$\qquad$ $\qquad$ 2.1 

$\qquad$  3 TBA

$\qquad$  4 TBA

$\qquad$  5 Conclusion

$\qquad$ References


## Exercise Content

$\qquad$ *Exercise 1* - Motivation (rename later)

$\qquad$ *Exercise 2* - TBA

$\qquad$ *Exercise 3* - TBA

$\qquad$ *Exercise 4* - TBA

$\qquad$ *Exercise 5* - TBA


### ReadME


The problem set offers different ways to interact with it. Coding exercises are marked as **TASK**. Some only need to be run, for others you need to complement a small part of the code, which is noted in the task description. Below you can read about the different types of interactions with their corresponding functions:   


 - Code Chunks: Require you to complete small parts of Code. The work flow of solving code chunks is intuitive and as follows:
                
  + `edit` : Click to insert your own Code into the chunk.
  + `run chunk`: Runs the chunk and displays outputs or errors in the corresponding console.
  + `check`: Check your input for against the solution.
  + `hint` : Should you have problem to solve a task, you can request a hint.  
&nbsp;

  
  Additional functions:    
                   
  + `data`: Redirects you to the data browser - you can view the loaded data with the help of an interface.
  + `solution` : Shows the solution of the task.  
&nbsp;

  
 - Quizzes: Evaluate your knownledge of topics before we dive in our analysis.
    
 - Info Boxes: Contain additional information on technical terms or documentation of functions.
 

After you finish a chapter, click `Go to next exercise` on the bottom or navigate around with the help of the bar on top.


## Exercise 1 -- Motivation

`Coal` is the **world's biggest source of energy and carbon emissions**, mostly because it is easy to store, transport, doesn't alter and can be mined in huge quantities around the world. This makes it desirable and cheap to use as a energy source. Given that the coal supply will last for decades, it is a major goal to find incentitives to reduce emissions from coal consumption.  
One alternative to coal is `natural gas`. Even though still being a fossil fuel, its' emissions and heat density are way superior to coal. Nevertheless, natural gas wasn't considered to be an real alternative to coal because to its higher prices more difficult handling up until the early 2000s.  
This changed due to the `Shale Revolution`, whereby natural gas was not only a by-product of the oil industry, but could now be extracted in a targeted manner and in large quantities. Lanfrancois (2012) estimates, that based on the Clean Power Plan introduced by the Obama administration in 2015, carbon dioxide emissions from the electricity industry could be reduced by 23 to 42 percent by switching existing coal powered generators to gas powered ones.  
  

***

### Info: Shale-Revolution
Shale gas is a form of natural gas and is extracted from shale formation, known as fracking. Since the start of the century, shale gas became a increasingly more important source of natural gas in the United States. Whereas in 2000 shale gas only provided 1% of the natural gas, nowadays in 2020 it makes up roughly 50%.
However at the same time, the environmental concerns of fracking are heavily debated.  

You can find further information on the topic here:  
<a href="https://en.wikipedia.org/wiki/Shale_ga   target = "_blank"> https://en.wikipedia.org/wiki/Shale_gas</a>s  
<a href="https://en.wikipedia.org/wiki/Hydraulic_fracturing   target = "_blank"> https://en.wikipedia.org/wiki/Hydraulic_fracturing</a>

***

  
With this in mind, in `Exercise 1` you will explore data to get insights in the current situation of the U.S. energy sector. You will look at the distribution of energy sources in the American market, its prices and the generated load over time.  

**Task:**
Use the `read_csv` command to *load the data set* and store it in a variable called `PaGP`.
The basic structure of the command is already given in the code chunk as a comment.


***

### Info: read.csv() and write.csv()
The command `read_csv()` reads in a **csv file** and stores it into a given name. Csv is a format for data, that uses commas as seperators and periods as decimals. Another version of are **csv2 files**, where semicolons are used for seperators and commas for decimals. We only use csv files here.

Given the file you want to read it is in the same working directory, you can use the command below:

```{r "1",eval=FALSE}
example <- read_csv("example.csv")
```

If the file is saved outside of your working directory there are two possibilities. For one you can insert the whole file path, if the file is you can navigate through the whole file path if your file is above 

If the file is saved in an structure above your working directory you have to additionally insert the full file path:

```{r "1__2",eval=FALSE}
example <- read_csv("C:/Data/example.csv")
```

For files that are located below the working directory it is sufficient to specify the following file path:

```{r "1__3",eval=FALSE}
example <- read_csv("./Data/example.csv")
```


Csv files can be saved using the `write.csv` command.

```{r "1__4",eval=FALSE}
write_csv(example, file="example.csv")
```

For further information, use `help(write.csv)`.

***


```{r "1__5"}
# ... <- read_csv("./Data/PaGP.csv")
PaGP <- read_csv("./Data/PaGP.csv")
```


**Task:** Lets take a look at the data we just imported. Use the `head()` command to show the first **eight** rows of the data set. 


```{r "1__6"}
# head(PaGP, ...)
head(PaGP, 5)

```


Alternatively you can press the `data` button to get redirected to the `Data Explorer` Tab. 

The date column is currently stored as a character. To be able visualize the date variable as a continuous variable, we have to convert is. Therefore, R has a build in date class.  
**Task:** Just press *check*.

```{r "1__7"}
PaGP <- as.data.frame(PaGP)
PaGP$date <- as.Date(PaGP$date)
```

  
The data frame contains monthly numbers of generated MwH with coal and gas as well as prices of Energy commodities. 
Keep in mind that different commodities are traded in different units. Oil is traded in barrels (\$/bbl), coal in metric tons (\$/mt) and gas in British thermal units($/mmbtu). The natural gas index is
set to 100 in the year 2010 and changes accordingly.
Prior to visualizing the data and to get clearer results, lets modifiy the data set. As mentioned before, commodities are traded in different units. Therefore we will add new entries for normalized
prices, which gives us a good cost basis to produce the same amount of energy with each commodity.  On this account, we assume that `1 MwH = 0.454 mT Coal = 3.412 mmBtu Natural Gas`.

**Task:** Perform the above calculations. Just press *check*.
  

***

### Info: Pipe, mutate, select
The pipe operator `%>%` is a feature provided by the `dplyr` Package. Essentially it allows to exectute multiple operation on a dataframe at once.
This works the way that every pipe operator returns a dataframe and passes it to the next connected function. `Select` allows you to filter out certain columns of data, whereas `mutate` allows you to
alter data. The counterpart for selecting specific rows is `filter`. There are several more functions to alter your data, below i linked a handy cheatsheet.
  
```{r "1__8",eval=FALSE}
example %>% 
  select(1:5)  `select: keep certain columns, here column 1 to 5`  %>% 
  mutate(new_column = old_column+1)`mutate: create or alter columns`    

```

You can find a more detailed cheatsheet [here](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) or use the `help()` function.

***



***

### Info: ggplot2
The package `ggplot2` is a powerful data visualization package for `R`, which is part of the `tidyverse` environment. Besides basic functions that are also provided by native `R`, it allows the user to
highly modify graphs by **altering**, **adding** or **removing** components.

The problem set doesn't require you to have deeper knowledge about function of `ggplot2`. However, you can find further documentation [here](https://ggplot2.tidyverse.org/) or type `help(ggplot2)`.

***



```{r "1__9"}
PaGP <- PaGP %>% 
  mutate(price_naturalgas_USA_normalized = price_naturalgas_USA * 3.412,
         price_naturalgas_Europe_normalized = price_naturalgas_Europe * 3.412,
         price_coal_australia_normalized = price_coal_australia * 0.453, 
         price_coal_africa_normalized = price_coal_africa * 0.453)
```

**Task:** Output a graphic. Just press *check*.
```{r "1__10"}
ggplot(data=PaGP, aes(x=date)) +
  geom_line(aes(y=PaGP$price_coal_australia_normalized, color="Coal Autralia"), size=1) +
  geom_line(aes(y=PaGP$price_coal_africa_normalized, color="Coal Africa"), size=1) +
  geom_line(aes(y=PaGP$price_naturalgas_USA_normalized, color="Gas US"), size=1) +
  geom_line(aes(y=PaGP$price_naturalgas_Europe_normalized, color="Gas Europe"), size=1) +
  labs(x = "Year", y = "", title = "Normalized Ressource Prices", subtitle = "Y=$/MwH")+
  scale_color_manual(name="Region",values = c("green", "yellow", "blue","red"))
```

TEXT


In the next Step we will look at the generated Power for Coal / Gas in the U.S. 




Quiz: Do you think that the proportion of gas generated electicity compared to coal generated electricity has increased or decreased over time?

- increased [x]

- decreased [ ]

&nbsp;




**Task:** Just press *check*.

```{r "1__11"}
ggplot(data=PaGP, aes(x=date)) +
  geom_line(aes(y=PaGP$generated_coal, color="Coal Generation (TWh)"), size=1, alpha=0.5) +
  geom_line(aes(y=PaGP$generated_gas, color="Natural Gas Generation (TWh)"), size=1, alpha=0.5) +
  labs(x = "Year", y = "", title = "Monthly Generation by Fueltype", subtitle = "Y=Monthly Electricty (TWh)")+
  scale_color_manual(name="",values = c("black","red"))+
  scale_y_continuous(breaks=seq(0,200,25))
```

TEXT


***

### Award: Starter Kit
Good Start! You will earn awards at the end of every chapter. At the end you will see how many you have earned.

***



## Exercise 2 -- Interconnections // mapping carbon prices???

![Interconnections](./Material/interconnections.png) (SOURCE)


***

### Info: Interconnections
The American Electric system is made up of three major `Interconnections`, which in turn concist of different balancing authorities (responsible for maintaining the electricity balance within the region).
Local electricity grids are hereby connected to form a network, which provides higher stablity and reliability of electricity. These `Interconnections` are operated independently of each other and, in contrast to the European electricity grid, there is little transfer of power.  
The 3 regions, as seen in the graph above, are as followed:
- Easter Interconnection: Consists of 36 balancing authorities and extends from the East Coast to the Rocky Mountains.
- Western Interconnection: Involves 37 balancing authorities, which are located in the West of North America.
- Electric Reliability Council of Texas (ERCOT): Consists of large parts of Texas

***


**Task:** Just press *check*.
```{r "2__12"}
Emissions <- read.csv("./Data/Emissions_Unit_Type.csv")
```

wip



### theory behind mapping carbon prices


$$\tag{1}MC=HR\cdot(P_{fuel}+CO_{2,fuel}\cdot P_{co2})=HR\cdot C_{fuel}$$

einfuehren priceratio auf basis von tabelle oben - hohe varianz


## Exercise 3 -- Road to a working model

In this exercise we briefly go over the data we use for our main analysis and give an overview what we will be doing in the following exercises. The main question of this problem set is to find out how
carbon prices would effect emissions in the energy sector. To answer this we will construct a statistical model to understand the emission behaviour for changing input costs while controlling for
variables that effect the energy market. However we won't simply propose a final model but will work our way from simple linear regressions to more complex but also more accurate models.  
&nbsp;
 - You can find a rough guideline of content in each exercise below:
                
  + `Exercise 3.1` - Linear Regression and Polynomial Regression
  + `Exercise 3.2` - Introduction of Cubic Splines
  + `Exercise 3.3` - Estimated CO2 Response to Fuel Prices
  + `Exercise 3.4` - Imputed CO2 Response to Carbon Prices
&nbsp;

If you want to go faster through the problem set, you can skip to exercise `3.3` onwards, which presents the final model and visualize our results.  
Before we take a look at the data, import our dataset.

**Task:** Load the data set `main_data.csv`, press `edit` and `check` afterwards.

```{r "3__13",message=FALSE}
dat <- read_csv("Data/main_data.csv")
head(dat,3)
```
&nbsp;

The data frame is a combination of data we used previous exercises and additional factors. It consists of `daily` information for `each interconnection`. Relevant columns are explained below:

`co2mass` = CO2 emissions in tons  
`gasprice` = Capacity weighted average daily gas price per interconnetion ($ per million BTU)  
`coalprice` = Price of Coal ($ per million BTU)  
`load` = daily electricity consumption per interconnection in MWH  
`meant` = average daily temperature per interconnection  
`nonFossil` 
`so2price`
`netNSflow` = MwH flowing from Canada to US by interconnection and month


++++++++ sources of data

When choosing control variables we have to be sure that they directly effect the emissions 

To give us an overview of the data, lets create a table with average values for relevant factors for each interconnection. R provides several packages that , but for now we work with packages we
introduced before and solve this with `dyplr`.  

**Task:** Use `group_by()` to group the dataset `dat` by `intercn`. Afterwards use `summarise_all()` to calculate the means of every variable. You don't have to deal with the additional lines of code, which is used to create a more understandable output.


***

### Info: Group_by() and summarise()
`Group_by()` allows you to group a data frame by specific variables. Operations that are run on the output data frame of grouped data are then performed on each group.

The function `Summarise()` can be used on your **grouped data** and can perform operations on your grouped data e.g. calculating means (`mean()`) or finding minimums (`min()`). There are several
pre-implemented version of `summarise` function in `R`. The one we use here is `summarise_all()`, which performs these operations on multiple variables.

To give you an example in code form, lets pretend we have a dataframe `data` with several car manufacturer and their respective car models with prices and we want to calculate the average car price per
manufacturer.

```{r "3__14",eval=FALSE}
example <- data %>% 
  group_by(manufacturer) %>%
  summarise(mean_price = mean(price))
```

Call `help(group_by)` or `help(summarize)` for futher information.

***


```{r "3__15"}
#... %>% 
#  select(intercn, co2mass, load, gasprice, coalprice) %>% 
#  group_by(...) %>% 
#  ...("mean") %>% 
#  mutate(co2mass = co2mass/1000, load=load/1000, "Emission Rate"=co2mass/load, "Cost Ratio"=coalprice/gasprice) %>% 
#  rename("CO2 Emissions"=co2mass, Load=load, "Gas Price"=gasprice, "Coal Price"=coalprice)
dat %>% 
  select(intercn, co2mass, load, gasprice, coalprice, meant, nonfossil, so2price) %>% 
  group_by(intercn) %>% 
  mutate(co2mass = co2mass/1000, load=load/1000, "Cost Ratio"=coalprice/gasprice, "Emission Rate"=co2mass/load) %>% 
  summarise_all("mean") %>% 
  rename("Interconnection"=intercn, "CO2 Emissions"=co2mass, Load=load, "Gas Price"=gasprice, "Coal Price"=coalprice)
```




/// graph einheiten y achse


**Task:** Just press *check*.


***

### Info: geom_encircle
Besides standard functionality for plotting points or lines, `ggplot2` provides a advanced framework for visualising your data. `geom_encircle()` encloses groups of data point in a polycan and can be
used to circle specified groups of data and can be used to visualise differences in groups of data.

Call `help(geom_encircle)` to get further information.

***


```{r "3__16"}
ggplot(dat,aes(x=gasprice,y=co2mass/1000,color=intercn))+
        geom_point(alpha=0.2) +
        geom_encircle(aes(group=intercn,fill=intercn),alpha=0.3, s_shape=1) +
        theme_bw()+ 
        labs(y="", 
        x="Gas Price", 
        subtitle="CO2 Emissions",
        title="CO2 Emissions vs. Gasprice")
```

TEXT

## Exercise 3.1 -- Priceratio Regressions

In this and the following chapter we will take a look at regression theory and develop a model that satifies our statistical needs tor answer our initial question on how changing commodity prices will effect $CO_2$ emissions. We start with simple regressions and introduce new methods along the way to make our model more precise.

**Task:** To get started, load the data set `main_data.csv`, press `edit` and `check` afterwards.

```{r "3_1__17",message=FALSE}
dat <- read_csv("Data/main_data.csv")
```

We have seen in the previous exercise that it makes sense to calculate our model for each intersection separately. For this purpose we filter our data for intersection `EAST` and develop the model based on that `intersection`. Afterwards we will use the model on each intersection. Since we observe substantial variation in coal and gas prices, we construct a new variable for relative costs `priceratio`. There are several ways to propose price ratios, we use the ratio between the price of coal and gas, which is defined as followed:  

As we have seen in the last chapter it makes sense to apply our analysis for each intersection `separately`. For this reason the data are divided into interconnections. We `develop` our model based on the `EAST` interconnection and map the model to all at a later point in time.  







$$\tag{2}CR=\frac{C_{coal}}{C_{gas}}=\frac{P_{coal}+CO_{2,coal}\cdot P_{co2}}{P_{gas}+CO_{2,gas}\cdot P_{co2}}(2)$$



**Task:** The data set contains a column `intercn` with values `EAST`, `WEST` and `ERCOT`. Filter only for data with interconnection `EAST` and store the new data frame in variable `dat_east`. Additionally, calculate the cost ratio between `coalprice` and `gasprice`.
```{r "3_1__18"}
# ... <- data %>% 
#  mutate(CR = .../...) %>% 
#  filter(intercn=="...")
dat_east <- dat %>% 
  mutate(priceratio = coalprice/gasprice) %>%
  filter(intercn=="EAST")
```


### Stage 1: Linear Regression

Highly unlikely here, but to get you rolling in the topic, lets start with a simple linear regression and analyse the results on fitting. I will introduce methods to interpret regression results ...

///////// why priceratio - paper 18 absatz 2



***

### Info: Linear Regression with lm()

`lm()` is part of the `stats` package and loaded on default. As shown in the syntax example below, it enables you to regress `y` on the indepedent variables `x1` and `x2`. The model can be `stored` in a variable or directly `used` in other functions. Another popular function to solve linear regressions in `R` is `felm()`, that provides further functionality to include `fixed effects`. In this problem set we will strictly use `lm()`.

```{r "3_1__19",eval=FALSE}
example <- lm(y~x1+x2, data=dat_east)
```

You can find more information on the `lm()` function [here](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm) or use the `help()` function.

***


**Task:** Run a regression with `co2mass` as the dependent variable and `pricerati` as independent variable. Store it in the variable `fit1`. 
```{r "3_1__20"}
# ... <- lm(...~... , data=east)
fit <- lm(co2mass ~ priceratio, data=dat_east)
```



Before we look at our results, answer this quiz. 


Quiz: What impact do changing price ratios have on emissions? Remember, priceratio is defined as above.

- With increasing price ratios emissions will increase. [ ]

- With increasing price ratios emissions will fall. [x]



TEXT

**Task:** To
```{r "3_1__21"}
summary(fit)
```





**Task:** To
```{r "3_1__22"}
p1 <- predict(fit, newdata = dat_east)
```

QUIZ: erwartung fallend oder steigend


***

### Info: Predict
`predict()`

***


**Task:** To
```{r "3_1__23"}
plot(co2mass~priceratio, dat_east)
lines(dat_east$priceratio, p1, col="red")
```


We will use the `stargazer()` function from the `stargazer` package to show summary statistics from our regressions. We don't need everything to know everything the basic functions displays, therefore we define a own custom function with statistics we need. Read below to find out more about `stargazer` and `custom functions` and continue with the next `task`.


***

### Info: Stargazer
`stargazer` provides specialised `HTML` formatting for regression tables and summary statistics tables. It is easy to use, supports a large number of model types and formats data in a more pleasing way. The basic function is called by `stargazer()`, but can be customized heavily. For more information run `help(stargazer)` or read further [here](https://cran.r-project.org/web/packages/stargazer/).

***



***

### Info: Custom functions
`R` provides an easy framework to add your own functions. The syntax is quite similar to other `Programming Languages` you could be familiar with. Once you have defined a function, you can use it as long as you are in the same session. Below you can find the basic structure of a function:

```{r "3_1__24",eval=FALSE}
`myfunction <- function(arg1, arg2, ... ){`  
`statements`  
`return(object)`  
```  
Here's an simple functions that adds `5` to the input and returns it.
```{r "3_1__25",eval=FALSE}
`example <- function(x) {`  
  `x + 5`  
`}`  
`example(1)`
```  
You can find more detailed information [here](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/function).


***


**Task:** Run the Code Chunk. It defines the function to show our custom regression tables.
```{r "3_1__26"}
show.regression= function(...){
  library(stargazer)
    stargazer(..., 
            type = "text", 
            style = "aer",  
            digits = 3,
            df = FALSE,
            report = "vct*",
            star.cutoffs = c(0.05, 0.01, 0.001),
            model.names = FALSE,
            object.names = TRUE,
            model.numbers = FALSE, 
            omit.stat=c("f", "ser")
    )
} 
```



**Task:** Let's see what we just defined. Run the regression table for the linear model. Insert 
```{r "3_1__27"}
# regression.result(...)
show.regression(fit)
```

TEXT

**Task:** To
```{r "3_1__28"}
plot(fit, 1)
plot(fit, 2)
```

QQ PLOT RESIDUALS?


***

### Info: R-squared
`R-Squared` is a statistical measurement that represents the correlation between `fitted values` and `observed values`. `R-squared` is always positive and ranges from 0 to 1. A value closer to 1 indicates that the suggested model explains a majority of the variance in the outcome variable.  
$R^{2}=1-\frac{Explained Variation}{Total Variation}$
A problem with the `R-squared` measurement is, that it always increases with higher numbers of variables in the model, even if these variables are only weakly responsible for the predicted values. An solution is to take the number of variables into account, this is called `Adjusted R-Squared` and also shown in the summary output.

***


### Stage 2: Polynomial Regression

**Task:** Just press *check*.
```{r "3_1__29"}
CR.squared <- east$CR^2
fit2 <- lm(CO2MASS ~ CR + CR.squared, east)

CR.cubed <- east$CR^3
fit3 <- lm(CO2MASS ~ CR + + CR.squared + CR.cubed, east)
```

**Task:** Just press *check*.
```{r "3_1__30"}
p2 <- predict(fit2, east)
p3 <- predict(fit3, east)
```

**Task:** Just press *check*.
```{r "3_1__31"}
plot(CO2MASS~CR, east)
lines(east$CR, p1, col="red")
lines(east$CR, p2, col="blue")
lines(east$CR, p3, col="green")
```

**Task:** Just press *check*.
```{r "3_1__32"}
regression.result(fit, fit2, fit3)
```

**Task:** Just press *check*.
```{r "3_1__33"}
anova(fit, fit2, fit3)
```










## Exercise 3.2 -- Restricted Spline Regressions

### Stage 3: Cubic Spline

In previous stages we came to the conclusion that a model that relies purely on `$CO_{2}$ emissions` and the `Cost Ratio` of gas and coal isn't sufficient to explain the real-life situation. In this exercise we will introduce the concept of `spline regression` and extend our model with several `control variables`.  
The model is a `reduced-form regression` and is defined as followed:

Explain Cubic Splines

```{r "3_2__34",optional=TRUE}
# show that all integers between 0 and 10
1:10
```



simple cubic splines

$$\tag{4}CO_{2t}=s(CR_{t}|\beta)$$



First, we have to define our model 





***

### Award: Linear Regression Expert
TEXT

***



## Exercise 3.3 -- Estimated CO2 Response to Fuel Prices

In this exercise we will expand our results from the previous exercise and estimate the $CO_{2}$ respone to changing fuel prices. 
To summarise the results from last exercises and to understand why we do certain methods this way, lets summarise. In exercise ?.? we showed that it makes sense to split our analysis in different connection. 

Getting the results we want isn't so easy, but we will take it step by step. First we will 

$$\tag{5}CO_{2t}=s(CR_{t}|\beta)+s(load_{t}|\theta) + s(temp_t|\omega)+X_t\psi+D_\gamma+\epsilon_t$$

***

### Info: Model variables
$CO_{2t}$ = CO2 emissions in tons  
$CR_{t}$ = Capacity weighted average daily gas price per interconnetion ($ per million BTU)  
$load_{t}$ = daily electricity consumption per interconnection in MWH  
meant = average daily temperature per interconnection  
$X_{t}$ = We include traditional factors like non-fossil electricity production (e.g. solar, hydro or wind), nonFossil, $SO_{2}$ price and net imports of electricity from Canada

***



**Task:** Load the data and store them in `dat`. Create a new variable called `priceratio` and calculate the ratio between `coalprice` and `gasprice`.
```{r "3_3__35",message=FALSE}
dat <- read_csv("Data/main_data.csv")

dat <- dat %>% 
  mutate(priceratio = coalprice/gasprice,
         season=(month>3) + (month>6) + (month>9),
         yearseason=year*10+season)
```

**Task:** Filter the data set for interconnection `EAST`.
```{r "3_3__36"}
east <- filter(dat, intercn=="EAST")
```

**Task:** Calculate the `mean` of every variable we use in our regression. First, select the necessary columns and then use `summarise_all` to get the `mean`. Store the result in `mean_dat_east`.
```{r "3_3__37"}
mean_dat_east <- east %>% 
  select(load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)
```






**Task:** To make our life a bit easier we will create a new data set with `gasprice`, `priceratio` and the results of the `last` task. Use `tibble()` to create the described output.


***

### Info: tibble()



***


***

### Info: cbind()



***

```{r "3_3__38"}
temp_east <- tibble(gasprice = east$gasprice, priceratio = east$priceratio) %>% cbind(mean_dat_east)
```

Our data are now ready to be used on our model. We have the necessary data for our regression model in the data set `east` and afterwards we can predict `emissions` with the help of data in `mean_dat_east`.


***

### Info: ns()



***


**Task:** Perform the regression model we described in the beginning of this exercise. Use `ns()` for variable we want to regress per spline regression. We want to use `5` degrees of freedom. Store the resulting model in `reg_east`.
```{r "3_3__39"}
reg_east <- lm(co2mass ~ ns(priceratio, df=5) + ns(load, df=5) + tlsd + tlmin + tlmax + ns(meant, df=5) + nonfossil + so2price + netNSflow + yearseason, data=east)
```

**Task:** Predict $CO_2$ emissions based on the regression model `reg_east` and `temp_east`.
```{r "3_3__40"}
co2.east = predict(reg_east, newdata = temp_east, interval = 'confidence')

co2.east$fit
#temp_east = temp_east %>% cbind(as.data.frame(predict(reg_east, newdata = temp_east, interval = 'confidence')))
```




**Task:** Just press *check*.
```{r "3_3__41"}
basecoal=2.25
basegas=5.75

diff_base <- abs(east$priceratio - (basecoal/basegas))
min_dif <- min(diff_base)
closest <- min_dif==diff_base
base_emit <- mean(co2.east$fit[which(closest)])

transformed.east.fit <- co2.east$fit/base_emit-1
transformed.east.lwr <- co2.east$lwr/base_emit-1
transformed.east.upr <- co2.east$upr/base_emit-1

#pred_east <- temp_east %>% cbind(transformed.east = transformed.east)

```

**Task:** Just press *check*.
```{r "3_3__42",warning=FALSE}
plot_east <- ggplot(temp_east, aes(x=basecoal/priceratio, y=transformed.east.fit)) +
  geom_ribbon(aes_string(ymin = transformed.east.lwr, ymax = transformed.east.upr),
                   colour="lightgrey", fill="lightgrey", alpha=0.5) +
  geom_line(aes(y=transformed.east.fit)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2, 12)) +
  labs(title="EAST Interconnection", subtitle = "Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU") +
  theme_minimal()

plot_east
```

**Task:** Run the code for the `ERCOT` interconnection. Just press *check*.
```{r "3_3__43",warning=FALSE}
ercot <- filter(dat, intercn=="ERCOT")

mean_dat_ercot <- ercot %>% 
  select(co2mass, load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)

pred_temp2 <- tibble(gasprice = ercot$gasprice, priceratio = ercot$priceratio) %>% cbind(mean_dat_ercot)

reg_ercot <- lm(co2mass ~ ns(priceratio, df=6) + ns(load, df=6) + tlsd + tlmin + tlmax + ns(meant, df=6) + nonfossil + so2price + netNSflow + yearseason, data=ercot)
#ERCOT has no net imports of electricity, predict throws warning
co2.ercot = suppressWarnings(predict(reg_ercot, pred_temp2))

pred_ercot <- pred_temp2 %>% cbind(transformed.ercot = co2.ercot/(mean(co2.ercot[which(min(abs(ercot$priceratio - (basecoal/basegas)))==abs(ercot$priceratio - (basecoal/basegas)))]))-1)

plot_ercot <- ggplot(pred_ercot, aes(x=basecoal/priceratio, y=transformed.ercot)) +
  geom_line(aes(y=transformed.ercot)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2, 12)) +
  labs(title="ERCOT Interconnection", subtitle = "Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU")
plot_ercot
```

**Task:** Run the code for the `WECC` interconnection. Just press *check*.
```{r "3_3__44",warning=FALSE}
wecc <- filter(dat,intercn=="WECC")

mean_dat_wecc <- wecc %>% 
  select(co2mass, load, tlsd, tlmin, tlmax, meant, nonfossil, so2price, netNSflow, yearseason) %>% 
  summarise_all(mean)

pred_temp3 <- tibble(gasprice = wecc$gasprice, priceratio = wecc$priceratio) %>% cbind(mean_dat_wecc)

reg_wecc <- lm(co2mass ~ ns(priceratio, df=5) + ns(load, df=5) + tlsd + tlmin + tlmax + ns(meant, df=5) + nonfossil + so2price + netNSflow + yearseason, data=wecc)

co2.wecc = predict(reg_wecc, pred_temp3)

pred_wecc <- pred_temp3 %>% cbind(transformed.wecc = co2.wecc/(mean(co2.wecc[which(min(abs(wecc$priceratio - (basecoal/basegas)))==abs(wecc$priceratio - (basecoal/basegas)))]))-1)

plot_wecc <- ggplot(pred_wecc, aes(x=basecoal/priceratio, y=transformed.wecc)) +
  geom_line(aes(y=transformed.wecc)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.15,.05)) +
  geom_vline(xintercept = 5.75, linetype = "dashed") + 
  scale_x_continuous(breaks=c(2,3,4,5,6,7,8,9,10,11,12), limits=c(2, 12)) +
  labs(title="WECC Interconnection", subtitle = "Percentage Change in CO2 emissions",
       y="", x="Gas Price $/MMBTU")
plot_wecc
```

```{r "3_3__45",warning=FALSE}
grid.arrange(plot_east, plot_wecc, plot_ercot, nrow=1)
```

///////// checken
```{r "3_3__46"}
e <- tibble(date=east$date, intercn=east$intercn, gasprice=east$gasprice, coalprice=east$coalprice, priceratio=east$priceratio, emission=co2.east, transformed.emission=pred_east$transformed.east)
er <- tibble(date=ercot$date, intercn=ercot$intercn, gasprice=ercot$gasprice, coalprice=ercot$coalprice, priceratio=ercot$priceratio, emission=co2.ercot, transformed.emission=pred_ercot$transformed.ercot)
wec <-tibble(date=wecc$date, intercn=wecc$intercn, gasprice=wecc$gasprice, coalprice=wecc$coalprice, priceratio=wecc$priceratio, emission=co2.wecc, transformed.emission=pred_wecc$transformed.wecc)

main_data2 <- rbind(e,er,wec)

main_data2 <- main_data2[order(as.Date(main_data2$date, format="%d/%m/%Y")),]

write.csv(main_data2, "X:\\libraries\\RTutor_BA\\main_data2.csv", row.names = FALSE)


temp <- read_csv("main_data2.csv")

```





***

### Award: Sp(l)ine Surgeon
This was a critical operation, but you mastered it! Keep going, the hardest part is over.

***





## Exercise 3.4 --  Imputed CO2 Response to Carbon Prices


The first step is the same as in the last exercise, but we need it for this part too. You can just run the code below. If you have skipped to this exercise and dont understand what it does you should go back to the previous exercise.

${P_{co2}}=\frac{CR\cdot{P_{gas}}-{P_{coal}}}{CO_{2,coal}-CR\cdot CO_{2,gas}}$

To safe us a bit of work i already created a dataframe that contains the results of last exercise.

**Task:** Just press *check*.
```{r "3_4__47",message=FALSE}
dat <- read_csv("Data/main_data2.csv")
head(dat,3)

basegas <- 5.75
basecoal <- 2.25
```


**Task:** Just press *check*.
```{r "3_4__48"}
#117 is lbs carbon/MMBTU for gas or 0.0585 tons/MMBTU
#210.8 is lbs carbon/MMBTU for coal or .1054 tons/MMBTUgen
temp_east <- dat %>% 
  filter(intercn=="EAST") %>% 
  mutate(carbontax = (priceratio*basegas-basecoal)/(0.1054-priceratio*0.0585))

```

**Task:** Just press *check*.
```{r "3_4__49"}
tax_east <- temp_east %>% 
  filter(carbontax >= 0 & carbontax <= 80)
```


**Task:** Just press *check*.
```{r "3_4__50"}
ggplot(tax_east, aes(x=carbontax, y=transformed.emission*(-1))) +
  geom_line() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.05,0.2)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Eastern Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="Carbon Price $/ton") + 
  coord_flip()

```
///////COMMENT

**Task:** Run the code for the `ERCOT` interconnection. Just press *check*.
```{r "3_4__51"}
temp_ercot <- dat %>% 
  filter(intercn=="ERCOT") %>% 
  mutate(carbontax = (priceratio*basegas-basecoal)/(0.1054-priceratio*0.0585))


tax_ercot <- temp_ercot %>% 
  filter(carbontax >= 0 & carbontax <= 80)

ggplot(tax_ercot, aes(x=carbontax, y=transformed.emission*(-1))) +
  geom_line() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.05,0.2)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Ercot Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="Carbon Price $/ton") + 
  coord_flip()
```

**Task:** Run the code for the `WECC` interconnection. Just press *check*.
```{r "3_4__52"}
temp_wecc <- dat %>% 
  filter(intercn=="WECC") %>% 
  mutate(carbontax = (priceratio*basegas-basecoal)/(0.1054-priceratio*0.0585))


tax_wecc <- temp_wecc %>% 
  filter(carbontax >= 0 & carbontax <= 80)

ggplot(tax_wecc, aes(x=carbontax, y=transformed.emission*(-1))) +
  geom_line() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits=c(-.05,0.2)) +
  scale_x_continuous(limits=c(0, 80)) +
  labs(title="Western Interconnection",
       y="CO2 Emissions abated as a Percentage of Baseline Emissions", x="", subtitle="Carbon Price $/ton") + 
  coord_flip()
```

**Task:** Just press *check*.










///////// TABELLE 

















//// einschub robustness test mit anderen definition von priceratios , appendix a2< number of knots NUR FUER EAST, danach kurz interpretieren


```{r "3_4__53",optional=TRUE}
# show that all integers between 0 and 10
1:10
```



```{r "3_4__54",optional=TRUE}
# show that all integers between 0 and 10
1:10
```


## Exercise 4 -- Conclusion


```{r "4__55"}
awards()
```


The methods used here can be further used to generate additoinal results. This could be a point where you can go on.


## Exercise References


### Bibliography

- Cullen, Joseph A., and Erin T. Mansur. 2017. "Inferring Carbon Abatement Costs in Electricity Markets: A Revealed Preference Approach Using the Shale Revolution." American Economic Journal: Economic Policy, 9 (3): 106-33.

- Lafrancois, B. A. (2012), ‘A lot left over: Reducing CO2 emissions in the United States’ electric power sector through the use of natural gas’, Energy Policy 50, 428–435.


/add literature

### R Packages

- Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables.
 R package version 5.2.2. https://CRAN.R-project.org/package=stargazer 

- Kranz, S. (2015): RTutor. "Creating R problem sets with automatic assessment of student's solutions", R package version 2019.10.11, https://github.com/skranz/RTutor

- Wickham, H. (2016): ggplot2. "Elegant Graphics for Data Analysis", Springer-Verlag, New York, R package version 3.2.1, http://CRAN.R-project.org/package=ggplot2

- Wickham, H., Francois, R., Henry, L., Muller, K., (2018): dplyr. "A Grammar of Data Manipulation", R package version 0.8.3, http://CRAN.R-project.org/package=dplyr

/// add packages, "splines", "regtools", "ggalt?" ,"htmltable"
 
### Data Sources

- Federal Energy Regulatory Comission, "Form  No. 714 Annual Electric Balancing Authority Area
and Planning Area Report", https://www.ferc.gov/docs-filing/forms/form-714/data.asp

- The World Bank , "Commodity Markets Monthly Prices",  https://www.worldbank.org/en/research/commodity-markets

- U.S. Energy Information Administration, "Form EIA-923", https://www.eia.gov/electricity/data.php#generation


/// add data sources


*All of the above links were accessable as of March 31, 2020.*

